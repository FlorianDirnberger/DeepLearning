Loaded module: cuda/11.8
Loaded dependency [python3/3.10.13]: sqlite3/3.45.1
Loaded dependency [python3/3.10.13]: gcc/12.3.0-binutils-2.40
Loaded module: python3/3.10.13

Loading python3/3.10.13
  Loading requirement: sqlite3/3.45.1 gcc/12.3.0-binutils-2.40
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: raimo-sieber (raimo-sieber-technical-university-of-munich). Use `wandb login --relogin` to force relogin
wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.
wandb: WARNING To avoid this, please fix the sweep config schema violations below:
wandb: WARNING   Violation 1. Additional properties are not allowed ('count' was unexpected)
wandb: Agent Starting Run: 4wj0ij52 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_162151-4wj0ij52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-1
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4wj0ij52
wandb: - 0.009 MB of 0.009 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇▇▇▆▅▅▄▄▃▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▇▇▇▆▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 8.36373
wandb:      train_rmse 2.89201
wandb: validation_loss 9.27244
wandb: validation_rmse 3.04507
wandb: 
wandb: 🚀 View run summer-sweep-1 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4wj0ij52
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_162151-4wj0ij52/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cou1qs9w with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_163100-cou1qs9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-2
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cou1qs9w
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 🚀 View run apricot-sweep-2 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cou1qs9w
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_163100-cou1qs9w/logs
wandb: Agent Starting Run: ice15dn7 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_163111-ice15dn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-3
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ice15dn7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▄▁▁▁▂▁▁▁▂▁▃▁▁▁▁▁▂▁▁▂▄▁▃▄▁▆▃▂▁▂▁▃▁▂▁▁▂
wandb: validation_rmse █▂▂▅▂▂▁▂▂▂▂▂▃▁▁▁▂▂▃▁▂▂▅▁▂▅▁▇▃▂▃▁▂▂▄▂▃▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 27.10582
wandb:      train_rmse 5.20633
wandb: validation_loss 27.16215
wandb: validation_rmse 5.21173
wandb: 
wandb: 🚀 View run divine-sweep-3 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ice15dn7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_163111-ice15dn7/logs
wandb: Agent Starting Run: oe6dd6xb with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_163821-oe6dd6xb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-4
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oe6dd6xb
wandb:                                                                                
wandb: 🚀 View run dazzling-sweep-4 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oe6dd6xb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_163821-oe6dd6xb/logs
wandb: Agent Starting Run: 2j7h1wla with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_163826-2j7h1wla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-5
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2j7h1wla
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-5 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2j7h1wla
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_163826-2j7h1wla/logs
wandb: Agent Starting Run: geu5z20x with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_163832-geu5z20x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-6
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/geu5z20x
wandb:                                                                                
wandb: 🚀 View run fanciful-sweep-6 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/geu5z20x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_163832-geu5z20x/logs
wandb: Agent Starting Run: rzpzali5 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_163837-rzpzali5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-7
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rzpzali5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss ▇█▅▃▆█▁▃▂▂
wandb: validation_rmse ▇█▆▃▆█▁▃▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 43.79391
wandb:      train_rmse 6.6177
wandb: validation_loss 114.29094
wandb: validation_rmse 10.69069
wandb: 
wandb: 🚀 View run zany-sweep-7 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rzpzali5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_163837-rzpzali5/logs
wandb: Agent Starting Run: jkpupqax with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164011-jkpupqax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-8
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jkpupqax
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run polished-sweep-8 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jkpupqax
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164011-jkpupqax/logs
wandb: Agent Starting Run: qoe0fwzi with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164016-qoe0fwzi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-9
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qoe0fwzi
wandb:                                                                                
wandb: 🚀 View run flowing-sweep-9 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qoe0fwzi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164016-qoe0fwzi/logs
wandb: Agent Starting Run: 6r9x69mf with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164022-6r9x69mf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-10
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6r9x69mf
wandb:                                                                                
wandb: 🚀 View run prime-sweep-10 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6r9x69mf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164022-6r9x69mf/logs
wandb: Agent Starting Run: aekv3mlf with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164027-aekv3mlf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-11
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aekv3mlf
wandb:                                                                                
wandb: 🚀 View run genial-sweep-11 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aekv3mlf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164027-aekv3mlf/logs
wandb: Agent Starting Run: ojyle4jg with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164033-ojyle4jg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-12
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ojyle4jg
wandb:                                                                                
wandb: 🚀 View run vital-sweep-12 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ojyle4jg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164033-ojyle4jg/logs
wandb: Agent Starting Run: kly0il1i with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164038-kly0il1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-13
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kly0il1i
wandb:                                                                                
wandb: 🚀 View run wandering-sweep-13 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kly0il1i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164038-kly0il1i/logs
wandb: Agent Starting Run: faij0icp with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164043-faij0icp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-14
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/faij0icp
wandb:                                                                                
wandb: 🚀 View run graceful-sweep-14 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/faij0icp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164043-faij0icp/logs
wandb: Agent Starting Run: 6i0r15jj with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164049-6i0r15jj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-15
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6i0r15jj
wandb:                                                                                
wandb: 🚀 View run likely-sweep-15 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6i0r15jj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164049-6i0r15jj/logs
wandb: Agent Starting Run: wz8u1u1m with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164054-wz8u1u1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-16
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wz8u1u1m
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (3 x 16). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
wandb:                                                                                
wandb: 🚀 View run whole-sweep-16 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wz8u1u1m
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164054-wz8u1u1m/logs
Run wz8u1u1m errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (3 x 16). Kernel size: (5 x 5). Kernel size can't be greater than actual input size

wandb: ERROR Run wz8u1u1m errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
wandb: ERROR     return self._conv_forward(input, self.weight, self.bias)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
wandb: ERROR     return F.conv2d(input, weight, bias, self.stride,
wandb: ERROR RuntimeError: Calculated padded input size per channel: (3 x 16). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5d84fha9 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164110-5d84fha9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-17
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5d84fha9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▇▇▆▅▄▃▂▁
wandb:      train_rmse ██▇▇▆▅▅▃▂▁
wandb: validation_loss ██▇▆▆▅▄▃▃▁
wandb: validation_rmse ██▇▇▆▅▄▄▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 364.58732
wandb:      train_rmse 19.09417
wandb: validation_loss 653.01202
wandb: validation_rmse 25.5541
wandb: 
wandb: 🚀 View run comfy-sweep-17 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5d84fha9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164110-5d84fha9/logs
wandb: Agent Starting Run: fdlwp5mt with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164244-fdlwp5mt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-18
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fdlwp5mt
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▁▂▁▂▅▁▄▁
wandb: validation_rmse █▄▁▂▁▃▅▁▄▁
wandb: 
wandb: Run summary:
wandb:      train_loss 68.74955
wandb:      train_rmse 8.29153
wandb: validation_loss 75.00428
wandb: validation_rmse 8.6605
wandb: 
wandb: 🚀 View run tough-sweep-18 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fdlwp5mt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164244-fdlwp5mt/logs
wandb: Agent Starting Run: z7djisp1 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164418-z7djisp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-19
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z7djisp1
wandb:                                                                                
wandb: 🚀 View run crimson-sweep-19 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z7djisp1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164418-z7djisp1/logs
wandb: Agent Starting Run: em7eehkp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164423-em7eehkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-20
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/em7eehkp
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-20 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/em7eehkp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164423-em7eehkp/logs
wandb: Agent Starting Run: 5basf8h0 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164429-5basf8h0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-21
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5basf8h0
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run dry-sweep-21 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5basf8h0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164429-5basf8h0/logs
wandb: Agent Starting Run: mzcnr0jp with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164434-mzcnr0jp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-22
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mzcnr0jp
wandb:                                                                                
wandb: 🚀 View run morning-sweep-22 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mzcnr0jp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164434-mzcnr0jp/logs
wandb: Agent Starting Run: bfanzy8v with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164439-bfanzy8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-23
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bfanzy8v
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run cosmic-sweep-23 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bfanzy8v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164439-bfanzy8v/logs
wandb: Agent Starting Run: y9bdmdsz with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_164450-y9bdmdsz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-24
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y9bdmdsz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▃▂▂▁▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.43076
wandb:      train_rmse 0.65633
wandb: validation_loss 6.84691
wandb: validation_rmse 2.61666
wandb: 
wandb: 🚀 View run skilled-sweep-24 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y9bdmdsz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_164450-y9bdmdsz/logs
wandb: Agent Starting Run: vt7c1bs9 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165150-vt7c1bs9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-25
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vt7c1bs9
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-25 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vt7c1bs9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165150-vt7c1bs9/logs
wandb: Agent Starting Run: bnp5srub with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165156-bnp5srub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-26
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bnp5srub
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▅▄▃▂▂▁
wandb:      train_rmse █▇▇▆▅▄▃▂▂▁
wandb: validation_loss █▇▇▆▅▃▃▂▁▁
wandb: validation_rmse █▇▇▆▅▃▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 648.58909
wandb:      train_rmse 25.46741
wandb: validation_loss 704.60342
wandb: validation_rmse 26.54437
wandb: 
wandb: 🚀 View run dulcet-sweep-26 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bnp5srub
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165156-bnp5srub/logs
wandb: Agent Starting Run: egakh8ze with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165324-egakh8ze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-27
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/egakh8ze
wandb:                                                                                
wandb: 🚀 View run polar-sweep-27 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/egakh8ze
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165324-egakh8ze/logs
wandb: Agent Starting Run: 02wkifji with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165329-02wkifji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-28
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/02wkifji
wandb:                                                                                
wandb: 🚀 View run prime-sweep-28 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/02wkifji
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165329-02wkifji/logs
wandb: Agent Starting Run: 3odsyrff with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165334-3odsyrff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-29
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3odsyrff
wandb:                                                                                
wandb: 🚀 View run usual-sweep-29 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3odsyrff
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165334-3odsyrff/logs
wandb: Agent Starting Run: ndisuiie with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165340-ndisuiie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-30
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ndisuiie
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run honest-sweep-30 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ndisuiie
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165340-ndisuiie/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8jdxen4q with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165355-8jdxen4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-31
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8jdxen4q
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run super-sweep-31 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8jdxen4q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165355-8jdxen4q/logs
wandb: Agent Starting Run: jccflr18 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165401-jccflr18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-32
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jccflr18
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run neat-sweep-32 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jccflr18
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165401-jccflr18/logs
wandb: Agent Starting Run: 2bu2w6e5 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165406-2bu2w6e5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-33
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2bu2w6e5
wandb:                                                                                
wandb: 🚀 View run true-sweep-33 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2bu2w6e5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165406-2bu2w6e5/logs
wandb: Agent Starting Run: yz6y99xe with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165412-yz6y99xe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-34
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yz6y99xe
wandb:                                                                                
wandb: 🚀 View run swift-sweep-34 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yz6y99xe
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165412-yz6y99xe/logs
wandb: Agent Starting Run: fo8mgqhf with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165417-fo8mgqhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-35
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fo8mgqhf
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (2 x 24). Kernel size: (3 x 7). Kernel size can't be greater than actual input size
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-35 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fo8mgqhf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165417-fo8mgqhf/logs
Run fo8mgqhf errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (2 x 24). Kernel size: (3 x 7). Kernel size can't be greater than actual input size

wandb: ERROR Run fo8mgqhf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
wandb: ERROR     return self._conv_forward(input, self.weight, self.bias)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
wandb: ERROR     return F.conv2d(input, weight, bias, self.stride,
wandb: ERROR RuntimeError: Calculated padded input size per channel: (2 x 24). Kernel size: (3 x 7). Kernel size can't be greater than actual input size
wandb: ERROR 
wandb: Agent Starting Run: 7hz14vla with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165423-7hz14vla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-36
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7hz14vla
wandb:                                                                                
wandb: 🚀 View run icy-sweep-36 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7hz14vla
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165423-7hz14vla/logs
wandb: Agent Starting Run: at3x02td with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165428-at3x02td
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-37
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/at3x02td
wandb:                                                                                
wandb: 🚀 View run dauntless-sweep-37 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/at3x02td
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165428-at3x02td/logs
wandb: Agent Starting Run: 5iknml3j with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165434-5iknml3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-38
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5iknml3j
wandb:                                                                                
wandb: 🚀 View run rural-sweep-38 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5iknml3j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165434-5iknml3j/logs
wandb: Agent Starting Run: 9c6by6dk with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165440-9c6by6dk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-39
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9c6by6dk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▂▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▂▁▁▁▁▁▁
wandb: validation_loss █▆▃▂▁▁▁▁▁▁
wandb: validation_rmse █▆▄▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 67.32294
wandb:      train_rmse 8.20506
wandb: validation_loss 254.06158
wandb: validation_rmse 15.93931
wandb: 
wandb: 🚀 View run astral-sweep-39 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9c6by6dk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165440-9c6by6dk/logs
wandb: Agent Starting Run: lx29wc0c with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165613-lx29wc0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-40
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lx29wc0c
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run rose-sweep-40 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lx29wc0c
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165613-lx29wc0c/logs
wandb: Agent Starting Run: qqhtjk1b with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165629-qqhtjk1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-41
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qqhtjk1b
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run neat-sweep-41 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qqhtjk1b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165629-qqhtjk1b/logs
wandb: Agent Starting Run: vu3cl212 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165634-vu3cl212
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-42
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vu3cl212
wandb:                                                                                
wandb: 🚀 View run different-sweep-42 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vu3cl212
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165634-vu3cl212/logs
wandb: Agent Starting Run: sbjxqtw1 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165640-sbjxqtw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-43
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sbjxqtw1
wandb:                                                                                
wandb: 🚀 View run mild-sweep-43 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sbjxqtw1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165640-sbjxqtw1/logs
wandb: Agent Starting Run: 3lgwng8p with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_165645-3lgwng8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-44
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3lgwng8p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▂▂▂▃▂▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▃▂▃▂▁▂▂▁▁▁▁▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 20.25182
wandb:      train_rmse 4.5002
wandb: validation_loss 9.83106
wandb: validation_rmse 3.13545
wandb: 
wandb: 🚀 View run vital-sweep-44 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3lgwng8p
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_165645-3lgwng8p/logs
wandb: Agent Starting Run: lom6p668 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170355-lom6p668
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-45
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lom6p668
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run eager-sweep-45 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lom6p668
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170355-lom6p668/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hw4b1rb9 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170410-hw4b1rb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-46
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hw4b1rb9
wandb:                                                                                
wandb: 🚀 View run pretty-sweep-46 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hw4b1rb9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170410-hw4b1rb9/logs
wandb: Agent Starting Run: 8r2wt88f with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170416-8r2wt88f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-47
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8r2wt88f
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▅▄▃▃▃▁▂▁
wandb:      train_rmse █▅▅▄▃▃▃▁▂▁
wandb: validation_loss █▅▆▇▇▅▅▄▁▅
wandb: validation_rmse █▅▆▇▇▅▅▄▁▅
wandb: 
wandb: Run summary:
wandb:      train_loss 905.02716
wandb:      train_rmse 30.08367
wandb: validation_loss 906.81763
wandb: validation_rmse 30.11341
wandb: 
wandb: 🚀 View run swift-sweep-47 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8r2wt88f
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170416-8r2wt88f/logs
wandb: Agent Starting Run: sdjp8jcw with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170559-sdjp8jcw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-48
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sdjp8jcw
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-48 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sdjp8jcw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170559-sdjp8jcw/logs
wandb: Agent Starting Run: vybty4fa with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170605-vybty4fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-49
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vybty4fa
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run stellar-sweep-49 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vybty4fa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170605-vybty4fa/logs
wandb: Agent Starting Run: v6afqxj6 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170610-v6afqxj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-50
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v6afqxj6
wandb:                                                                                
wandb: 🚀 View run clear-sweep-50 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v6afqxj6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170610-v6afqxj6/logs
wandb: Agent Starting Run: chdek3ld with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170616-chdek3ld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-51
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/chdek3ld
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x2x6). Calculated output size: (64x0x1). Output size is too small
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-51 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/chdek3ld
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170616-chdek3ld/logs
Run chdek3ld errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x2x6). Calculated output size: (64x0x1). Output size is too small

wandb: ERROR Run chdek3ld errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (64x2x6). Calculated output size: (64x0x1). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: t0yqda6d with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170621-t0yqda6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-52
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t0yqda6d
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run deep-sweep-52 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t0yqda6d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170621-t0yqda6d/logs
wandb: Agent Starting Run: mfl2e2qn with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170626-mfl2e2qn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-53
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mfl2e2qn
wandb:                                                                                
wandb: 🚀 View run comic-sweep-53 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mfl2e2qn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170626-mfl2e2qn/logs
wandb: Agent Starting Run: pfiz7v3l with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170632-pfiz7v3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-54
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pfiz7v3l
wandb:                                                                                
wandb: 🚀 View run scarlet-sweep-54 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pfiz7v3l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170632-pfiz7v3l/logs
wandb: Agent Starting Run: gztomudy with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170637-gztomudy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-55
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gztomudy
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-55 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gztomudy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170637-gztomudy/logs
wandb: Agent Starting Run: 6qt545my with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170643-6qt545my
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-56
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6qt545my
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run whole-sweep-56 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6qt545my
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170643-6qt545my/logs
wandb: Agent Starting Run: ntld21ls with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170648-ntld21ls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-57
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ntld21ls
wandb:                                                                                
wandb: 🚀 View run firm-sweep-57 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ntld21ls
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170648-ntld21ls/logs
wandb: Agent Starting Run: otudtfqm with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170654-otudtfqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-58
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/otudtfqm
wandb:                                                                                
wandb: 🚀 View run radiant-sweep-58 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/otudtfqm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170654-otudtfqm/logs
wandb: Agent Starting Run: jr6drqq4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170659-jr6drqq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-59
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jr6drqq4
wandb:                                                                                
wandb: 🚀 View run honest-sweep-59 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jr6drqq4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170659-jr6drqq4/logs
wandb: Agent Starting Run: rztp4uz8 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170704-rztp4uz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-60
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rztp4uz8
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-60 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rztp4uz8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170704-rztp4uz8/logs
wandb: Agent Starting Run: 3k5t8rbt with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170710-3k5t8rbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-61
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3k5t8rbt
wandb:                                                                                
wandb: 🚀 View run youthful-sweep-61 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3k5t8rbt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170710-3k5t8rbt/logs
wandb: Agent Starting Run: r13rnols with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170715-r13rnols
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-62
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r13rnols
wandb:                                                                                
wandb: 🚀 View run stilted-sweep-62 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r13rnols
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170715-r13rnols/logs
wandb: Agent Starting Run: gl17rnlo with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170721-gl17rnlo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-63
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gl17rnlo
wandb:                                                                                
wandb: 🚀 View run fine-sweep-63 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gl17rnlo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170721-gl17rnlo/logs
wandb: Agent Starting Run: 2wbuoqx7 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170726-2wbuoqx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-64
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2wbuoqx7
wandb:                                                                                
wandb: 🚀 View run fluent-sweep-64 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2wbuoqx7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170726-2wbuoqx7/logs
wandb: Agent Starting Run: au6v9m18 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170732-au6v9m18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-65
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/au6v9m18
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run twilight-sweep-65 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/au6v9m18
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170732-au6v9m18/logs
wandb: Agent Starting Run: qnecgkxh with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170737-qnecgkxh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-66
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qnecgkxh
wandb:                                                                                
wandb: 🚀 View run daily-sweep-66 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qnecgkxh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170737-qnecgkxh/logs
wandb: Agent Starting Run: wrdcb5cj with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170743-wrdcb5cj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-67
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wrdcb5cj
wandb:                                                                                
wandb: 🚀 View run fiery-sweep-67 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wrdcb5cj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170743-wrdcb5cj/logs
wandb: Agent Starting Run: wql25h61 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170748-wql25h61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-68
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wql25h61
wandb:                                                                                
wandb: 🚀 View run icy-sweep-68 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wql25h61
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170748-wql25h61/logs
wandb: Agent Starting Run: njpc3hmr with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170753-njpc3hmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-69
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/njpc3hmr
wandb:                                                                                
wandb: 🚀 View run drawn-sweep-69 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/njpc3hmr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170753-njpc3hmr/logs
wandb: Agent Starting Run: mhpmqydf with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170759-mhpmqydf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-70
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mhpmqydf
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-70 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mhpmqydf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170759-mhpmqydf/logs
wandb: Agent Starting Run: nr5cndzp with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170804-nr5cndzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-71
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nr5cndzp
wandb:                                                                                
wandb: 🚀 View run laced-sweep-71 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nr5cndzp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170804-nr5cndzp/logs
wandb: Agent Starting Run: frsbeho0 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170810-frsbeho0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-72
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/frsbeho0
wandb:                                                                                
wandb: 🚀 View run peachy-sweep-72 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/frsbeho0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170810-frsbeho0/logs
wandb: Agent Starting Run: tadusf8u with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170815-tadusf8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-73
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tadusf8u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▃▂▂▁▁
wandb:      train_rmse █▆▆▅▄▃▃▂▂▁
wandb: validation_loss █▆▅▅▄▃▃▂▁▁
wandb: validation_rmse █▆▆▅▄▃▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 392.08259
wandb:      train_rmse 19.80108
wandb: validation_loss 345.53703
wandb: validation_rmse 18.58863
wandb: 
wandb: 🚀 View run rose-sweep-73 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tadusf8u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170815-tadusf8u/logs
wandb: Agent Starting Run: tl16v5ly with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170949-tl16v5ly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-74
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tl16v5ly
wandb:                                                                                
wandb: 🚀 View run noble-sweep-74 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tl16v5ly
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170949-tl16v5ly/logs
wandb: Agent Starting Run: muj6768g with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_170956-muj6768g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-75
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/muj6768g
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb:      train_loss nan
wandb:      train_rmse nan
wandb: validation_loss nan
wandb: validation_rmse nan
wandb: 
wandb: 🚀 View run crisp-sweep-75 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/muj6768g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_170956-muj6768g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kztr19e7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171716-kztr19e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-76
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kztr19e7
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -32: [1, -32]
wandb:                                                                                
wandb: 🚀 View run solar-sweep-76 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kztr19e7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171716-kztr19e7/logs
Run kztr19e7 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -32: [1, -32]

wandb: ERROR Run kztr19e7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, 1))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -32: [1, -32]
wandb: ERROR 
wandb: Agent Starting Run: p415isvl with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171722-p415isvl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-77
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p415isvl
wandb:                                                                                
wandb: 🚀 View run golden-sweep-77 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p415isvl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171722-p415isvl/logs
wandb: Agent Starting Run: zbow22es with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171727-zbow22es
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-78
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zbow22es
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run playful-sweep-78 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zbow22es
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171727-zbow22es/logs
wandb: Agent Starting Run: kas1kb7g with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171733-kas1kb7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-79
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kas1kb7g
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run charmed-sweep-79 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kas1kb7g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171733-kas1kb7g/logs
wandb: Agent Starting Run: q0re3jid with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171738-q0re3jid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-80
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q0re3jid
wandb:                                                                                
wandb: 🚀 View run toasty-sweep-80 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q0re3jid
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171738-q0re3jid/logs
wandb: Agent Starting Run: y2krdg2t with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171744-y2krdg2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-81
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y2krdg2t
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run toasty-sweep-81 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y2krdg2t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171744-y2krdg2t/logs
Run y2krdg2t errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run y2krdg2t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: u032gyap with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_171749-u032gyap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-82
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u032gyap
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 11.04108
wandb:      train_rmse 3.32281
wandb: validation_loss 11.9951
wandb: validation_rmse 3.46339
wandb: 
wandb: 🚀 View run sweepy-sweep-82 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u032gyap
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_171749-u032gyap/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: o3rvzqln with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172510-o3rvzqln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-83
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o3rvzqln
wandb:                                                                                
wandb: 🚀 View run resilient-sweep-83 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o3rvzqln
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172510-o3rvzqln/logs
wandb: Agent Starting Run: g9cq8edn with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172515-g9cq8edn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-84
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g9cq8edn
wandb:                                                                                
wandb: 🚀 View run magic-sweep-84 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g9cq8edn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172515-g9cq8edn/logs
wandb: Agent Starting Run: 08xwx2v1 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172521-08xwx2v1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-85
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/08xwx2v1
wandb:                                                                                
wandb: 🚀 View run light-sweep-85 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/08xwx2v1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172521-08xwx2v1/logs
wandb: Agent Starting Run: dodvded0 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172528-dodvded0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-86
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dodvded0
wandb:                                                                                
wandb: 🚀 View run wild-sweep-86 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dodvded0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172528-dodvded0/logs
wandb: Agent Starting Run: 12bachha with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172533-12bachha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-87
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/12bachha
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run proud-sweep-87 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/12bachha
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172533-12bachha/logs
wandb: Agent Starting Run: g8m1qhvq with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172539-g8m1qhvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-88
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g8m1qhvq
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-88 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g8m1qhvq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172539-g8m1qhvq/logs
wandb: Agent Starting Run: m323k5xg with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172544-m323k5xg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-89
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m323k5xg
wandb:                                                                                
wandb: 🚀 View run deep-sweep-89 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m323k5xg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172544-m323k5xg/logs
wandb: Agent Starting Run: 8zyjz9c0 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172549-8zyjz9c0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-90
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8zyjz9c0
wandb:                                                                                
wandb: 🚀 View run volcanic-sweep-90 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8zyjz9c0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172549-8zyjz9c0/logs
wandb: Agent Starting Run: wu17i130 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172555-wu17i130
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-91
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wu17i130
wandb:                                                                                
wandb: 🚀 View run mild-sweep-91 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wu17i130
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172555-wu17i130/logs
wandb: Agent Starting Run: a2fpm9n4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172600-a2fpm9n4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-92
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a2fpm9n4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▃▂▁
wandb:      train_rmse █▇▆▅▅▄▄▃▂▁
wandb: validation_loss ██▇▅▄▂▄▂▁▂
wandb: validation_rmse ██▇▅▄▂▄▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 799.87147
wandb:      train_rmse 28.282
wandb: validation_loss 787.27975
wandb: validation_rmse 28.05851
wandb: 
wandb: 🚀 View run ethereal-sweep-92 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a2fpm9n4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172600-a2fpm9n4/logs
wandb: Agent Starting Run: 8tnss25b with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172734-8tnss25b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-93
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8tnss25b
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x2x25). Calculated output size: (16x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run silver-sweep-93 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8tnss25b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172734-8tnss25b/logs
Run 8tnss25b errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x2x25). Calculated output size: (16x0x6). Output size is too small

wandb: ERROR Run 8tnss25b errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (16x2x25). Calculated output size: (16x0x6). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: b1q69aan with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172739-b1q69aan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-94
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b1q69aan
wandb:                                                                                
wandb: 🚀 View run eager-sweep-94 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b1q69aan
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172739-b1q69aan/logs
wandb: Agent Starting Run: kad7jr6e with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172745-kad7jr6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-95
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kad7jr6e
wandb:                                                                                
wandb: 🚀 View run worthy-sweep-95 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kad7jr6e
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172745-kad7jr6e/logs
wandb: Agent Starting Run: tqaj9jmi with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172750-tqaj9jmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-96
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tqaj9jmi
wandb:                                                                                
wandb: 🚀 View run fanciful-sweep-96 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tqaj9jmi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172750-tqaj9jmi/logs
wandb: Agent Starting Run: 24dashgv with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172756-24dashgv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-97
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/24dashgv
wandb:                                                                                
wandb: 🚀 View run sweepy-sweep-97 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/24dashgv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172756-24dashgv/logs
wandb: Agent Starting Run: ybov6qhf with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172801-ybov6qhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-98
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ybov6qhf
wandb:                                                                                
wandb: 🚀 View run toasty-sweep-98 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ybov6qhf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172801-ybov6qhf/logs
wandb: Agent Starting Run: iz8r5wl8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172806-iz8r5wl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-99
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iz8r5wl8
wandb:                                                                                
wandb: 🚀 View run zesty-sweep-99 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iz8r5wl8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172806-iz8r5wl8/logs
wandb: Agent Starting Run: hdi8i38l with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172813-hdi8i38l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-100
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hdi8i38l
wandb:                                                                                
wandb: 🚀 View run chocolate-sweep-100 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hdi8i38l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172813-hdi8i38l/logs
wandb: Agent Starting Run: cgvzj3rr with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172819-cgvzj3rr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-101
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cgvzj3rr
wandb:                                                                                
wandb: 🚀 View run amber-sweep-101 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cgvzj3rr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172819-cgvzj3rr/logs
wandb: Agent Starting Run: jxwmsphv with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172824-jxwmsphv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-102
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxwmsphv
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run royal-sweep-102 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxwmsphv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172824-jxwmsphv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: j8bdk5zg with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_172840-j8bdk5zg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-103
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j8bdk5zg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▃▂▁▁▂▁▁▁▂
wandb: validation_rmse █▄▂▂▁▁▂▃▁▁▂▁▁▁▁▁▁▂▁▂▂▁▂▁▂▂▁▁▁▁▁▄▂▂▁▂▁▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 22.04048
wandb:      train_rmse 4.69473
wandb: validation_loss 11.03033
wandb: validation_rmse 3.32119
wandb: 
wandb: 🚀 View run valiant-sweep-103 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j8bdk5zg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_172840-j8bdk5zg/logs
wandb: Agent Starting Run: d4tgu7el with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173546-d4tgu7el
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-104
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d4tgu7el
wandb:                                                                                
wandb: 🚀 View run neat-sweep-104 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d4tgu7el
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173546-d4tgu7el/logs
wandb: Agent Starting Run: eui11jh1 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173552-eui11jh1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-105
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eui11jh1
wandb:                                                                                
wandb: 🚀 View run super-sweep-105 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eui11jh1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173552-eui11jh1/logs
wandb: Agent Starting Run: j7nur24k with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173557-j7nur24k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-106
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j7nur24k
wandb:                                                                                
wandb: 🚀 View run pious-sweep-106 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j7nur24k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173557-j7nur24k/logs
wandb: Agent Starting Run: dvmjb3pb with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173602-dvmjb3pb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-107
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dvmjb3pb
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-107 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dvmjb3pb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173602-dvmjb3pb/logs
wandb: Agent Starting Run: vd0w6574 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173608-vd0w6574
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-108
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vd0w6574
wandb:                                                                                
wandb: 🚀 View run deep-sweep-108 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vd0w6574
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173608-vd0w6574/logs
wandb: Agent Starting Run: g23guvzj with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173613-g23guvzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-109
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g23guvzj
wandb:                                                                                
wandb: 🚀 View run gentle-sweep-109 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g23guvzj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173613-g23guvzj/logs
wandb: Agent Starting Run: 5ccia1of with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173619-5ccia1of
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-110
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5ccia1of
wandb:                                                                                
wandb: 🚀 View run genial-sweep-110 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5ccia1of
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173619-5ccia1of/logs
wandb: Agent Starting Run: 501fvua3 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173624-501fvua3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-111
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/501fvua3
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run winter-sweep-111 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/501fvua3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173624-501fvua3/logs
wandb: Agent Starting Run: u7dfynws with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173629-u7dfynws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-112
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u7dfynws
wandb:                                                                                
wandb: 🚀 View run gentle-sweep-112 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u7dfynws
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173629-u7dfynws/logs
wandb: Agent Starting Run: b38h5dtl with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173635-b38h5dtl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-113
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b38h5dtl
wandb:                                                                                
wandb: 🚀 View run bright-sweep-113 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b38h5dtl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173635-b38h5dtl/logs
wandb: Agent Starting Run: rrloydlu with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173640-rrloydlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-114
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rrloydlu
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run restful-sweep-114 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rrloydlu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173640-rrloydlu/logs
wandb: Agent Starting Run: nwlcqyp5 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173645-nwlcqyp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-115
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nwlcqyp5
wandb:                                                                                
wandb: 🚀 View run still-sweep-115 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nwlcqyp5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173645-nwlcqyp5/logs
wandb: Agent Starting Run: 66luaviy with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173651-66luaviy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-116
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/66luaviy
wandb:                                                                                
wandb: 🚀 View run polar-sweep-116 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/66luaviy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173651-66luaviy/logs
wandb: Agent Starting Run: nce7syhp with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_173658-nce7syhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-117
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nce7syhp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▄▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 73.94972
wandb:      train_rmse 8.5994
wandb: validation_loss 38.38024
wandb: validation_rmse 6.19518
wandb: 
wandb: 🚀 View run sandy-sweep-117 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nce7syhp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_173658-nce7syhp/logs
wandb: Agent Starting Run: 6kcf8bhg with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174410-6kcf8bhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-118
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6kcf8bhg
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run pretty-sweep-118 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6kcf8bhg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174410-6kcf8bhg/logs
wandb: Agent Starting Run: 9vqbf20h with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174415-9vqbf20h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-119
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9vqbf20h
wandb:                                                                                
wandb: 🚀 View run upbeat-sweep-119 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9vqbf20h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174415-9vqbf20h/logs
wandb: Agent Starting Run: u6vslq6f with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174421-u6vslq6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-120
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u6vslq6f
wandb:                                                                                
wandb: 🚀 View run gallant-sweep-120 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u6vslq6f
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174421-u6vslq6f/logs
wandb: Agent Starting Run: lq5l3af1 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174428-lq5l3af1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-121
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lq5l3af1
wandb:                                                                                
wandb: 🚀 View run revived-sweep-121 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lq5l3af1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174428-lq5l3af1/logs
wandb: Agent Starting Run: mf0sk2l8 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174433-mf0sk2l8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-122
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mf0sk2l8
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run clean-sweep-122 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mf0sk2l8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174433-mf0sk2l8/logs
wandb: Agent Starting Run: ki3nskkt with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174439-ki3nskkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-123
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ki3nskkt
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run frosty-sweep-123 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ki3nskkt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174439-ki3nskkt/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: npu7ne2y with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174454-npu7ne2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-124
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/npu7ne2y
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run decent-sweep-124 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/npu7ne2y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174454-npu7ne2y/logs
wandb: Agent Starting Run: ojhogq5d with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174505-ojhogq5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-125
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ojhogq5d
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run peachy-sweep-125 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ojhogq5d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174505-ojhogq5d/logs
wandb: Agent Starting Run: yum36sgl with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174516-yum36sgl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-126
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yum36sgl
wandb:                                                                                
wandb: 🚀 View run worthy-sweep-126 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yum36sgl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174516-yum36sgl/logs
wandb: Agent Starting Run: ntepzlpa with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174521-ntepzlpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-127
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ntepzlpa
wandb:                                                                                
wandb: 🚀 View run firm-sweep-127 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ntepzlpa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174521-ntepzlpa/logs
wandb: Agent Starting Run: nhvss3cu with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174528-nhvss3cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-128
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nhvss3cu
wandb:                                                                                
wandb: 🚀 View run balmy-sweep-128 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nhvss3cu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174528-nhvss3cu/logs
wandb: Agent Starting Run: la2hfp8o with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174533-la2hfp8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-129
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/la2hfp8o
wandb:                                                                                
wandb: 🚀 View run denim-sweep-129 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/la2hfp8o
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174533-la2hfp8o/logs
wandb: Agent Starting Run: rg60o0zf with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174538-rg60o0zf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-130
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rg60o0zf
wandb:                                                                                
wandb: 🚀 View run polar-sweep-130 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rg60o0zf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174538-rg60o0zf/logs
wandb: Agent Starting Run: oyez8bzu with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174544-oyez8bzu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-131
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oyez8bzu
wandb:                                                                                
wandb: 🚀 View run misunderstood-sweep-131 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oyez8bzu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174544-oyez8bzu/logs
wandb: Agent Starting Run: k10yxez7 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174550-k10yxez7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-132
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k10yxez7
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [128, -256]
wandb:                                                                                
wandb: 🚀 View run wandering-sweep-132 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k10yxez7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174550-k10yxez7/logs
Run k10yxez7 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [128, -256]

wandb: ERROR Run k10yxez7 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -256: [128, -256]
wandb: ERROR 
wandb: Agent Starting Run: ur0foe3g with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174555-ur0foe3g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-133
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ur0foe3g
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run faithful-sweep-133 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ur0foe3g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174555-ur0foe3g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1yvc8lt1 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174610-1yvc8lt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-134
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1yvc8lt1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▂▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 65.90899
wandb:      train_rmse 8.11844
wandb: validation_loss 68.37921
wandb: validation_rmse 8.26917
wandb: 
wandb: 🚀 View run polar-sweep-134 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1yvc8lt1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174610-1yvc8lt1/logs
wandb: Agent Starting Run: 0zkk0sla with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174744-0zkk0sla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-135
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0zkk0sla
wandb:                                                                                
wandb: 🚀 View run deft-sweep-135 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0zkk0sla
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174744-0zkk0sla/logs
wandb: Agent Starting Run: 9kx8azu7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174749-9kx8azu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-136
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9kx8azu7
wandb:                                                                                
wandb: 🚀 View run soft-sweep-136 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9kx8azu7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174749-9kx8azu7/logs
wandb: Agent Starting Run: kl9eudnz with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174755-kl9eudnz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-137
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kl9eudnz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▅▃▄▃▁▁
wandb:      train_rmse █▆▆▅▅▃▄▃▁▁
wandb: validation_loss █▇▆▅▅▃▄▃▂▁
wandb: validation_rmse █▇▆▅▅▃▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 944.08544
wandb:      train_rmse 30.72597
wandb: validation_loss 939.61694
wandb: validation_rmse 30.65317
wandb: 
wandb: 🚀 View run sandy-sweep-137 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kl9eudnz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174755-kl9eudnz/logs
wandb: Agent Starting Run: 8jbab9k7 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174924-8jbab9k7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-138
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8jbab9k7
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run stellar-sweep-138 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8jbab9k7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174924-8jbab9k7/logs
wandb: Agent Starting Run: oqg0vm9q with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174934-oqg0vm9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-139
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oqg0vm9q
wandb:                                                                                
wandb: 🚀 View run worthy-sweep-139 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oqg0vm9q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174934-oqg0vm9q/logs
wandb: Agent Starting Run: t06p4yup with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_174940-t06p4yup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-140
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t06p4yup
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇▅▅▄▄▃▂▁
wandb:      train_rmse █▇▇▅▅▄▄▃▂▁
wandb: validation_loss █▇▆▆▅▄▄▃▂▁
wandb: validation_rmse █▇▆▆▅▄▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 901.93233
wandb:      train_rmse 30.03219
wandb: validation_loss 906.55072
wandb: validation_rmse 30.10898
wandb: 
wandb: 🚀 View run snowy-sweep-140 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t06p4yup
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_174940-t06p4yup/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0w79vizk with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175138-0w79vizk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-141
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0w79vizk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 68.25709
wandb:      train_rmse 8.26179
wandb: validation_loss 73.4693
wandb: validation_rmse 8.57142
wandb: 
wandb: 🚀 View run fresh-sweep-141 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0w79vizk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175138-0w79vizk/logs
wandb: Agent Starting Run: 3hs8xm2t with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175311-3hs8xm2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-142
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3hs8xm2t
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run pretty-sweep-142 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3hs8xm2t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175311-3hs8xm2t/logs
wandb: Agent Starting Run: pd9pu67a with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175327-pd9pu67a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-143
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pd9pu67a
wandb:                                                                                
wandb: 🚀 View run morning-sweep-143 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pd9pu67a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175327-pd9pu67a/logs
wandb: Agent Starting Run: 27klmoag with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175332-27klmoag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-144
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/27klmoag
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -128: [64, -128]
wandb:                                                                                
wandb: 🚀 View run vocal-sweep-144 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/27klmoag
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175332-27klmoag/logs
Run 27klmoag errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -128: [64, -128]

wandb: ERROR Run 27klmoag errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -128: [64, -128]
wandb: ERROR 
wandb: Agent Starting Run: xemr9glq with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175338-xemr9glq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-145
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xemr9glq
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run rural-sweep-145 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xemr9glq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175338-xemr9glq/logs
Run xemr9glq errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run xemr9glq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: jlk4n9q4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175343-jlk4n9q4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-146
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jlk4n9q4
wandb:                                                                                
wandb: 🚀 View run skilled-sweep-146 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jlk4n9q4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175343-jlk4n9q4/logs
wandb: Agent Starting Run: hkg3daon with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175348-hkg3daon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-147
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hkg3daon
wandb:                                                                                
wandb: 🚀 View run royal-sweep-147 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hkg3daon
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175348-hkg3daon/logs
wandb: Agent Starting Run: lsxbnozk with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175354-lsxbnozk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-148
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lsxbnozk
wandb:                                                                                
wandb: 🚀 View run glamorous-sweep-148 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lsxbnozk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175354-lsxbnozk/logs
wandb: Agent Starting Run: 7mwfi6no with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175359-7mwfi6no
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-149
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7mwfi6no
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run polar-sweep-149 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7mwfi6no
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175359-7mwfi6no/logs
Run 7mwfi6no errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 7mwfi6no errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 7i8sqgaj with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175404-7i8sqgaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-150
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7i8sqgaj
wandb:                                                                                
wandb: 🚀 View run scarlet-sweep-150 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7i8sqgaj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175404-7i8sqgaj/logs
wandb: Agent Starting Run: i2ultfv9 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175410-i2ultfv9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-151
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i2ultfv9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇▆▅▄▃▃▂▁
wandb:      train_rmse █▇▇▆▅▅▄▃▂▁
wandb: validation_loss ██▇▇▇▆▅▃▃▁
wandb: validation_rmse ██▇▇▇▆▅▄▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 507.90115
wandb:      train_rmse 22.53666
wandb: validation_loss 754.90073
wandb: validation_rmse 27.47546
wandb: 
wandb: 🚀 View run avid-sweep-151 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i2ultfv9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175410-i2ultfv9/logs
wandb: Agent Starting Run: 34ht62a1 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175544-34ht62a1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-152
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/34ht62a1
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-152 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/34ht62a1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175544-34ht62a1/logs
wandb: Agent Starting Run: ghgfk0rk with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175549-ghgfk0rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-153
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ghgfk0rk
wandb:                                                                                
wandb: 🚀 View run drawn-sweep-153 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ghgfk0rk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175549-ghgfk0rk/logs
wandb: Agent Starting Run: xe07hj3a with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175554-xe07hj3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-154
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xe07hj3a
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run generous-sweep-154 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xe07hj3a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175554-xe07hj3a/logs
wandb: Agent Starting Run: jkbzp9sv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175600-jkbzp9sv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-155
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jkbzp9sv
wandb:                                                                                
wandb: 🚀 View run lemon-sweep-155 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jkbzp9sv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175600-jkbzp9sv/logs
wandb: Agent Starting Run: 05qbkl81 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175605-05qbkl81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-156
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/05qbkl81
wandb:                                                                                
wandb: 🚀 View run clear-sweep-156 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/05qbkl81
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175605-05qbkl81/logs
wandb: Agent Starting Run: nqm22x5d with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175610-nqm22x5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-157
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nqm22x5d
wandb:                                                                                
wandb: 🚀 View run different-sweep-157 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nqm22x5d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175610-nqm22x5d/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sog1mwd0 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175625-sog1mwd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-158
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sog1mwd0
wandb:                                                                                
wandb: 🚀 View run playful-sweep-158 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sog1mwd0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175625-sog1mwd0/logs
wandb: Agent Starting Run: eiuo9ovh with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175633-eiuo9ovh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-159
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eiuo9ovh
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-159 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eiuo9ovh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175633-eiuo9ovh/logs
wandb: Agent Starting Run: mb1macoj with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175639-mb1macoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-160
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mb1macoj
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run olive-sweep-160 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mb1macoj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175639-mb1macoj/logs
Run mb1macoj errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run mb1macoj errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: ii1ecq0r with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175644-ii1ecq0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-161
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ii1ecq0r
wandb:                                                                                
wandb: 🚀 View run clear-sweep-161 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ii1ecq0r
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175644-ii1ecq0r/logs
wandb: Agent Starting Run: uknjx1w8 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175649-uknjx1w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-162
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uknjx1w8
wandb:                                                                                
wandb: 🚀 View run serene-sweep-162 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uknjx1w8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175649-uknjx1w8/logs
wandb: Agent Starting Run: ws5w9aoi with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_175655-ws5w9aoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-163
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ws5w9aoi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▁▁▁▂▂▂▁▁▁▂▁▂▁▁▁▁▁▁▁▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 3.4857
wandb:      train_rmse 1.867
wandb: validation_loss 39.63396
wandb: validation_rmse 6.29555
wandb: 
wandb: 🚀 View run serene-sweep-163 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ws5w9aoi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_175655-ws5w9aoi/logs
wandb: Agent Starting Run: tswbnurt with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180410-tswbnurt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-164
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tswbnurt
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run generous-sweep-164 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tswbnurt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180410-tswbnurt/logs
Run tswbnurt errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run tswbnurt errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: vv36g5c5 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180416-vv36g5c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-165
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vv36g5c5
wandb:                                                                                
wandb: 🚀 View run honest-sweep-165 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vv36g5c5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180416-vv36g5c5/logs
wandb: Agent Starting Run: l84aayw1 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180421-l84aayw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-166
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l84aayw1
wandb:                                                                                
wandb: 🚀 View run flowing-sweep-166 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l84aayw1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180421-l84aayw1/logs
wandb: Agent Starting Run: fbs2563m with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180427-fbs2563m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-167
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fbs2563m
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run super-sweep-167 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fbs2563m
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180427-fbs2563m/logs
wandb: Agent Starting Run: oqchldf9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180433-oqchldf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-168
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oqchldf9
wandb:                                                                                
wandb: 🚀 View run stellar-sweep-168 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oqchldf9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180433-oqchldf9/logs
wandb: Agent Starting Run: cwl7tk21 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180438-cwl7tk21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-169
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cwl7tk21
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run autumn-sweep-169 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cwl7tk21
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180438-cwl7tk21/logs
wandb: Agent Starting Run: 2bn2w2yy with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180449-2bn2w2yy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-170
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2bn2w2yy
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▁▂▇█▁▄▂▆▁▃
wandb:      train_rmse ▁▂▇█▁▄▂▆▁▃
wandb: validation_loss ▂▁▅▇██████
wandb: validation_rmse ▂▁▅▇██████
wandb: 
wandb: Run summary:
wandb:      train_loss 983.06817
wandb:      train_rmse 31.35392
wandb: validation_loss 978.02084
wandb: validation_rmse 31.27332
wandb: 
wandb: 🚀 View run true-sweep-170 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2bn2w2yy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180449-2bn2w2yy/logs
wandb: Agent Starting Run: ni0vxq8u with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_180622-ni0vxq8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-171
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ni0vxq8u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▃▃▂▁▂▂▁▂▂▂▂▂▁▁▁▂▁▁▁▃▂▁▁▁▃▁▁▁▂▂▁▂▁▂▂▁▂▁
wandb: validation_rmse █▂▁▄▄▄▄▃▂▄▄▃▃▃▂▂▁▄▁▁▂▄▃▂▁▂▄▂▂▂▃▃▂▃▂▄▃▂▃▂
wandb: 
wandb: Run summary:
wandb:      train_loss 14.82254
wandb:      train_rmse 3.85001
wandb: validation_loss 12.86062
wandb: validation_rmse 3.58617
wandb: 
wandb: 🚀 View run dashing-sweep-171 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ni0vxq8u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180622-ni0vxq8u/logs
wandb: Agent Starting Run: f3ov0uil with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_181329-f3ov0uil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-172
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f3ov0uil
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▇▆▅▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▃▂█▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse ▆▄█▂▃▃▂▁▂▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 39.31582
wandb:      train_rmse 6.27023
wandb: validation_loss 15.23448
wandb: validation_rmse 3.90314
wandb: 
wandb: 🚀 View run fast-sweep-172 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f3ov0uil
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_181329-f3ov0uil/logs
wandb: Agent Starting Run: ptaiqpd8 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_182138-ptaiqpd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-173
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ptaiqpd8
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.008 MB of 0.008 MB uploadedwandb: | 0.008 MB of 0.008 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▅▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▂▃▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 32.25771
wandb:      train_rmse 5.67959
wandb: validation_loss 9.52657
wandb: validation_rmse 3.08651
wandb: 
wandb: 🚀 View run deft-sweep-173 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ptaiqpd8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_182138-ptaiqpd8/logs
wandb: Agent Starting Run: hmjzbwkn with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_182848-hmjzbwkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-174
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hmjzbwkn
wandb:                                                                                
wandb: 🚀 View run decent-sweep-174 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hmjzbwkn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_182848-hmjzbwkn/logs
wandb: Agent Starting Run: 0fqaayug with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_182853-0fqaayug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-175
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0fqaayug
wandb:                                                                                
wandb: 🚀 View run polished-sweep-175 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0fqaayug
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_182853-0fqaayug/logs
wandb: Agent Starting Run: orswgvq9 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_182858-orswgvq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-176
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/orswgvq9
wandb:                                                                                
wandb: 🚀 View run desert-sweep-176 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/orswgvq9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_182858-orswgvq9/logs
wandb: Agent Starting Run: zb5arhsc with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_182904-zb5arhsc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-177
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zb5arhsc
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.008 MB of 0.008 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 32.36751
wandb:      train_rmse 5.68925
wandb: validation_loss 10.94058
wandb: validation_rmse 3.30765
wandb: 
wandb: 🚀 View run colorful-sweep-177 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zb5arhsc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_182904-zb5arhsc/logs
wandb: Agent Starting Run: mkpqptni with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_183615-mkpqptni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-178
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mkpqptni
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 64.27722
wandb:      train_rmse 8.01731
wandb: validation_loss 68.85061
wandb: validation_rmse 8.29763
wandb: 
wandb: 🚀 View run sweepy-sweep-178 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mkpqptni
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_183615-mkpqptni/logs
wandb: Agent Starting Run: foer821d with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_183744-foer821d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-179
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/foer821d
wandb:                                                                                
wandb: 🚀 View run eternal-sweep-179 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/foer821d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_183744-foer821d/logs
wandb: Agent Starting Run: ih8jmqd6 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_183749-ih8jmqd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-180
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ih8jmqd6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 16.10227
wandb:      train_rmse 4.01276
wandb: validation_loss 6.45194
wandb: validation_rmse 2.54007
wandb: 
wandb: 🚀 View run solar-sweep-180 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ih8jmqd6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_183749-ih8jmqd6/logs
wandb: Agent Starting Run: kales95g with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_184459-kales95g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-181
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kales95g
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x1x24). Calculated output size: (16x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run fallen-sweep-181 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kales95g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_184459-kales95g/logs
Run kales95g errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x1x24). Calculated output size: (16x0x6). Output size is too small

wandb: ERROR Run kales95g errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (16x1x24). Calculated output size: (16x0x6). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: dau0tquv with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_184504-dau0tquv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-182
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dau0tquv
wandb:                                                                                
wandb: 🚀 View run legendary-sweep-182 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dau0tquv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_184504-dau0tquv/logs
wandb: Agent Starting Run: 3vh9rslj with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_184509-3vh9rslj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-183
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3vh9rslj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.76767
wandb:      train_rmse 0.87617
wandb: validation_loss 9.54387
wandb: validation_rmse 3.08932
wandb: 
wandb: 🚀 View run splendid-sweep-183 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3vh9rslj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_184509-3vh9rslj/logs
wandb: Agent Starting Run: jvq4krqp with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185240-jvq4krqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-184
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jvq4krqp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▁▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss █▇▆▅▄▄▃▂▂▁
wandb: validation_rmse █▇▆▅▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 532.83191
wandb:      train_rmse 23.08315
wandb: validation_loss 506.95239
wandb: validation_rmse 22.5156
wandb: 
wandb: 🚀 View run autumn-sweep-184 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jvq4krqp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185240-jvq4krqp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iahv3x0q with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185419-iahv3x0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-185
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iahv3x0q
wandb:                                                                                
wandb: 🚀 View run polished-sweep-185 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iahv3x0q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185419-iahv3x0q/logs
wandb: Agent Starting Run: 0qzq6p2o with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185425-0qzq6p2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-186
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0qzq6p2o
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▁▃▃▇▆▃▆▂
wandb:      train_rmse █▅▁▃▃▇▆▃▆▂
wandb: validation_loss █▂▃▂▃▄▃▃▃▁
wandb: validation_rmse █▂▃▂▃▄▃▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 984.54608
wandb:      train_rmse 31.37748
wandb: validation_loss 950.88019
wandb: validation_rmse 30.83635
wandb: 
wandb: 🚀 View run swept-sweep-186 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0qzq6p2o
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185425-0qzq6p2o/logs
wandb: Agent Starting Run: 2geauze4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185553-2geauze4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-187
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2geauze4
wandb:                                                                                
wandb: 🚀 View run glad-sweep-187 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2geauze4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185553-2geauze4/logs
wandb: Agent Starting Run: rz61mu34 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185559-rz61mu34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-188
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rz61mu34
wandb:                                                                                
wandb: 🚀 View run gallant-sweep-188 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rz61mu34
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185559-rz61mu34/logs
wandb: Agent Starting Run: cbs9zv15 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185604-cbs9zv15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-189
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cbs9zv15
wandb:                                                                                
wandb: 🚀 View run ruby-sweep-189 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cbs9zv15
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185604-cbs9zv15/logs
wandb: Agent Starting Run: 841pjqa4 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185610-841pjqa4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-190
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/841pjqa4
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run grateful-sweep-190 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/841pjqa4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185610-841pjqa4/logs
wandb: Agent Starting Run: 2r80kki9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185615-2r80kki9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-191
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2r80kki9
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run divine-sweep-191 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2r80kki9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185615-2r80kki9/logs
wandb: Agent Starting Run: roak5non with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185621-roak5non
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-192
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/roak5non
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-192 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/roak5non
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185621-roak5non/logs
wandb: Agent Starting Run: 41lwxr4n with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185626-41lwxr4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-193
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/41lwxr4n
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run frosty-sweep-193 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/41lwxr4n
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185626-41lwxr4n/logs
wandb: Agent Starting Run: jtj0yf67 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185631-jtj0yf67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-194
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jtj0yf67
wandb:                                                                                
wandb: 🚀 View run vibrant-sweep-194 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jtj0yf67
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185631-jtj0yf67/logs
wandb: Agent Starting Run: lfwojj6r with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185636-lfwojj6r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-195
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lfwojj6r
wandb:                                                                                
wandb: 🚀 View run easy-sweep-195 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lfwojj6r
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185636-lfwojj6r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0n12erfu with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185652-0n12erfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-196
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0n12erfu
wandb:                                                                                
wandb: 🚀 View run rosy-sweep-196 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0n12erfu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185652-0n12erfu/logs
wandb: Agent Starting Run: i9txq7rd with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185657-i9txq7rd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-197
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i9txq7rd
wandb:                                                                                
wandb: 🚀 View run confused-sweep-197 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i9txq7rd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185657-i9txq7rd/logs
wandb: Agent Starting Run: 3cb4nbcc with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185703-3cb4nbcc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-198
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3cb4nbcc
wandb:                                                                                
wandb: 🚀 View run firm-sweep-198 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3cb4nbcc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185703-3cb4nbcc/logs
wandb: Agent Starting Run: y1ecailq with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185708-y1ecailq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-199
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y1ecailq
wandb:                                                                                
wandb: 🚀 View run clear-sweep-199 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y1ecailq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185708-y1ecailq/logs
wandb: Sweep Agent: Waiting for job.
500 response executing GraphQL.
{"error":"context deadline exceeded"}
wandb: Job received.
wandb: Agent Starting Run: 1ng0ugi7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185827-1ng0ugi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-200
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1ng0ugi7
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run pious-sweep-200 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1ng0ugi7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185827-1ng0ugi7/logs
wandb: Agent Starting Run: f6j712e3 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185837-f6j712e3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-201
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f6j712e3
wandb:                                                                                
wandb: 🚀 View run devout-sweep-201 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f6j712e3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185837-f6j712e3/logs
wandb: Agent Starting Run: 3tns5g5w with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185843-3tns5g5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-202
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3tns5g5w
wandb:                                                                                
wandb: 🚀 View run cool-sweep-202 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3tns5g5w
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185843-3tns5g5w/logs
wandb: Agent Starting Run: 4jeh79j1 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185848-4jeh79j1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-203
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4jeh79j1
wandb:                                                                                
wandb: 🚀 View run fanciful-sweep-203 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4jeh79j1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185848-4jeh79j1/logs
wandb: Agent Starting Run: 4wyq9tor with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185854-4wyq9tor
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-204
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4wyq9tor
wandb:                                                                                
wandb: 🚀 View run smart-sweep-204 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4wyq9tor
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185854-4wyq9tor/logs
wandb: Agent Starting Run: a8wh8irr with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185859-a8wh8irr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-205
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a8wh8irr
wandb:                                                                                
wandb: 🚀 View run fast-sweep-205 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a8wh8irr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185859-a8wh8irr/logs
wandb: Agent Starting Run: ugbrxxaq with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185904-ugbrxxaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-206
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ugbrxxaq
wandb:                                                                                
wandb: 🚀 View run lively-sweep-206 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ugbrxxaq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185904-ugbrxxaq/logs
wandb: Agent Starting Run: d26vacyo with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185910-d26vacyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-207
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d26vacyo
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -768: [128, -768]
wandb:                                                                                
wandb: 🚀 View run avid-sweep-207 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d26vacyo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185910-d26vacyo/logs
Run d26vacyo errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -768: [128, -768]

wandb: ERROR Run d26vacyo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -768: [128, -768]
wandb: ERROR 
wandb: Agent Starting Run: fqeb7arn with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185915-fqeb7arn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-208
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fqeb7arn
wandb:                                                                                
wandb: 🚀 View run hopeful-sweep-208 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fqeb7arn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185915-fqeb7arn/logs
wandb: Agent Starting Run: fw216nm6 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_185920-fw216nm6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-209
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fw216nm6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▃▃▃▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 6.03364
wandb:      train_rmse 2.45635
wandb: validation_loss 8.39713
wandb: validation_rmse 2.89778
wandb: 
wandb: 🚀 View run eager-sweep-209 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fw216nm6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_185920-fw216nm6/logs
wandb: Agent Starting Run: 9tor0ell with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_190625-9tor0ell
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-210
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9tor0ell
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▅▇█▅▅▅▅▃▄▃▄▃▂▂▄▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▇▇▇▇▅▆▄▄▅▃▂▅▃▂▃▂▂▃▂▂▂▁▂▂▁▁▂▁▁▁▁▂▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 13.44806
wandb:      train_rmse 3.66716
wandb: validation_loss 13.26742
wandb: validation_rmse 3.64245
wandb: 
wandb: 🚀 View run vague-sweep-210 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9tor0ell
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_190625-9tor0ell/logs
wandb: Agent Starting Run: dhlovkk4 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191330-dhlovkk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-211
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dhlovkk4
wandb:                                                                                
wandb: 🚀 View run polar-sweep-211 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dhlovkk4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191330-dhlovkk4/logs
wandb: Agent Starting Run: fkv7j01b with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191335-fkv7j01b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-212
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fkv7j01b
wandb:                                                                                
wandb: 🚀 View run frosty-sweep-212 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fkv7j01b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191335-fkv7j01b/logs
wandb: Agent Starting Run: c7z6wpx7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191340-c7z6wpx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-213
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c7z6wpx7
wandb:                                                                                
wandb: 🚀 View run dashing-sweep-213 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c7z6wpx7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191340-c7z6wpx7/logs
wandb: Agent Starting Run: p85xf2vz with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191346-p85xf2vz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-214
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p85xf2vz
wandb:                                                                                
wandb: 🚀 View run iconic-sweep-214 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p85xf2vz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191346-p85xf2vz/logs
wandb: Agent Starting Run: 505qjfgp with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191353-505qjfgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-215
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/505qjfgp
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run spring-sweep-215 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/505qjfgp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191353-505qjfgp/logs
wandb: Agent Starting Run: k5r6ff4v with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191402-k5r6ff4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-216
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k5r6ff4v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▂▂▁
wandb:      train_rmse █▇▆▅▅▄▃▂▂▁
wandb: validation_loss █▇▆▅▅▄▃▂▂▁
wandb: validation_rmse █▇▆▆▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 580.64639
wandb:      train_rmse 24.09661
wandb: validation_loss 563.00595
wandb: validation_rmse 23.72775
wandb: 
wandb: 🚀 View run smooth-sweep-216 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k5r6ff4v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191402-k5r6ff4v/logs
wandb: Agent Starting Run: k39q1r1f with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191535-k39q1r1f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-217
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k39q1r1f
wandb:                                                                                
wandb: 🚀 View run floral-sweep-217 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k39q1r1f
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191535-k39q1r1f/logs
wandb: Agent Starting Run: vmnnd4v9 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191540-vmnnd4v9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-218
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vmnnd4v9
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-218 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vmnnd4v9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191540-vmnnd4v9/logs
wandb: Agent Starting Run: slrd1cuj with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_191546-slrd1cuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-219
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/slrd1cuj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▂▂▁▁▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 3.9663
wandb:      train_rmse 1.99156
wandb: validation_loss 22.04646
wandb: validation_rmse 4.69537
wandb: 
wandb: 🚀 View run serene-sweep-219 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/slrd1cuj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191546-slrd1cuj/logs
wandb: Agent Starting Run: ufwomhou with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_192250-ufwomhou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-220
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ufwomhou
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-220 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ufwomhou
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_192250-ufwomhou/logs
wandb: Agent Starting Run: 5w19cwd2 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_192256-5w19cwd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-221
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5w19cwd2
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -448: [64, -448]
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 🚀 View run quiet-sweep-221 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5w19cwd2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_192256-5w19cwd2/logs
Run 5w19cwd2 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -448: [64, -448]

wandb: ERROR Run 5w19cwd2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -448: [64, -448]
wandb: ERROR 
wandb: Agent Starting Run: 0ay0kqyv with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_192307-0ay0kqyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-222
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ay0kqyv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▁▂▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:      train_rmse █▆▅▅▄▄▄▄▄▄▄▂▂▃▂▃▂▃▃▂▃▂▃▂▃▂▂▂▂▂▂▃▂▂▂▂▂▁▂▁
wandb: validation_loss ▇█▇▆▇▃▄▄▅▃▅▃▄▄▃▄▂▄▃▃▃▂▅▂▂▃▂▃▃▁▃▂▂▁▃▁▃▂▂▃
wandb: validation_rmse ▆█▇▆▅▅▃▄▄▅▃▄▃▄▃▄▃▄▃▃▄▂▅▂▂▃▂▃▃▁▂▂▁▃▃▃▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 58.19197
wandb:      train_rmse 7.62837
wandb: validation_loss 27.14804
wandb: validation_rmse 5.21038
wandb: 
wandb: 🚀 View run elated-sweep-222 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ay0kqyv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_192307-0ay0kqyv/logs
wandb: Agent Starting Run: zgf1xs8v with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193010-zgf1xs8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-223
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zgf1xs8v
wandb:                                                                                
wandb: 🚀 View run playful-sweep-223 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zgf1xs8v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193010-zgf1xs8v/logs
wandb: Agent Starting Run: 8wno2uj4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193015-8wno2uj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-224
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8wno2uj4
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▅▄▃▂▂▁
wandb:      train_rmse █▇▇▆▅▄▃▂▂▁
wandb: validation_loss █▇▇▆▅▄▃▂▂▁
wandb: validation_rmse █▇▇▆▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 843.023
wandb:      train_rmse 29.03486
wandb: validation_loss 826.68759
wandb: validation_rmse 28.75218
wandb: 
wandb: 🚀 View run stellar-sweep-224 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8wno2uj4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193015-8wno2uj4/logs
wandb: Agent Starting Run: 6kqg9g4u with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193148-6kqg9g4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-225
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6kqg9g4u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▅▄▄▄▃▂▆▁
wandb: validation_rmse █▆▅▄▄▄▃▂▆▁
wandb: 
wandb: Run summary:
wandb:      train_loss 64.19825
wandb:      train_rmse 8.01238
wandb: validation_loss 67.2972
wandb: validation_rmse 8.20349
wandb: 
wandb: 🚀 View run legendary-sweep-225 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6kqg9g4u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193148-6kqg9g4u/logs
wandb: Agent Starting Run: 0m4nk6yt with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193316-0m4nk6yt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-226
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0m4nk6yt
wandb:                                                                                
wandb: 🚀 View run sleek-sweep-226 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0m4nk6yt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193316-0m4nk6yt/logs
wandb: Agent Starting Run: mijhlkjw with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193322-mijhlkjw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-227
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mijhlkjw
wandb:                                                                                
wandb: 🚀 View run eternal-sweep-227 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mijhlkjw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193322-mijhlkjw/logs
wandb: Agent Starting Run: heb0izkm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193327-heb0izkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-228
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/heb0izkm
wandb:                                                                                
wandb: 🚀 View run tough-sweep-228 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/heb0izkm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193327-heb0izkm/logs
wandb: Agent Starting Run: yies5q7t with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193332-yies5q7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-229
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yies5q7t
wandb:                                                                                
wandb: 🚀 View run peachy-sweep-229 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yies5q7t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193332-yies5q7t/logs
wandb: Agent Starting Run: b3i0nmrd with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193338-b3i0nmrd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-230
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b3i0nmrd
wandb:                                                                                
wandb: 🚀 View run graceful-sweep-230 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b3i0nmrd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193338-b3i0nmrd/logs
wandb: Agent Starting Run: dythl4za with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193343-dythl4za
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-231
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dythl4za
wandb:                                                                                
wandb: 🚀 View run young-sweep-231 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dythl4za
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193343-dythl4za/logs
wandb: Agent Starting Run: 34ugim61 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_193349-34ugim61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-232
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/34ugim61
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▄▁▂▂▂▂▂▁▂▁▂▁▁▁▂▂▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 20.382
wandb:      train_rmse 4.51464
wandb: validation_loss 8.57239
wandb: validation_rmse 2.92786
wandb: 
wandb: 🚀 View run revived-sweep-232 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/34ugim61
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193349-34ugim61/logs
wandb: Agent Starting Run: zr5qpxwj with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194059-zr5qpxwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-233
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zr5qpxwj
wandb:                                                                                
wandb: 🚀 View run vague-sweep-233 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zr5qpxwj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194059-zr5qpxwj/logs
wandb: Agent Starting Run: x7st12u2 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194104-x7st12u2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-234
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x7st12u2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▆▄▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▅▂▂▂▁▁▁▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 51.33015
wandb:      train_rmse 7.16451
wandb: validation_loss 11.7292
wandb: validation_rmse 3.42479
wandb: 
wandb: 🚀 View run rose-sweep-234 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x7st12u2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194104-x7st12u2/logs
wandb: Agent Starting Run: 1n2eg4vw with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194815-1n2eg4vw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-235
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1n2eg4vw
wandb:                                                                                
wandb: 🚀 View run dark-sweep-235 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1n2eg4vw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194815-1n2eg4vw/logs
wandb: Agent Starting Run: gb5k0rih with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194821-gb5k0rih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-236
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gb5k0rih
wandb:                                                                                
wandb: 🚀 View run fanciful-sweep-236 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gb5k0rih
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194821-gb5k0rih/logs
wandb: Agent Starting Run: 58n2a090 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194826-58n2a090
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-237
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/58n2a090
wandb:                                                                                
wandb: 🚀 View run faithful-sweep-237 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/58n2a090
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194826-58n2a090/logs
wandb: Agent Starting Run: u7tplh30 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194831-u7tplh30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-238
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u7tplh30
wandb:                                                                                
wandb: 🚀 View run crisp-sweep-238 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u7tplh30
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194831-u7tplh30/logs
wandb: Agent Starting Run: lozhhcxp with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194837-lozhhcxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-239
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lozhhcxp
wandb:                                                                                
wandb: 🚀 View run golden-sweep-239 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lozhhcxp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194837-lozhhcxp/logs
wandb: Agent Starting Run: krx6gem8 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194842-krx6gem8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-240
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/krx6gem8
wandb:                                                                                
wandb: 🚀 View run young-sweep-240 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/krx6gem8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194842-krx6gem8/logs
wandb: Agent Starting Run: b6ojhezj with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194847-b6ojhezj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-241
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b6ojhezj
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run volcanic-sweep-241 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b6ojhezj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194847-b6ojhezj/logs
wandb: Agent Starting Run: wtkbgf4i with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_194853-wtkbgf4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-242
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wtkbgf4i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▅▄▅▂▁▁
wandb:      train_rmse █▇▆▆▅▄▅▂▁▁
wandb: validation_loss █▆▆▅▄▄▃▃▁▁
wandb: validation_rmse █▆▆▅▄▄▃▃▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 831.7384
wandb:      train_rmse 28.83988
wandb: validation_loss 833.79233
wandb: validation_rmse 28.87546
wandb: 
wandb: 🚀 View run dashing-sweep-242 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wtkbgf4i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194853-wtkbgf4i/logs
wandb: Agent Starting Run: 4z9fp3nq with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195026-4z9fp3nq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-243
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4z9fp3nq
wandb:                                                                                
wandb: 🚀 View run jumping-sweep-243 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4z9fp3nq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195026-4z9fp3nq/logs
wandb: Agent Starting Run: raiw6pl5 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195031-raiw6pl5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-244
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/raiw6pl5
wandb:                                                                                
wandb: 🚀 View run dazzling-sweep-244 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/raiw6pl5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195031-raiw6pl5/logs
wandb: Agent Starting Run: schmxeln with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195037-schmxeln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-245
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/schmxeln
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-245 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/schmxeln
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195037-schmxeln/logs
wandb: Agent Starting Run: 98lrdldo with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195042-98lrdldo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-246
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/98lrdldo
wandb:                                                                                
wandb: 🚀 View run skilled-sweep-246 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/98lrdldo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195042-98lrdldo/logs
wandb: Agent Starting Run: 28rn61ul with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195047-28rn61ul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-247
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/28rn61ul
wandb:                                                                                
wandb: 🚀 View run lunar-sweep-247 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/28rn61ul
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195047-28rn61ul/logs
wandb: Agent Starting Run: cy4s1tgs with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195053-cy4s1tgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-248
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cy4s1tgs
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run classic-sweep-248 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cy4s1tgs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195053-cy4s1tgs/logs
wandb: Agent Starting Run: f4b67u5x with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195058-f4b67u5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-249
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f4b67u5x
wandb:                                                                                
wandb: 🚀 View run eager-sweep-249 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f4b67u5x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195058-f4b67u5x/logs
wandb: Agent Starting Run: 7vdqah05 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195104-7vdqah05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-250
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7vdqah05
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▇▄▃▁▂▃▅▁
wandb:      train_rmse █▄▇▄▃▁▂▃▅▁
wandb: validation_loss █▇▆▆▅▄▃▃▂▁
wandb: validation_rmse █▇▆▆▅▄▃▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 1030.40053
wandb:      train_rmse 32.09985
wandb: validation_loss 1013.10718
wandb: validation_rmse 31.82934
wandb: 
wandb: 🚀 View run floral-sweep-250 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7vdqah05
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195104-7vdqah05/logs
wandb: Agent Starting Run: ebcswhlp with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195237-ebcswhlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-251
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ebcswhlp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 3.82872
wandb:      train_rmse 1.95671
wandb: validation_loss 8.05385
wandb: validation_rmse 2.83793
wandb: 
wandb: 🚀 View run ruby-sweep-251 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ebcswhlp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195237-ebcswhlp/logs
wandb: Agent Starting Run: laagzk1k with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_195956-laagzk1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-252
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/laagzk1k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▂▂▁
wandb:      train_rmse █▇▆▅▅▄▃▂▂▁
wandb: validation_loss █▇▆▅▅▄▃▃▂▁
wandb: validation_rmse █▇▆▆▅▄▃▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 864.17605
wandb:      train_rmse 29.39687
wandb: validation_loss 858.52319
wandb: validation_rmse 29.30057
wandb: 
wandb: 🚀 View run true-sweep-252 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/laagzk1k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_195956-laagzk1k/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a1v0eti3 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200235-a1v0eti3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-253
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a1v0eti3
wandb:                                                                                
wandb: 🚀 View run legendary-sweep-253 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a1v0eti3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200235-a1v0eti3/logs
wandb: Agent Starting Run: c8v6ehkz with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200241-c8v6ehkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-254
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c8v6ehkz
wandb:                                                                                
wandb: 🚀 View run woven-sweep-254 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c8v6ehkz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200241-c8v6ehkz/logs
wandb: Agent Starting Run: 36sgehlt with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200247-36sgehlt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-255
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/36sgehlt
wandb:                                                                                
wandb: 🚀 View run efficient-sweep-255 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/36sgehlt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200247-36sgehlt/logs
wandb: Agent Starting Run: pgegke2o with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200252-pgegke2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-256
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pgegke2o
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run dandy-sweep-256 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pgegke2o
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200252-pgegke2o/logs
Run pgegke2o errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run pgegke2o errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 6srwihnb with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200302-6srwihnb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-257
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6srwihnb
wandb:                                                                                
wandb: 🚀 View run brisk-sweep-257 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6srwihnb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200302-6srwihnb/logs
wandb: Agent Starting Run: 4w0vn79u with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200308-4w0vn79u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-258
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4w0vn79u
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run lunar-sweep-258 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4w0vn79u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200308-4w0vn79u/logs
wandb: Agent Starting Run: 8t7q15hi with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200344-8t7q15hi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-259
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8t7q15hi
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x1x7). Calculated output size: (32x0x3). Output size is too small
wandb:                                                                                
wandb: 🚀 View run rural-sweep-259 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8t7q15hi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200344-8t7q15hi/logs
Run 8t7q15hi errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x1x7). Calculated output size: (32x0x3). Output size is too small

wandb: ERROR Run 8t7q15hi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x1x7). Calculated output size: (32x0x3). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: 6c9h0n7k with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200349-6c9h0n7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-260
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6c9h0n7k
wandb:                                                                                
wandb: 🚀 View run apricot-sweep-260 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6c9h0n7k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200349-6c9h0n7k/logs
wandb: Agent Starting Run: nw3fe1z6 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200355-nw3fe1z6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-261
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nw3fe1z6
wandb:                                                                                
wandb: 🚀 View run dry-sweep-261 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nw3fe1z6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200355-nw3fe1z6/logs
wandb: Agent Starting Run: p1zpnzwm with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200400-p1zpnzwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-262
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p1zpnzwm
wandb:                                                                                
wandb: 🚀 View run upbeat-sweep-262 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p1zpnzwm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200400-p1zpnzwm/logs
wandb: Agent Starting Run: v60hdpjt with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200405-v60hdpjt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-263
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v60hdpjt
wandb:                                                                                
wandb: 🚀 View run crimson-sweep-263 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v60hdpjt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200405-v60hdpjt/logs
wandb: Agent Starting Run: fpktjs0x with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200411-fpktjs0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-264
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fpktjs0x
wandb:                                                                                
wandb: 🚀 View run gallant-sweep-264 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fpktjs0x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200411-fpktjs0x/logs
wandb: Agent Starting Run: yfrkkp85 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200416-yfrkkp85
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-265
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yfrkkp85
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▄▃▃▃▂▂▁▁
wandb:      train_rmse █▅▄▃▃▃▂▂▁▁
wandb: validation_loss █▇▆▅▅▄▃▂▂▁
wandb: validation_rmse █▇▆▅▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 820.82214
wandb:      train_rmse 28.64999
wandb: validation_loss 815.55447
wandb: validation_rmse 28.55791
wandb: 
wandb: 🚀 View run ethereal-sweep-265 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yfrkkp85
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200416-yfrkkp85/logs
wandb: Agent Starting Run: bixxo3x5 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200550-bixxo3x5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-266
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bixxo3x5
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run revived-sweep-266 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bixxo3x5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200550-bixxo3x5/logs
wandb: Agent Starting Run: snkd5z0z with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200555-snkd5z0z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-267
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/snkd5z0z
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run sparkling-sweep-267 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/snkd5z0z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200555-snkd5z0z/logs
wandb: Agent Starting Run: rjnzm323 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200605-rjnzm323
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-268
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rjnzm323
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ███▅▂▃▂▁▂▃
wandb:      train_rmse ███▅▂▃▂▁▂▃
wandb: validation_loss █▆▇▆▃▄▃▃▁▃
wandb: validation_rmse █▆▇▆▃▄▃▃▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 979.59959
wandb:      train_rmse 31.29856
wandb: validation_loss 968.55945
wandb: validation_rmse 31.12169
wandb: 
wandb: 🚀 View run sage-sweep-268 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rjnzm323
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200605-rjnzm323/logs
wandb: Agent Starting Run: 31j6r8jv with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200739-31j6r8jv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-269
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/31j6r8jv
wandb:                                                                                
wandb: 🚀 View run golden-sweep-269 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/31j6r8jv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200739-31j6r8jv/logs
wandb: Agent Starting Run: sx6t459p with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200744-sx6t459p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-270
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sx6t459p
wandb:                                                                                
wandb: 🚀 View run peach-sweep-270 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sx6t459p
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200744-sx6t459p/logs
wandb: Agent Starting Run: 0benb6mm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200750-0benb6mm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-271
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0benb6mm
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run rural-sweep-271 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0benb6mm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200750-0benb6mm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wxgjv64i with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200809-wxgjv64i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-272
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wxgjv64i
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-272 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wxgjv64i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200809-wxgjv64i/logs
wandb: Agent Starting Run: xf6iy7jl with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200815-xf6iy7jl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-273
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xf6iy7jl
wandb:                                                                                
wandb: 🚀 View run graceful-sweep-273 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xf6iy7jl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200815-xf6iy7jl/logs
wandb: Agent Starting Run: 6i2k5nhr with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200821-6i2k5nhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-274
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6i2k5nhr
wandb:                                                                                
wandb: 🚀 View run absurd-sweep-274 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6i2k5nhr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200821-6i2k5nhr/logs
wandb: Agent Starting Run: 4zjo124x with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200826-4zjo124x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-275
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4zjo124x
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -96: [128, -96]
wandb:                                                                                
wandb: 🚀 View run light-sweep-275 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4zjo124x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200826-4zjo124x/logs
Run 4zjo124x errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -96: [128, -96]

wandb: ERROR Run 4zjo124x errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -96: [128, -96]
wandb: ERROR 
wandb: Agent Starting Run: ny4s38za with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200832-ny4s38za
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-276
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ny4s38za
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run genial-sweep-276 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ny4s38za
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200832-ny4s38za/logs
wandb: Agent Starting Run: vo4wvf37 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200842-vo4wvf37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-277
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vo4wvf37
wandb:                                                                                
wandb: 🚀 View run legendary-sweep-277 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vo4wvf37
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200842-vo4wvf37/logs
wandb: Agent Starting Run: u6xhdnk7 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200848-u6xhdnk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-278
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u6xhdnk7
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run daily-sweep-278 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u6xhdnk7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200848-u6xhdnk7/logs
wandb: Agent Starting Run: ppzz7g9j with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200853-ppzz7g9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-279
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ppzz7g9j
wandb:                                                                                
wandb: 🚀 View run clear-sweep-279 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ppzz7g9j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200853-ppzz7g9j/logs
wandb: Agent Starting Run: foira4w3 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200858-foira4w3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-280
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/foira4w3
wandb:                                                                                
wandb: 🚀 View run lucky-sweep-280 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/foira4w3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200858-foira4w3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hnkfws1k with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200922-hnkfws1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-281
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hnkfws1k
wandb:                                                                                
wandb: 🚀 View run major-sweep-281 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hnkfws1k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200922-hnkfws1k/logs
wandb: Agent Starting Run: ni06kdyg with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200929-ni06kdyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-282
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ni06kdyg
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-282 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ni06kdyg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200929-ni06kdyg/logs
wandb: Agent Starting Run: exfo1os2 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200934-exfo1os2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-283
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/exfo1os2
wandb:                                                                                
wandb: 🚀 View run earthy-sweep-283 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/exfo1os2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200934-exfo1os2/logs
wandb: Agent Starting Run: hjy826o0 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200940-hjy826o0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-284
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hjy826o0
wandb:                                                                                
wandb: 🚀 View run cosmic-sweep-284 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hjy826o0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200940-hjy826o0/logs
wandb: Agent Starting Run: lcljje84 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200945-lcljje84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-285
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lcljje84
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-285 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lcljje84
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200945-lcljje84/logs
wandb: Agent Starting Run: gigsapof with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200950-gigsapof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-286
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gigsapof
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-286 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gigsapof
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200950-gigsapof/logs
wandb: Agent Starting Run: uqf7fk9y with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_200956-uqf7fk9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-287
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uqf7fk9y
wandb:                                                                                
wandb: 🚀 View run silvery-sweep-287 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uqf7fk9y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_200956-uqf7fk9y/logs
wandb: Agent Starting Run: m7dyny8z with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201001-m7dyny8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-288
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m7dyny8z
wandb:                                                                                
wandb: 🚀 View run laced-sweep-288 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m7dyny8z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201001-m7dyny8z/logs
wandb: Agent Starting Run: l99eba7t with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201006-l99eba7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-289
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l99eba7t
wandb:                                                                                
wandb: 🚀 View run stellar-sweep-289 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l99eba7t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201006-l99eba7t/logs
wandb: Agent Starting Run: bn22g3m8 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201017-bn22g3m8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-290
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bn22g3m8
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇▆▆▄▄▄▂▁
wandb:      train_rmse █▇▇▆▆▄▄▄▂▁
wandb: validation_loss ██▇▇▆▅▄▃▂▁
wandb: validation_rmse ██▇▇▆▅▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 958.10523
wandb:      train_rmse 30.95327
wandb: validation_loss 954.73026
wandb: validation_rmse 30.89871
wandb: 
wandb: 🚀 View run drawn-sweep-290 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bn22g3m8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201017-bn22g3m8/logs
wandb: Agent Starting Run: qj9meqyr with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201150-qj9meqyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-291
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qj9meqyr
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-291 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qj9meqyr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201150-qj9meqyr/logs
wandb: Agent Starting Run: s34y4j5m with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201155-s34y4j5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-292
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s34y4j5m
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run lively-sweep-292 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s34y4j5m
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201155-s34y4j5m/logs
wandb: Agent Starting Run: zc4y6bwz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201237-zc4y6bwz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-293
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zc4y6bwz
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▁▁
wandb:      train_rmse █▆▅▄▄▃▂▂▁▁
wandb: validation_loss █▅▄▃▃▂▂▂▁▁
wandb: validation_rmse █▅▄▃▃▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 852.80372
wandb:      train_rmse 29.2028
wandb: validation_loss 849.29544
wandb: validation_rmse 29.14267
wandb: 
wandb: 🚀 View run sparkling-sweep-293 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zc4y6bwz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201237-zc4y6bwz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qfu4wygr with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201439-qfu4wygr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-294
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qfu4wygr
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-294 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qfu4wygr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201439-qfu4wygr/logs
wandb: Agent Starting Run: nye2yl9i with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201444-nye2yl9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-295
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nye2yl9i
wandb:                                                                                
wandb: 🚀 View run desert-sweep-295 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nye2yl9i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201444-nye2yl9i/logs
wandb: Agent Starting Run: h2mb3pft with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201449-h2mb3pft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-296
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h2mb3pft
wandb:                                                                                
wandb: 🚀 View run laced-sweep-296 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h2mb3pft
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201449-h2mb3pft/logs
wandb: Agent Starting Run: k0i9atio with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201455-k0i9atio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-297
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k0i9atio
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run swift-sweep-297 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k0i9atio
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201455-k0i9atio/logs
wandb: Agent Starting Run: 74v0mq2p with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201501-74v0mq2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-298
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/74v0mq2p
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run celestial-sweep-298 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/74v0mq2p
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201501-74v0mq2p/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: slus6hbm with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201516-slus6hbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-299
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/slus6hbm
wandb:                                                                                
wandb: 🚀 View run playful-sweep-299 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/slus6hbm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201516-slus6hbm/logs
wandb: Agent Starting Run: fxn6dnjx with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201522-fxn6dnjx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-300
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fxn6dnjx
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run eager-sweep-300 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fxn6dnjx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201522-fxn6dnjx/logs
wandb: Agent Starting Run: kqkr74py with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201532-kqkr74py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-301
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kqkr74py
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▃▂▁
wandb:      train_rmse █▇▆▅▅▄▃▃▂▁
wandb: validation_loss █▇▇▇▆▅▄▃▂▁
wandb: validation_rmse █▇▇▇▆▅▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 803.75171
wandb:      train_rmse 28.35052
wandb: validation_loss 786.21109
wandb: validation_rmse 28.03946
wandb: 
wandb: 🚀 View run gallant-sweep-301 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kqkr74py
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201532-kqkr74py/logs
wandb: Agent Starting Run: uh59rh2b with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201706-uh59rh2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-302
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uh59rh2b
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-302 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uh59rh2b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201706-uh59rh2b/logs
wandb: Agent Starting Run: n8ozjc4l with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201711-n8ozjc4l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-303
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/n8ozjc4l
wandb:                                                                                
wandb: 🚀 View run solar-sweep-303 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/n8ozjc4l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201711-n8ozjc4l/logs
wandb: Agent Starting Run: 1txk5m5b with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201716-1txk5m5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-304
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1txk5m5b
wandb:                                                                                
wandb: 🚀 View run wobbly-sweep-304 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1txk5m5b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201716-1txk5m5b/logs
wandb: Agent Starting Run: xbnuiikd with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201722-xbnuiikd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-305
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xbnuiikd
wandb:                                                                                
wandb: 🚀 View run twilight-sweep-305 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xbnuiikd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201722-xbnuiikd/logs
wandb: Agent Starting Run: qbz0ycw8 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_201727-qbz0ycw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-306
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qbz0ycw8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▂▃▂▁▁▁▃▄▁▂▁▂▁▂▂▁▁▁▂▁▁▂▄▁▃▂▁▁▁▁█▁▁▂▁▂▁▁▁▂
wandb: validation_rmse ▃▄▂▂▁▂▃▄▁▂▁▂▁▃▂▁▁▂▂▁▁▁▁▃▄▄▄▁▁▁▁█▁▂▂▂▂▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 9.06468
wandb:      train_rmse 3.01076
wandb: validation_loss 11.78153
wandb: validation_rmse 3.43242
wandb: 
wandb: 🚀 View run iconic-sweep-306 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qbz0ycw8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_201727-qbz0ycw8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pexrtp92 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202438-pexrtp92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-307
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pexrtp92
wandb:                                                                                
wandb: 🚀 View run wobbly-sweep-307 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pexrtp92
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202438-pexrtp92/logs
wandb: Agent Starting Run: qgzh22ui with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202443-qgzh22ui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-308
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qgzh22ui
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▃▂▁▁▁▁▁▁
wandb:      train_rmse █▆▄▃▂▁▁▁▁▁
wandb: validation_loss █▅▃▂▁▁▁▁▁▁
wandb: validation_rmse █▆▄▃▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 80.49844
wandb:      train_rmse 8.97209
wandb: validation_loss 73.97591
wandb: validation_rmse 8.60092
wandb: 
wandb: 🚀 View run royal-sweep-308 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qgzh22ui
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202443-qgzh22ui/logs
wandb: Agent Starting Run: wqw2xp66 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202614-wqw2xp66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-309
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wqw2xp66
wandb:                                                                                
wandb: 🚀 View run confused-sweep-309 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wqw2xp66
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202614-wqw2xp66/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 08eoulhv with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202629-08eoulhv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-310
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/08eoulhv
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x1x5). Calculated output size: (64x0x1). Output size is too small
wandb:                                                                                
wandb: 🚀 View run treasured-sweep-310 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/08eoulhv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202629-08eoulhv/logs
Run 08eoulhv errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x1x5). Calculated output size: (64x0x1). Output size is too small

wandb: ERROR Run 08eoulhv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (64x1x5). Calculated output size: (64x0x1). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: xe4q29dy with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202635-xe4q29dy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-311
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xe4q29dy
wandb:                                                                                
wandb: 🚀 View run whole-sweep-311 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xe4q29dy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202635-xe4q29dy/logs
wandb: Agent Starting Run: 8lfc71qm with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202640-8lfc71qm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-312
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8lfc71qm
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run peach-sweep-312 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8lfc71qm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202640-8lfc71qm/logs
Run 8lfc71qm errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 8lfc71qm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: untojaxt with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202645-untojaxt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-313
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/untojaxt
wandb:                                                                                
wandb: 🚀 View run morning-sweep-313 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/untojaxt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202645-untojaxt/logs
wandb: Agent Starting Run: ejgg6iu0 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202651-ejgg6iu0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-314
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ejgg6iu0
wandb:                                                                                
wandb: 🚀 View run eager-sweep-314 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ejgg6iu0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202651-ejgg6iu0/logs
wandb: Agent Starting Run: yizvqzxu with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202656-yizvqzxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-315
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yizvqzxu
wandb:                                                                                
wandb: 🚀 View run laced-sweep-315 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yizvqzxu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202656-yizvqzxu/logs
wandb: Agent Starting Run: aq1ahex1 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202701-aq1ahex1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-316
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aq1ahex1
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run tough-sweep-316 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aq1ahex1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202701-aq1ahex1/logs
wandb: Agent Starting Run: uzuf5y9r with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_202707-uzuf5y9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-317
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uzuf5y9r
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇▆▅▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▇▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 4.03757
wandb:      train_rmse 2.00937
wandb: validation_loss 6.25639
wandb: validation_rmse 2.50128
wandb: 
wandb: 🚀 View run lively-sweep-317 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uzuf5y9r
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202707-uzuf5y9r/logs
wandb: Agent Starting Run: ryxzt8xd with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_203412-ryxzt8xd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-318
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ryxzt8xd
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x1x26). Calculated output size: (16x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run super-sweep-318 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ryxzt8xd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_203412-ryxzt8xd/logs
Run ryxzt8xd errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x1x26). Calculated output size: (16x0x6). Output size is too small

wandb: ERROR Run ryxzt8xd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (16x1x26). Calculated output size: (16x0x6). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: j8ask0qe with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_203423-j8ask0qe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-319
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j8ask0qe
wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:      train_loss nan
wandb:      train_rmse nan
wandb: validation_loss nan
wandb: validation_rmse nan
wandb: 
wandb: 🚀 View run apricot-sweep-319 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j8ask0qe
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_203423-j8ask0qe/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pjuoex73 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_204144-pjuoex73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-320
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pjuoex73
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run classic-sweep-320 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pjuoex73
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204144-pjuoex73/logs
wandb: Agent Starting Run: 4l8idoo6 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_204150-4l8idoo6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-321
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4l8idoo6
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run ancient-sweep-321 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4l8idoo6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204150-4l8idoo6/logs
Run 4l8idoo6 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 4l8idoo6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 0rgu28t1 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_204156-0rgu28t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-322
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0rgu28t1
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run generous-sweep-322 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0rgu28t1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204156-0rgu28t1/logs
wandb: Agent Starting Run: ykh1yccl with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_204206-ykh1yccl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-323
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ykh1yccl
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-323 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ykh1yccl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204206-ykh1yccl/logs
wandb: Agent Starting Run: rxsenf00 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_204211-rxsenf00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-324
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rxsenf00
wandb:                                                                                
wandb: 🚀 View run morning-sweep-324 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rxsenf00
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204211-rxsenf00/logs
wandb: Agent Starting Run: oiw17gjz with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_204217-oiw17gjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-325
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oiw17gjz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▂▁▁▁▁▂▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▂▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 20.81836
wandb:      train_rmse 4.56271
wandb: validation_loss 11.76543
wandb: validation_rmse 3.43008
wandb: 
wandb: 🚀 View run dandy-sweep-325 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oiw17gjz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204217-oiw17gjz/logs
wandb: Agent Starting Run: 65mlt746 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205232-65mlt746
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-326
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/65mlt746
wandb:                                                                                
wandb: 🚀 View run glorious-sweep-326 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/65mlt746
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205232-65mlt746/logs
wandb: Agent Starting Run: 1qmjy51l with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205238-1qmjy51l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-327
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1qmjy51l
wandb:                                                                                
wandb: 🚀 View run flowing-sweep-327 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1qmjy51l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205238-1qmjy51l/logs
wandb: Agent Starting Run: 1v8qobm9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205243-1v8qobm9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-328
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1v8qobm9
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-328 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1v8qobm9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205243-1v8qobm9/logs
Run 1v8qobm9 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 1v8qobm9 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: pefyapll with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205249-pefyapll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-329
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pefyapll
wandb:                                                                                
wandb: 🚀 View run feasible-sweep-329 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pefyapll
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205249-pefyapll/logs
wandb: Agent Starting Run: h871nhr6 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205254-h871nhr6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-330
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h871nhr6
wandb:                                                                                
wandb: 🚀 View run divine-sweep-330 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h871nhr6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205254-h871nhr6/logs
wandb: Agent Starting Run: 5plk8kzz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205259-5plk8kzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-331
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5plk8kzz
wandb:                                                                                
wandb: 🚀 View run zesty-sweep-331 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5plk8kzz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205259-5plk8kzz/logs
wandb: Agent Starting Run: tm24xwyc with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205305-tm24xwyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-332
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tm24xwyc
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run grateful-sweep-332 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tm24xwyc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205305-tm24xwyc/logs
wandb: Agent Starting Run: dqa3i3j1 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205315-dqa3i3j1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-333
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dqa3i3j1
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run astral-sweep-333 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dqa3i3j1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205315-dqa3i3j1/logs
wandb: Agent Starting Run: lr8e0njw with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205321-lr8e0njw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-334
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lr8e0njw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▂▁▁▁▁▁▁
wandb:      train_rmse █▂▂▃▂▂▁▁▁▁
wandb: validation_loss █▆▁▃▆█▆▅▂▁
wandb: validation_rmse █▆▁▄▇█▆▆▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 20.7659
wandb:      train_rmse 4.55696
wandb: validation_loss 75.88665
wandb: validation_rmse 8.71129
wandb: 
wandb: 🚀 View run sleek-sweep-334 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lr8e0njw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205321-lr8e0njw/logs
wandb: Agent Starting Run: tq9k7buh with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205450-tq9k7buh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-335
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tq9k7buh
wandb:                                                                                
wandb: 🚀 View run glad-sweep-335 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tq9k7buh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205450-tq9k7buh/logs
wandb: Agent Starting Run: 1oyr2dp1 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205455-1oyr2dp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-336
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1oyr2dp1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▃▃▂▂▁▁
wandb:      train_rmse █▆▅▄▃▃▂▂▁▁
wandb: validation_loss █▆▅▄▄▅▃▂▂▁
wandb: validation_rmse █▆▅▄▄▅▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 924.62044
wandb:      train_rmse 30.40757
wandb: validation_loss 915.31631
wandb: validation_rmse 30.25419
wandb: 
wandb: 🚀 View run laced-sweep-336 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1oyr2dp1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205455-1oyr2dp1/logs
wandb: Agent Starting Run: nbvkzfyn with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205652-nbvkzfyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-337
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nbvkzfyn
wandb:                                                                                
wandb: 🚀 View run daily-sweep-337 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nbvkzfyn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205652-nbvkzfyn/logs
wandb: Agent Starting Run: 6ailpw6r with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205658-6ailpw6r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-338
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ailpw6r
wandb:                                                                                
wandb: 🚀 View run peachy-sweep-338 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ailpw6r
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205658-6ailpw6r/logs
wandb: Agent Starting Run: moo6aujr with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205703-moo6aujr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-339
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/moo6aujr
wandb:                                                                                
wandb: 🚀 View run usual-sweep-339 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/moo6aujr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205703-moo6aujr/logs
wandb: Agent Starting Run: jd339gte with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205708-jd339gte
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-340
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jd339gte
wandb:                                                                                
wandb: 🚀 View run lemon-sweep-340 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jd339gte
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205708-jd339gte/logs
wandb: Agent Starting Run: jyvmvpod with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205714-jyvmvpod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-341
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jyvmvpod
wandb:                                                                                
wandb: 🚀 View run graceful-sweep-341 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jyvmvpod
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205714-jyvmvpod/logs
wandb: Agent Starting Run: d3pqji0d with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205719-d3pqji0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-342
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d3pqji0d
wandb:                                                                                
wandb: 🚀 View run apricot-sweep-342 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d3pqji0d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205719-d3pqji0d/logs
wandb: Agent Starting Run: v547z2sy with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205725-v547z2sy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-343
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v547z2sy
wandb:                                                                                
wandb: 🚀 View run proud-sweep-343 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v547z2sy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205725-v547z2sy/logs
wandb: Agent Starting Run: 7epnr14y with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205730-7epnr14y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-344
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7epnr14y
wandb:                                                                                
wandb: 🚀 View run rosy-sweep-344 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7epnr14y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205730-7epnr14y/logs
wandb: Agent Starting Run: wb1dp76x with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205735-wb1dp76x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-345
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wb1dp76x
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-345 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wb1dp76x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205735-wb1dp76x/logs
wandb: Agent Starting Run: g7a315zm with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205741-g7a315zm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-346
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g7a315zm
wandb:                                                                                
wandb: 🚀 View run major-sweep-346 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g7a315zm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205741-g7a315zm/logs
wandb: Agent Starting Run: bdzbwbeb with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205746-bdzbwbeb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-347
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bdzbwbeb
wandb:                                                                                
wandb: 🚀 View run proud-sweep-347 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bdzbwbeb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205746-bdzbwbeb/logs
wandb: Agent Starting Run: h72shshc with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205751-h72shshc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-348
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h72shshc
wandb:                                                                                
wandb: 🚀 View run dashing-sweep-348 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h72shshc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205751-h72shshc/logs
wandb: Agent Starting Run: 57kysvpw with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205756-57kysvpw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-349
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/57kysvpw
wandb:                                                                                
wandb: 🚀 View run different-sweep-349 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/57kysvpw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205756-57kysvpw/logs
wandb: Agent Starting Run: ubbcbrti with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205802-ubbcbrti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-350
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ubbcbrti
wandb:                                                                                
wandb: 🚀 View run trim-sweep-350 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ubbcbrti
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205802-ubbcbrti/logs
wandb: Agent Starting Run: ei9bobl4 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205807-ei9bobl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-351
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ei9bobl4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▇▅▁█▇▆▄▆█▄
wandb:      train_rmse ▇▅▁█▇▆▄▆█▄
wandb: validation_loss █▃▄▁▁▃▃▃▂▂
wandb: validation_rmse █▃▄▁▁▃▃▃▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 961.33558
wandb:      train_rmse 31.00541
wandb: validation_loss 964.13571
wandb: validation_rmse 31.05053
wandb: 
wandb: 🚀 View run sparkling-sweep-351 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ei9bobl4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205807-ei9bobl4/logs
wandb: Agent Starting Run: coozyuj2 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205936-coozyuj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-352
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/coozyuj2
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run different-sweep-352 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/coozyuj2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205936-coozyuj2/logs
Run coozyuj2 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run coozyuj2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: g0t8oyph with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205942-g0t8oyph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-353
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g0t8oyph
wandb:                                                                                
wandb: 🚀 View run youthful-sweep-353 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g0t8oyph
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205942-g0t8oyph/logs
wandb: Agent Starting Run: yce8rnlp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205948-yce8rnlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-354
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yce8rnlp
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-354 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yce8rnlp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205948-yce8rnlp/logs
wandb: Agent Starting Run: ndmxom0q with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205953-ndmxom0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-355
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ndmxom0q
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -96: [32, -96]
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-355 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ndmxom0q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205953-ndmxom0q/logs
Run ndmxom0q errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -96: [32, -96]

wandb: ERROR Run ndmxom0q errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -96: [32, -96]
wandb: ERROR 
wandb: Agent Starting Run: dykvtqvk with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_205959-dykvtqvk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-356
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dykvtqvk
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x8). Calculated output size: (32x0x2). Output size is too small
wandb:                                                                                
wandb: 🚀 View run fanciful-sweep-356 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dykvtqvk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205959-dykvtqvk/logs
Run dykvtqvk errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x8). Calculated output size: (32x0x2). Output size is too small

wandb: ERROR Run dykvtqvk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x3x8). Calculated output size: (32x0x2). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: 6emjwbfj with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210004-6emjwbfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-357
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6emjwbfj
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run northern-sweep-357 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6emjwbfj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210004-6emjwbfj/logs
wandb: Agent Starting Run: f13vubsa with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210015-f13vubsa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-358
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f13vubsa
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-358 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f13vubsa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210015-f13vubsa/logs
wandb: Agent Starting Run: y28tf0ji with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210020-y28tf0ji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-359
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y28tf0ji
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-359 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y28tf0ji
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210020-y28tf0ji/logs
wandb: Agent Starting Run: 41jfyiup with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210025-41jfyiup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-360
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/41jfyiup
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run pretty-sweep-360 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/41jfyiup
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210025-41jfyiup/logs
wandb: Agent Starting Run: 0z8mfteq with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210032-0z8mfteq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-361
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0z8mfteq
wandb:                                                                                
wandb: 🚀 View run smart-sweep-361 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0z8mfteq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210032-0z8mfteq/logs
wandb: Agent Starting Run: te0qjkvo with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210037-te0qjkvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-362
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/te0qjkvo
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x1x8). Calculated output size: (64x0x2). Output size is too small
wandb:                                                                                
wandb: 🚀 View run deft-sweep-362 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/te0qjkvo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210037-te0qjkvo/logs
Run te0qjkvo errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x1x8). Calculated output size: (64x0x2). Output size is too small

wandb: ERROR Run te0qjkvo errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (64x1x8). Calculated output size: (64x0x2). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: 3ecn729t with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210042-3ecn729t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-363
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ecn729t
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▄▃▂▁▁
wandb:      train_rmse █▇▇▆▅▄▃▂▂▁
wandb: validation_loss █▇▆▅▄▃▃▂▁▁
wandb: validation_rmse █▇▇▆▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 229.63166
wandb:      train_rmse 15.1536
wandb: validation_loss 211.34264
wandb: validation_rmse 14.53763
wandb: 
wandb: 🚀 View run helpful-sweep-363 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ecn729t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210042-3ecn729t/logs
wandb: Agent Starting Run: zyakzpu3 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210216-zyakzpu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-364
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zyakzpu3
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-364 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zyakzpu3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210216-zyakzpu3/logs
wandb: Agent Starting Run: zkwrq7e8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210221-zkwrq7e8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-365
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zkwrq7e8
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -448: [1, -448]
wandb:                                                                                
wandb: 🚀 View run eternal-sweep-365 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zkwrq7e8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210221-zkwrq7e8/logs
Run zkwrq7e8 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -448: [1, -448]

wandb: ERROR Run zkwrq7e8 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, 1))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -448: [1, -448]
wandb: ERROR 
wandb: Agent Starting Run: lgiiq7uy with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210226-lgiiq7uy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-366
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lgiiq7uy
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -64: [1, -64]
wandb:                                                                                
wandb: 🚀 View run flowing-sweep-366 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lgiiq7uy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210226-lgiiq7uy/logs
Run lgiiq7uy errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -64: [1, -64]

wandb: ERROR Run lgiiq7uy errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, 1))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -64: [1, -64]
wandb: ERROR 
wandb: Agent Starting Run: b1p3r83y with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210232-b1p3r83y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-367
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b1p3r83y
wandb:                                                                                
wandb: 🚀 View run colorful-sweep-367 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b1p3r83y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210232-b1p3r83y/logs
wandb: Agent Starting Run: lawllt60 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210237-lawllt60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-368
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lawllt60
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▂▂▁
wandb:      train_rmse █▇▆▅▅▄▃▂▂▁
wandb: validation_loss ▅▅▆▄▇█▆▂▃▁
wandb: validation_rmse ▅▅▆▄▇█▆▂▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 799.53812
wandb:      train_rmse 28.27611
wandb: validation_loss 859.88107
wandb: validation_rmse 29.32373
wandb: 
wandb: 🚀 View run polished-sweep-368 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lawllt60
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210237-lawllt60/logs
wandb: Agent Starting Run: i5eakscg with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210415-i5eakscg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-369
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i5eakscg
wandb:                                                                                
wandb: 🚀 View run hearty-sweep-369 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i5eakscg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210415-i5eakscg/logs
wandb: Agent Starting Run: 3qwhmddb with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210421-3qwhmddb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-370
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3qwhmddb
wandb:                                                                                
wandb: 🚀 View run fiery-sweep-370 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3qwhmddb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210421-3qwhmddb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: p740vgt4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210435-p740vgt4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-371
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p740vgt4
wandb:                                                                                
wandb: 🚀 View run woven-sweep-371 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p740vgt4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210435-p740vgt4/logs
wandb: Agent Starting Run: i8cjfrd4 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_210443-i8cjfrd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-372
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i8cjfrd4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 10.25167
wandb:      train_rmse 3.20182
wandb: validation_loss 6.80345
wandb: validation_rmse 2.60834
wandb: 
wandb: 🚀 View run sweet-sweep-372 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i8cjfrd4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_210443-i8cjfrd4/logs
wandb: Agent Starting Run: 00cz01ps with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211157-00cz01ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-373
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/00cz01ps
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run hearty-sweep-373 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/00cz01ps
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211157-00cz01ps/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 26e6f726 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211212-26e6f726
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-374
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/26e6f726
wandb:                                                                                
wandb: 🚀 View run twilight-sweep-374 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/26e6f726
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211212-26e6f726/logs
wandb: Agent Starting Run: pqaxxdoa with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211217-pqaxxdoa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-375
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pqaxxdoa
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x1x28). Calculated output size: (32x0x14). Output size is too small
wandb:                                                                                
wandb: 🚀 View run dandy-sweep-375 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pqaxxdoa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211217-pqaxxdoa/logs
Run pqaxxdoa errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x1x28). Calculated output size: (32x0x14). Output size is too small

wandb: ERROR Run pqaxxdoa errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x1x28). Calculated output size: (32x0x14). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: 3g9ybyky with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211223-3g9ybyky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-376
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3g9ybyky
wandb:                                                                                
wandb: 🚀 View run eager-sweep-376 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3g9ybyky
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211223-3g9ybyky/logs
wandb: Agent Starting Run: facrspky with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211228-facrspky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-377
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/facrspky
wandb:                                                                                
wandb: 🚀 View run eternal-sweep-377 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/facrspky
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211228-facrspky/logs
wandb: Agent Starting Run: vswq35io with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211233-vswq35io
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-378
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vswq35io
wandb:                                                                                
wandb: 🚀 View run light-sweep-378 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vswq35io
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211233-vswq35io/logs
wandb: Agent Starting Run: bqshyfqm with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211239-bqshyfqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-379
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bqshyfqm
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run quiet-sweep-379 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bqshyfqm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211239-bqshyfqm/logs
wandb: Agent Starting Run: 0cq6b0aa with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211245-0cq6b0aa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-380
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0cq6b0aa
wandb:                                                                                
wandb: 🚀 View run wild-sweep-380 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0cq6b0aa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211245-0cq6b0aa/logs
wandb: Agent Starting Run: blyedhpx with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211251-blyedhpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-381
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/blyedhpx
wandb:                                                                                
wandb: 🚀 View run easy-sweep-381 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/blyedhpx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211251-blyedhpx/logs
wandb: Agent Starting Run: 2kmo3wco with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211256-2kmo3wco
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-382
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2kmo3wco
wandb:                                                                                
wandb: 🚀 View run fallen-sweep-382 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2kmo3wco
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211256-2kmo3wco/logs
wandb: Agent Starting Run: ml7tvuft with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211302-ml7tvuft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-383
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ml7tvuft
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-383 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ml7tvuft
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211302-ml7tvuft/logs
wandb: Agent Starting Run: wtn6g01q with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211307-wtn6g01q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-384
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wtn6g01q
wandb:                                                                                
wandb: 🚀 View run golden-sweep-384 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wtn6g01q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211307-wtn6g01q/logs
wandb: Agent Starting Run: ds0g4jye with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_211313-ds0g4jye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-385
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ds0g4jye
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇▄▅▄▃▄▃▂▃▃▃▂▂▁▂▃▁▃▁▅▄▄▅▂▆▃▃▃▂▁▃▁▁▁▁▁▂▁▄
wandb: validation_rmse ██▄▆▄▃▄▄▃▄▄▃▃▃▁▂▃▁▂▂▄▄▆▂▂▃▃▃▃▃▂▁▃▁▁▂▁▁▂▅
wandb: 
wandb: Run summary:
wandb:      train_loss 7.05786
wandb:      train_rmse 2.65666
wandb: validation_loss 23.06265
wandb: validation_rmse 4.80236
wandb: 
wandb: 🚀 View run honest-sweep-385 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ds0g4jye
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_211313-ds0g4jye/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: j230e8mi with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_212024-j230e8mi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-386
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j230e8mi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▄▄▃▃▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▅▅▄▃▃▃▂▂▂▂▂▂▁▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇▆▅▄▂▃▂▂▃▂▁▁▁▁▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁
wandb: validation_rmse █▇▇▆▅▃▄▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▁▁▁▂▂▁▁▁▂▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 41.49666
wandb:      train_rmse 6.44179
wandb: validation_loss 11.18491
wandb: validation_rmse 3.34438
wandb: 
wandb: 🚀 View run valiant-sweep-386 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j230e8mi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_212024-j230e8mi/logs
wandb: Agent Starting Run: hff12ejs with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_212734-hff12ejs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-387
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hff12ejs
wandb:                                                                                
wandb: 🚀 View run royal-sweep-387 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hff12ejs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_212734-hff12ejs/logs
wandb: Agent Starting Run: uhinskho with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_212739-uhinskho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-388
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uhinskho
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▂▂▁
wandb:      train_rmse █▇▆▆▅▄▃▂▂▁
wandb: validation_loss █▇▆▅▅▄▃▂▂▁
wandb: validation_rmse █▇▆▆▅▄▃▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 760.13622
wandb:      train_rmse 27.57057
wandb: validation_loss 746.69113
wandb: validation_rmse 27.32565
wandb: 
wandb: 🚀 View run exalted-sweep-388 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uhinskho
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_212739-uhinskho/logs
wandb: Agent Starting Run: gv1ex3qd with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_212907-gv1ex3qd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-389
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gv1ex3qd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▂▁▁▂▁
wandb: validation_rmse █▄▂▃▁▂▂▂▂▁▃▃▁▁▁▁▂▂▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▄▁▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 16.80772
wandb:      train_rmse 4.09972
wandb: validation_loss 7.88817
wandb: validation_rmse 2.80859
wandb: 
wandb: 🚀 View run glad-sweep-389 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gv1ex3qd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_212907-gv1ex3qd/logs
wandb: Agent Starting Run: u6eh79eu with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213611-u6eh79eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-390
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u6eh79eu
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run likely-sweep-390 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u6eh79eu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213611-u6eh79eu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0vbdyx3s with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213650-0vbdyx3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-391
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0vbdyx3s
wandb:                                                                                
wandb: 🚀 View run devout-sweep-391 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0vbdyx3s
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213650-0vbdyx3s/logs
wandb: Agent Starting Run: pnycks3q with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213655-pnycks3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-392
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pnycks3q
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-392 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pnycks3q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213655-pnycks3q/logs
wandb: Agent Starting Run: pfd4p9ad with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213701-pfd4p9ad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-393
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pfd4p9ad
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▃▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▄▃▃▂▂▂▁▂▁▁▂▂▁▁▁▁
wandb: validation_loss ▆▅▇▁█▆▄▃▆▅█▅▅▅▆▄▄█
wandb: validation_rmse ▆▆▇▁█▆▅▃▆▆█▆▅▆▇▅▅█
wandb: 
wandb: Run summary:
wandb:      train_loss 43.23309
wandb:      train_rmse 6.57519
wandb: validation_loss 152.29277
wandb: validation_rmse 12.3407
wandb: 
wandb: 🚀 View run pleasant-sweep-393 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pfd4p9ad
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213701-pfd4p9ad/logs
wandb: Agent Starting Run: v5ju3b9z with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213942-v5ju3b9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-394
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v5ju3b9z
wandb:                                                                                
wandb: 🚀 View run soft-sweep-394 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v5ju3b9z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213942-v5ju3b9z/logs
wandb: Agent Starting Run: 6kmmhwij with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213947-6kmmhwij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-395
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6kmmhwij
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-395 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6kmmhwij
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213947-6kmmhwij/logs
wandb: Agent Starting Run: lx9mir4a with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213952-lx9mir4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-396
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lx9mir4a
wandb:                                                                                
wandb: 🚀 View run lilac-sweep-396 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lx9mir4a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213952-lx9mir4a/logs
wandb: Agent Starting Run: vw81iscv with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_213958-vw81iscv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-397
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vw81iscv
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run balmy-sweep-397 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vw81iscv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_213958-vw81iscv/logs
wandb: Agent Starting Run: 4e1819qh with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214003-4e1819qh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-398
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4e1819qh
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run valiant-sweep-398 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4e1819qh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214003-4e1819qh/logs
wandb: Agent Starting Run: 9213kqjt with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214014-9213kqjt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-399
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9213kqjt
wandb:                                                                                
wandb: 🚀 View run stellar-sweep-399 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9213kqjt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214014-9213kqjt/logs
wandb: Agent Starting Run: h0xexftv with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214020-h0xexftv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-400
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h0xexftv
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run revived-sweep-400 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h0xexftv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214020-h0xexftv/logs
wandb: Agent Starting Run: f8kezrol with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214025-f8kezrol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-401
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f8kezrol
wandb:                                                                                
wandb: 🚀 View run expert-sweep-401 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f8kezrol
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214025-f8kezrol/logs
wandb: Agent Starting Run: cbvrh93r with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214031-cbvrh93r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-402
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cbvrh93r
wandb:                                                                                
wandb: 🚀 View run dry-sweep-402 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cbvrh93r
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214031-cbvrh93r/logs
wandb: Agent Starting Run: 1fpggnb3 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214036-1fpggnb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-403
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1fpggnb3
wandb:                                                                                
wandb: 🚀 View run fine-sweep-403 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1fpggnb3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214036-1fpggnb3/logs
wandb: Agent Starting Run: tpkeasbr with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214041-tpkeasbr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-404
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tpkeasbr
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run ethereal-sweep-404 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tpkeasbr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214041-tpkeasbr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 13uqdksp with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214057-13uqdksp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-405
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/13uqdksp
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run woven-sweep-405 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/13uqdksp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214057-13uqdksp/logs
wandb: Agent Starting Run: weqapkhq with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214102-weqapkhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-406
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/weqapkhq
wandb:                                                                                
wandb: 🚀 View run light-sweep-406 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/weqapkhq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214102-weqapkhq/logs
wandb: Agent Starting Run: viftuyhw with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214108-viftuyhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-407
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/viftuyhw
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run resilient-sweep-407 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/viftuyhw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214108-viftuyhw/logs
wandb: Agent Starting Run: lub1jrxd with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214118-lub1jrxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-408
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lub1jrxd
wandb:                                                                                
wandb: 🚀 View run revived-sweep-408 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lub1jrxd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214118-lub1jrxd/logs
wandb: Agent Starting Run: 7i00rwuc with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214123-7i00rwuc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-409
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7i00rwuc
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run effortless-sweep-409 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7i00rwuc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214123-7i00rwuc/logs
wandb: Agent Starting Run: 8isrwedo with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214134-8isrwedo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-410
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8isrwedo
wandb:                                                                                
wandb: 🚀 View run clear-sweep-410 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8isrwedo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214134-8isrwedo/logs
wandb: Agent Starting Run: 84h0ez7h with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214139-84h0ez7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-411
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/84h0ez7h
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run icy-sweep-411 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/84h0ez7h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214139-84h0ez7h/logs
wandb: Agent Starting Run: qfmp914j with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214145-qfmp914j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-412
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qfmp914j
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run wise-sweep-412 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qfmp914j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214145-qfmp914j/logs
wandb: Agent Starting Run: d1ixzbec with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214150-d1ixzbec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-413
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d1ixzbec
wandb:                                                                                
wandb: 🚀 View run prime-sweep-413 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d1ixzbec
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214150-d1ixzbec/logs
wandb: Agent Starting Run: 0ax7f8ul with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214155-0ax7f8ul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-414
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ax7f8ul
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▃▃▆▃▄▇▁█▃▁
wandb:      train_rmse ▃▃▆▃▄▇▁█▃▁
wandb: validation_loss █▆▇▅▃▄▁█▄▃
wandb: validation_rmse █▆▇▅▃▄▁█▄▃
wandb: 
wandb: Run summary:
wandb:      train_loss 963.16368
wandb:      train_rmse 31.03488
wandb: validation_loss 964.35123
wandb: validation_rmse 31.05401
wandb: 
wandb: 🚀 View run peachy-sweep-414 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ax7f8ul
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214155-0ax7f8ul/logs
wandb: Agent Starting Run: rf3hydb0 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_214329-rf3hydb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-415
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rf3hydb0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▃▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ██▄▃▃▂▂▃▃▂▂▂▁▂▁▂▁▂▁▁▁▁▂▂▁▁▃▁▁▁▁▂▃▁▁▁▃▂▁▂
wandb: validation_rmse ██▅▄▃▂▂▃▄▃▃▂▃▂▂▂▂▃▂▂▂▁▂▃▁▁▄▁▂▁▁▃▄▁▁▁▃▁▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 16.85535
wandb:      train_rmse 4.10553
wandb: validation_loss 16.58524
wandb: validation_rmse 4.0725
wandb: 
wandb: 🚀 View run astral-sweep-415 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rf3hydb0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214329-rf3hydb0/logs
wandb: Agent Starting Run: g5joppgn with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215030-g5joppgn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-416
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g5joppgn
wandb:                                                                                
wandb: 🚀 View run electric-sweep-416 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g5joppgn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215030-g5joppgn/logs
wandb: Agent Starting Run: 7v4khofl with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215035-7v4khofl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-417
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7v4khofl
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run crisp-sweep-417 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7v4khofl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215035-7v4khofl/logs
wandb: Agent Starting Run: jl971ld6 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215040-jl971ld6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-418
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jl971ld6
wandb:                                                                                
wandb: 🚀 View run atomic-sweep-418 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jl971ld6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215040-jl971ld6/logs
wandb: Agent Starting Run: hvxwstjv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215046-hvxwstjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-419
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hvxwstjv
wandb:                                                                                
wandb: 🚀 View run youthful-sweep-419 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hvxwstjv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215046-hvxwstjv/logs
wandb: Agent Starting Run: psk662oj with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215051-psk662oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-420
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/psk662oj
wandb:                                                                                
wandb: 🚀 View run azure-sweep-420 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/psk662oj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215051-psk662oj/logs
wandb: Agent Starting Run: lyzsfo6h with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215057-lyzsfo6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-421
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lyzsfo6h
wandb:                                                                                
wandb: 🚀 View run grateful-sweep-421 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lyzsfo6h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215057-lyzsfo6h/logs
wandb: Agent Starting Run: 4th977er with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215103-4th977er
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-422
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4th977er
wandb:                                                                                
wandb: 🚀 View run sleek-sweep-422 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4th977er
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215103-4th977er/logs
wandb: Agent Starting Run: npdx3jyr with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215108-npdx3jyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-423
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/npdx3jyr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▃█▁▂▂▂▃▅▃▂
wandb:      train_rmse ▃█▁▂▂▂▃▅▃▂
wandb: validation_loss ▁▅▇███████
wandb: validation_rmse ▁▅▇███████
wandb: 
wandb: Run summary:
wandb:      train_loss 1160.30665
wandb:      train_rmse 34.06327
wandb: validation_loss 1095.89398
wandb: validation_rmse 33.10429
wandb: 
wandb: 🚀 View run polished-sweep-423 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/npdx3jyr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215108-npdx3jyr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6attyzhq with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215246-6attyzhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-424
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6attyzhq
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run rare-sweep-424 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6attyzhq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215246-6attyzhq/logs
wandb: Agent Starting Run: mo6b2v0a with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215252-mo6b2v0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-425
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mo6b2v0a
wandb:                                                                                
wandb: 🚀 View run floral-sweep-425 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mo6b2v0a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215252-mo6b2v0a/logs
wandb: Agent Starting Run: jxrdaqlu with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215257-jxrdaqlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-426
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxrdaqlu
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run wild-sweep-426 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxrdaqlu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215257-jxrdaqlu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kst2rfcx with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215312-kst2rfcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-427
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kst2rfcx
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run floral-sweep-427 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kst2rfcx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215312-kst2rfcx/logs
wandb: Agent Starting Run: aqv8amix with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215318-aqv8amix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-428
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aqv8amix
wandb:                                                                                
wandb: 🚀 View run hearty-sweep-428 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aqv8amix
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215318-aqv8amix/logs
wandb: Agent Starting Run: 3mmgx5po with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215323-3mmgx5po
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-429
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3mmgx5po
wandb:                                                                                
wandb: 🚀 View run genial-sweep-429 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3mmgx5po
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215323-3mmgx5po/logs
wandb: Agent Starting Run: q1i7nx0a with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215329-q1i7nx0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-430
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q1i7nx0a
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run decent-sweep-430 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q1i7nx0a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215329-q1i7nx0a/logs
wandb: Agent Starting Run: zs5zzzfm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215334-zs5zzzfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-431
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zs5zzzfm
wandb:                                                                                
wandb: 🚀 View run earthy-sweep-431 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zs5zzzfm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215334-zs5zzzfm/logs
wandb: Agent Starting Run: adjvlf6a with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215339-adjvlf6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-432
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/adjvlf6a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▂▂▁
wandb:      train_rmse █▇▆▅▅▄▃▂▂▁
wandb: validation_loss █▆▆▅▄▄▃▂▂▁
wandb: validation_rmse █▆▆▅▄▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 878.5615
wandb:      train_rmse 29.64054
wandb: validation_loss 884.36447
wandb: validation_rmse 29.73827
wandb: 
wandb: 🚀 View run snowy-sweep-432 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/adjvlf6a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215339-adjvlf6a/logs
wandb: Agent Starting Run: d4d88h3f with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215513-d4d88h3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-433
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d4d88h3f
wandb:                                                                                
wandb: 🚀 View run fearless-sweep-433 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d4d88h3f
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215513-d4d88h3f/logs
wandb: Agent Starting Run: 94s2njve with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215518-94s2njve
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-434
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/94s2njve
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run still-sweep-434 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/94s2njve
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215518-94s2njve/logs
wandb: Agent Starting Run: w0v1f6oe with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215523-w0v1f6oe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-435
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w0v1f6oe
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-435 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w0v1f6oe
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215523-w0v1f6oe/logs
wandb: Agent Starting Run: zcwbo51l with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215529-zcwbo51l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-436
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zcwbo51l
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 61.19971
wandb:      train_rmse 7.82302
wandb: validation_loss 88.00771
wandb: validation_rmse 9.38124
wandb: 
wandb: 🚀 View run young-sweep-436 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zcwbo51l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215529-zcwbo51l/logs
wandb: Agent Starting Run: bgslc1p4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215657-bgslc1p4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-437
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bgslc1p4
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run lively-sweep-437 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bgslc1p4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215657-bgslc1p4/logs
wandb: Agent Starting Run: 7hy1w0cu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215702-7hy1w0cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-438
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7hy1w0cu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▃▃▂▂▁▃▁
wandb: validation_rmse █▅▃▃▃▃▂▁▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 77.02636
wandb:      train_rmse 8.77647
wandb: validation_loss 66.68706
wandb: validation_rmse 8.16621
wandb: 
wandb: 🚀 View run glad-sweep-438 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7hy1w0cu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215702-7hy1w0cu/logs
wandb: Agent Starting Run: h1qeowby with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215833-h1qeowby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-439
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h1qeowby
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-439 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h1qeowby
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215833-h1qeowby/logs
wandb: Agent Starting Run: dlr7962e with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_215838-dlr7962e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-440
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dlr7962e
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 68.57444
wandb:      train_rmse 8.28097
wandb: validation_loss 73.47817
wandb: validation_rmse 8.57194
wandb: 
wandb: 🚀 View run sleek-sweep-440 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dlr7962e
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_215838-dlr7962e/logs
wandb: Agent Starting Run: 9ix6zdtz with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220007-9ix6zdtz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-441
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9ix6zdtz
wandb:                                                                                
wandb: 🚀 View run light-sweep-441 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9ix6zdtz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220007-9ix6zdtz/logs
wandb: Agent Starting Run: vydm4t2i with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220012-vydm4t2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-442
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vydm4t2i
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-442 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vydm4t2i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220012-vydm4t2i/logs
wandb: Agent Starting Run: q3njd8b7 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220017-q3njd8b7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-443
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q3njd8b7
wandb:                                                                                
wandb: 🚀 View run zany-sweep-443 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q3njd8b7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220017-q3njd8b7/logs
wandb: Agent Starting Run: kfxzwzmv with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220023-kfxzwzmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-444
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kfxzwzmv
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run smart-sweep-444 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kfxzwzmv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220023-kfxzwzmv/logs
wandb: Agent Starting Run: 41n51gjc with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220028-41n51gjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-445
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/41n51gjc
wandb:                                                                                
wandb: 🚀 View run polished-sweep-445 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/41n51gjc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220028-41n51gjc/logs
wandb: Agent Starting Run: nlh2kja4 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220033-nlh2kja4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-446
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nlh2kja4
wandb:                                                                                
wandb: 🚀 View run peachy-sweep-446 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nlh2kja4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220033-nlh2kja4/logs
wandb: Agent Starting Run: guiwtmxv with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220039-guiwtmxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-447
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/guiwtmxv
wandb:                                                                                
wandb: 🚀 View run serene-sweep-447 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/guiwtmxv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220039-guiwtmxv/logs
wandb: Agent Starting Run: eq4yuiot with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220044-eq4yuiot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-448
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eq4yuiot
wandb:                                                                                
wandb: 🚀 View run vague-sweep-448 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eq4yuiot
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220044-eq4yuiot/logs
wandb: Agent Starting Run: hgxaobbp with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220050-hgxaobbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-449
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hgxaobbp
wandb:                                                                                
wandb: 🚀 View run legendary-sweep-449 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hgxaobbp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220050-hgxaobbp/logs
wandb: Agent Starting Run: 234zxelo with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220055-234zxelo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-450
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/234zxelo
wandb:                                                                                
wandb: 🚀 View run vocal-sweep-450 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/234zxelo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220055-234zxelo/logs
wandb: Agent Starting Run: 2mses3c0 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220100-2mses3c0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-451
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2mses3c0
wandb:                                                                                
wandb: 🚀 View run lyric-sweep-451 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2mses3c0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220100-2mses3c0/logs
wandb: Agent Starting Run: sb2vm4mx with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220106-sb2vm4mx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-452
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sb2vm4mx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇▃▃▂▃▂▂▁▂▂▁▂▆▂▁▁▁▂▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁
wandb: validation_rmse ▇█▇▃▃▄▃▃▂▂▃▃▂▂▆▂▂▂▃▂▂▃▁▂▁▁▂▂▁▁▁▂▁▂▂▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 13.84707
wandb:      train_rmse 3.72117
wandb: validation_loss 4.45817
wandb: validation_rmse 2.11144
wandb: 
wandb: 🚀 View run super-sweep-452 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sb2vm4mx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220106-sb2vm4mx/logs
wandb: Agent Starting Run: se2cinc7 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220810-se2cinc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-453
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/se2cinc7
wandb:                                                                                
wandb: 🚀 View run drawn-sweep-453 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/se2cinc7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220810-se2cinc7/logs
wandb: Agent Starting Run: t1vyhsm9 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220815-t1vyhsm9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-454
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t1vyhsm9
wandb:                                                                                
wandb: 🚀 View run balmy-sweep-454 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t1vyhsm9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220815-t1vyhsm9/logs
wandb: Agent Starting Run: 6ybf019z with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220821-6ybf019z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-455
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ybf019z
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run magic-sweep-455 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ybf019z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220821-6ybf019z/logs
wandb: Agent Starting Run: gt351jay with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220826-gt351jay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-456
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gt351jay
wandb:                                                                                
wandb: 🚀 View run dulcet-sweep-456 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gt351jay
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220826-gt351jay/logs
wandb: Agent Starting Run: l59g1m4n with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220832-l59g1m4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-457
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l59g1m4n
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run snowy-sweep-457 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l59g1m4n
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220832-l59g1m4n/logs
wandb: Agent Starting Run: j9kuwcv3 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220837-j9kuwcv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-458
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j9kuwcv3
wandb:                                                                                
wandb: 🚀 View run swift-sweep-458 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j9kuwcv3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220837-j9kuwcv3/logs
wandb: Agent Starting Run: k0rlqubb with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220842-k0rlqubb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-459
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k0rlqubb
wandb:                                                                                
wandb: 🚀 View run light-sweep-459 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k0rlqubb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220842-k0rlqubb/logs
wandb: Agent Starting Run: l2zg9cty with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220848-l2zg9cty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-460
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l2zg9cty
wandb:                                                                                
wandb: 🚀 View run brisk-sweep-460 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l2zg9cty
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220848-l2zg9cty/logs
wandb: Agent Starting Run: 0ol8pnoj with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220853-0ol8pnoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-461
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ol8pnoj
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run comfy-sweep-461 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ol8pnoj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220853-0ol8pnoj/logs
wandb: Agent Starting Run: ykwvz5m4 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220859-ykwvz5m4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-462
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ykwvz5m4
wandb:                                                                                
wandb: 🚀 View run unique-sweep-462 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ykwvz5m4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220859-ykwvz5m4/logs
wandb: Agent Starting Run: l2h26s4g with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220904-l2h26s4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-463
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l2h26s4g
wandb:                                                                                
wandb: 🚀 View run dauntless-sweep-463 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l2h26s4g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220904-l2h26s4g/logs
wandb: Agent Starting Run: zjepak7k with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220909-zjepak7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-464
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zjepak7k
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -128: [128, -128]
wandb:                                                                                
wandb: 🚀 View run polished-sweep-464 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zjepak7k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220909-zjepak7k/logs
Run zjepak7k errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -128: [128, -128]

wandb: ERROR Run zjepak7k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -128: [128, -128]
wandb: ERROR 
wandb: Agent Starting Run: fj9h9693 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220915-fj9h9693
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-465
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fj9h9693
wandb:                                                                                
wandb: 🚀 View run young-sweep-465 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fj9h9693
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220915-fj9h9693/logs
wandb: Agent Starting Run: ztraa47i with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220920-ztraa47i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-466
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ztraa47i
wandb:                                                                                
wandb: 🚀 View run worthy-sweep-466 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ztraa47i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220920-ztraa47i/logs
wandb: Agent Starting Run: bznk1i78 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220926-bznk1i78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-467
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bznk1i78
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-467 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bznk1i78
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220926-bznk1i78/logs
wandb: Agent Starting Run: gga8ozc8 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220931-gga8ozc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-468
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gga8ozc8
wandb:                                                                                
wandb: 🚀 View run pleasant-sweep-468 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gga8ozc8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220931-gga8ozc8/logs
wandb: Agent Starting Run: smlvwghi with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220936-smlvwghi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-469
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/smlvwghi
wandb:                                                                                
wandb: 🚀 View run noble-sweep-469 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/smlvwghi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220936-smlvwghi/logs
wandb: Agent Starting Run: fj86sv5u with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_220942-fj86sv5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-470
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fj86sv5u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▄▂▂▂▂▁▃▁▂▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▃
wandb: validation_rmse █▇▅▃▂▃▂▂▄▂▃▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▂▂▁▁▁▂▁▁▁▂▁▁▁▄
wandb: 
wandb: Run summary:
wandb:      train_loss 12.42144
wandb:      train_rmse 3.52441
wandb: validation_loss 17.54504
wandb: validation_rmse 4.18868
wandb: 
wandb: 🚀 View run earthy-sweep-470 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fj86sv5u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_220942-fj86sv5u/logs
wandb: Agent Starting Run: x2z6hcd8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_221646-x2z6hcd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-471
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x2z6hcd8
wandb:                                                                                
wandb: 🚀 View run fragrant-sweep-471 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x2z6hcd8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_221646-x2z6hcd8/logs
wandb: Agent Starting Run: q1fn3sze with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_221653-q1fn3sze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-472
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q1fn3sze
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▆▄▁▁▁▁▁▁
wandb:      train_rmse ██▇▅▂▁▁▁▁▁
wandb: validation_loss █▇▅▂▁▁▁▁▁▁
wandb: validation_rmse █▇▆▃▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 93.09059
wandb:      train_rmse 9.64835
wandb: validation_loss 70.60563
wandb: validation_rmse 8.40272
wandb: 
wandb: 🚀 View run apricot-sweep-472 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q1fn3sze
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_221653-q1fn3sze/logs
wandb: Agent Starting Run: zd2ua83g with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_221827-zd2ua83g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-473
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zd2ua83g
wandb:                                                                                
wandb: 🚀 View run autumn-sweep-473 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zd2ua83g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_221827-zd2ua83g/logs
wandb: Agent Starting Run: k9hsggsd with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_221832-k9hsggsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-474
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k9hsggsd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▅▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 35.9589
wandb:      train_rmse 5.99657
wandb: validation_loss 11.18321
wandb: validation_rmse 3.34413
wandb: 
wandb: 🚀 View run usual-sweep-474 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k9hsggsd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_221832-k9hsggsd/logs
wandb: Agent Starting Run: ik9sxvl0 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222538-ik9sxvl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-475
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ik9sxvl0
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [1, -256]
wandb:                                                                                
wandb: 🚀 View run smart-sweep-475 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ik9sxvl0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222538-ik9sxvl0/logs
Run ik9sxvl0 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [1, -256]

wandb: ERROR Run ik9sxvl0 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, 1))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -256: [1, -256]
wandb: ERROR 
wandb: Agent Starting Run: ahtwaz1j with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222544-ahtwaz1j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-476
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ahtwaz1j
wandb:                                                                                
wandb: 🚀 View run happy-sweep-476 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ahtwaz1j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222544-ahtwaz1j/logs
wandb: Agent Starting Run: y5f6gvhq with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222549-y5f6gvhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-477
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y5f6gvhq
wandb:                                                                                
wandb: 🚀 View run hopeful-sweep-477 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y5f6gvhq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222549-y5f6gvhq/logs
wandb: Agent Starting Run: vtdelz06 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222554-vtdelz06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-478
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vtdelz06
wandb:                                                                                
wandb: 🚀 View run hearty-sweep-478 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vtdelz06
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222554-vtdelz06/logs
wandb: Agent Starting Run: uz1koshs with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222600-uz1koshs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-479
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uz1koshs
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-479 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uz1koshs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222600-uz1koshs/logs
wandb: Agent Starting Run: 2i1pifio with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222605-2i1pifio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-480
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2i1pifio
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▃▂▂▁▁▁▁▁
wandb:      train_rmse █▆▄▃▂▂▁▁▁▁
wandb: validation_loss █▅▃▂▂▁▁▁▁▁
wandb: validation_rmse █▆▄▃▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 80.51092
wandb:      train_rmse 8.97279
wandb: validation_loss 74.21084
wandb: validation_rmse 8.61457
wandb: 
wandb: 🚀 View run toasty-sweep-480 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2i1pifio
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222605-2i1pifio/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x3vp1dhv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222816-x3vp1dhv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-481
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x3vp1dhv
wandb:                                                                                
wandb: 🚀 View run ruby-sweep-481 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x3vp1dhv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222816-x3vp1dhv/logs
wandb: Agent Starting Run: azze200i with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222821-azze200i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-482
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/azze200i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▂▁▁▁▁▁▁▁
wandb:      train_rmse █▆▂▁▁▁▁▁▁▁
wandb: validation_loss █▄▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 103.16905
wandb:      train_rmse 10.15722
wandb: validation_loss 70.84387
wandb: validation_rmse 8.41688
wandb: 
wandb: 🚀 View run radiant-sweep-482 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/azze200i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222821-azze200i/logs
wandb: Agent Starting Run: qaoymqhg with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_222955-qaoymqhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-483
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qaoymqhg
wandb:                                                                                
wandb: 🚀 View run dandy-sweep-483 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qaoymqhg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_222955-qaoymqhg/logs
wandb: Agent Starting Run: y837lf54 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223000-y837lf54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-484
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y837lf54
wandb:                                                                                
wandb: 🚀 View run zesty-sweep-484 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y837lf54
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223000-y837lf54/logs
wandb: Agent Starting Run: f1x8tbd0 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223005-f1x8tbd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-485
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f1x8tbd0
wandb:                                                                                
wandb: 🚀 View run avid-sweep-485 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f1x8tbd0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223005-f1x8tbd0/logs
wandb: Agent Starting Run: biux7rlc with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223011-biux7rlc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-486
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/biux7rlc
wandb:                                                                                
wandb: 🚀 View run dazzling-sweep-486 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/biux7rlc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223011-biux7rlc/logs
wandb: Agent Starting Run: y6xaoxti with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223016-y6xaoxti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-487
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y6xaoxti
wandb:                                                                                
wandb: 🚀 View run bumbling-sweep-487 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y6xaoxti
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223016-y6xaoxti/logs
wandb: Agent Starting Run: ziuxd68g with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223022-ziuxd68g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-488
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ziuxd68g
wandb:                                                                                
wandb: 🚀 View run jolly-sweep-488 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ziuxd68g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223022-ziuxd68g/logs
wandb: Agent Starting Run: 6z1p2sfi with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223027-6z1p2sfi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-489
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6z1p2sfi
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-489 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6z1p2sfi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223027-6z1p2sfi/logs
wandb: Agent Starting Run: jrf025qo with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223033-jrf025qo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-490
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jrf025qo
wandb:                                                                                
wandb: 🚀 View run fluent-sweep-490 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jrf025qo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223033-jrf025qo/logs
wandb: Agent Starting Run: 2epde2cx with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223038-2epde2cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-491
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2epde2cx
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-491 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2epde2cx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223038-2epde2cx/logs
wandb: Agent Starting Run: djb056oh with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223043-djb056oh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-492
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/djb056oh
wandb:                                                                                
wandb: 🚀 View run easy-sweep-492 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/djb056oh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223043-djb056oh/logs
wandb: Agent Starting Run: 8i1gdxuo with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223049-8i1gdxuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-493
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8i1gdxuo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▇▇▆▅▄▂▁▁
wandb:      train_rmse ███▇▇▆▅▃▂▁
wandb: validation_loss ██▇▇▆▅▄▂▁▁
wandb: validation_rmse ██▇▇▆▆▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 86.19879
wandb:      train_rmse 9.28433
wandb: validation_loss 96.24784
wandb: validation_rmse 9.8106
wandb: 
wandb: 🚀 View run icy-sweep-493 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8i1gdxuo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223049-8i1gdxuo/logs
wandb: Agent Starting Run: vq887jl1 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223222-vq887jl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-494
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vq887jl1
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run wobbly-sweep-494 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vq887jl1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223222-vq887jl1/logs
wandb: Agent Starting Run: m6ekxx26 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223227-m6ekxx26
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-495
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m6ekxx26
wandb:                                                                                
wandb: 🚀 View run wandering-sweep-495 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m6ekxx26
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223227-m6ekxx26/logs
wandb: Agent Starting Run: upfhegjb with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223232-upfhegjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-496
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/upfhegjb
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-496 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/upfhegjb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223232-upfhegjb/logs
wandb: Agent Starting Run: 80ubm2u0 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223238-80ubm2u0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-497
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/80ubm2u0
wandb:                                                                                
wandb: 🚀 View run polar-sweep-497 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/80ubm2u0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223238-80ubm2u0/logs
wandb: Agent Starting Run: xmrax3pf with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223243-xmrax3pf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-498
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xmrax3pf
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run fiery-sweep-498 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xmrax3pf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223243-xmrax3pf/logs
wandb: Agent Starting Run: 7s4ryvde with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223248-7s4ryvde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-499
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7s4ryvde
wandb:                                                                                
wandb: 🚀 View run glamorous-sweep-499 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7s4ryvde
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223248-7s4ryvde/logs
wandb: Agent Starting Run: 989aayrq with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223254-989aayrq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-500
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/989aayrq
wandb:                                                                                
wandb: 🚀 View run sunny-sweep-500 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/989aayrq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223254-989aayrq/logs
wandb: Agent Starting Run: 73842nor with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223300-73842nor
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-501
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/73842nor
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [1, -256]
wandb:                                                                                
wandb: 🚀 View run apricot-sweep-501 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/73842nor
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223300-73842nor/logs
Run 73842nor errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [1, -256]

wandb: ERROR Run 73842nor errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, 1))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -256: [1, -256]
wandb: ERROR 
wandb: Agent Starting Run: o0oeands with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223305-o0oeands
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-502
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o0oeands
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run firm-sweep-502 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o0oeands
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223305-o0oeands/logs
wandb: Agent Starting Run: c9i5sfdx with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223310-c9i5sfdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-503
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c9i5sfdx
wandb:                                                                                
wandb: 🚀 View run true-sweep-503 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c9i5sfdx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223310-c9i5sfdx/logs
wandb: Agent Starting Run: o572x1vw with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223316-o572x1vw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-504
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o572x1vw
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run effortless-sweep-504 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o572x1vw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223316-o572x1vw/logs
wandb: Agent Starting Run: annrhdsm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223321-annrhdsm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-505
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/annrhdsm
wandb:                                                                                
wandb: 🚀 View run vibrant-sweep-505 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/annrhdsm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223321-annrhdsm/logs
wandb: Agent Starting Run: gerzcot8 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223327-gerzcot8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-506
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gerzcot8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▄▃▂▂▁▁▁▁
wandb:      train_rmse █▆▅▄▃▂▂▁▁▁
wandb: validation_loss █▅▃▂▂▁▁▁▁▁
wandb: validation_rmse █▆▄▃▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 76.04381
wandb:      train_rmse 8.72031
wandb: validation_loss 80.28734
wandb: validation_rmse 8.96032
wandb: 
wandb: 🚀 View run magic-sweep-506 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gerzcot8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223327-gerzcot8/logs
wandb: Agent Starting Run: qoe0q7w7 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223500-qoe0q7w7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-507
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qoe0q7w7
wandb:                                                                                
wandb: 🚀 View run azure-sweep-507 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qoe0q7w7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223500-qoe0q7w7/logs
wandb: Agent Starting Run: d28prt0k with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_223505-d28prt0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-508
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d28prt0k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: train_loss ▁                                       
wandb: train_rmse ▁                                       
wandb: 
wandb: Run summary:
wandb:      train_loss nan
wandb:      train_rmse nan
wandb: validation_loss nan
wandb: validation_rmse nan
wandb: 
wandb: 🚀 View run still-sweep-508 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d28prt0k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223505-d28prt0k/logs
wandb: Agent Starting Run: mxdfvbba with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_224209-mxdfvbba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-509
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mxdfvbba
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 80.29577
wandb:      train_rmse 8.96079
wandb: validation_loss 72.18873
wandb: validation_rmse 8.4964
wandb: 
wandb: 🚀 View run devout-sweep-509 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mxdfvbba
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_224209-mxdfvbba/logs
wandb: Agent Starting Run: vl4amehs with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_224337-vl4amehs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-510
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vl4amehs
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run smooth-sweep-510 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vl4amehs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_224337-vl4amehs/logs
Run vl4amehs errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run vl4amehs errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: b68rx3as with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_224343-b68rx3as
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-511
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b68rx3as
wandb:                                                                                
wandb: 🚀 View run dark-sweep-511 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/b68rx3as
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_224343-b68rx3as/logs
wandb: Agent Starting Run: uw41ebke with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_224348-uw41ebke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-512
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uw41ebke
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▇▆▅▄▃▃▂▁
wandb:      train_rmse ██▇▆▅▄▃▃▂▁
wandb: validation_loss █▆▆▅▄▄▂▂▁▁
wandb: validation_rmse █▆▆▅▄▄▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 894.16166
wandb:      train_rmse 29.90254
wandb: validation_loss 863.42142
wandb: validation_rmse 29.38403
wandb: 
wandb: 🚀 View run devout-sweep-512 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uw41ebke
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_224348-uw41ebke/logs
wandb: Agent Starting Run: tkc20f7m with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_224521-tkc20f7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-513
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tkc20f7m
wandb:                                                                                
wandb: 🚀 View run azure-sweep-513 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tkc20f7m
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_224521-tkc20f7m/logs
wandb: Agent Starting Run: m92cvpt2 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_224527-m92cvpt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-514
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m92cvpt2
wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:      train_loss nan
wandb:      train_rmse nan
wandb: validation_loss nan
wandb: validation_rmse nan
wandb: 
wandb: 🚀 View run visionary-sweep-514 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m92cvpt2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_224527-m92cvpt2/logs
wandb: Agent Starting Run: 3zhwf61i with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_225249-3zhwf61i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-515
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3zhwf61i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▃█▂▅▂▁▅▄▃▂▁▂▄▃▃▃▁▂▁▁▃▂▃▂▁▅▂▁▂▂▂▄▂▃▂▂▂▁▂▂
wandb: validation_rmse ▃█▂▆▃▁▅▄▄▂▄▁▃▄▃▅▄▂▂▁▁▅▄▂▃▂▄▆▃▁▃▂▂▄▃▃▂▂▃▂
wandb: 
wandb: Run summary:
wandb:      train_loss 1.60492
wandb:      train_rmse 1.26685
wandb: validation_loss 19.80657
wandb: validation_rmse 4.45046
wandb: 
wandb: 🚀 View run electric-sweep-515 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3zhwf61i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_225249-3zhwf61i/logs
wandb: Agent Starting Run: 7swx0shj with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_225954-7swx0shj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-516
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7swx0shj
wandb:                                                                                
wandb: 🚀 View run golden-sweep-516 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7swx0shj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_225954-7swx0shj/logs
wandb: Agent Starting Run: csipgib9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230001-csipgib9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-517
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/csipgib9
wandb:                                                                                
wandb: 🚀 View run stoic-sweep-517 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/csipgib9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230001-csipgib9/logs
wandb: Agent Starting Run: 0gxuyqfb with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230007-0gxuyqfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-518
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0gxuyqfb
wandb:                                                                                
wandb: 🚀 View run proud-sweep-518 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0gxuyqfb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230007-0gxuyqfb/logs
wandb: Agent Starting Run: s3tnfxyu with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230012-s3tnfxyu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-519
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s3tnfxyu
wandb:                                                                                
wandb: 🚀 View run celestial-sweep-519 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s3tnfxyu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230012-s3tnfxyu/logs
wandb: Agent Starting Run: ww84ajva with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230017-ww84ajva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-520
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ww84ajva
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 65.48076
wandb:      train_rmse 8.09202
wandb: validation_loss 69.37446
wandb: validation_rmse 8.32913
wandb: 
wandb: 🚀 View run deft-sweep-520 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ww84ajva
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230017-ww84ajva/logs
wandb: Agent Starting Run: 2gtllir4 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230146-2gtllir4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-521
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2gtllir4
wandb:                                                                                
wandb: 🚀 View run unique-sweep-521 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2gtllir4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230146-2gtllir4/logs
wandb: Agent Starting Run: k3t8hdue with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230151-k3t8hdue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-522
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k3t8hdue
wandb:                                                                                
wandb: 🚀 View run confused-sweep-522 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k3t8hdue
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230151-k3t8hdue/logs
wandb: Agent Starting Run: 3qocihr4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230156-3qocihr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-523
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3qocihr4
wandb:                                                                                
wandb: 🚀 View run lucky-sweep-523 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3qocihr4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230156-3qocihr4/logs
wandb: Agent Starting Run: sficj0ic with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230202-sficj0ic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-524
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sficj0ic
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run clean-sweep-524 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sficj0ic
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230202-sficj0ic/logs
Run sficj0ic errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run sficj0ic errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: hrsu3sbi with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230212-hrsu3sbi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-525
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hrsu3sbi
wandb:                                                                                
wandb: 🚀 View run smart-sweep-525 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hrsu3sbi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230212-hrsu3sbi/logs
wandb: Agent Starting Run: xnscy820 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230218-xnscy820
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-526
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xnscy820
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run ruby-sweep-526 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xnscy820
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230218-xnscy820/logs
wandb: Agent Starting Run: rvj6f7km with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230254-rvj6f7km
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-527
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rvj6f7km
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run dry-sweep-527 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rvj6f7km
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230254-rvj6f7km/logs
Run rvj6f7km errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run rvj6f7km errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: ru1ig03f with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_230259-ru1ig03f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-528
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ru1ig03f
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▃▃▁▁▁▁▁▂▁▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 7.62876
wandb:      train_rmse 2.76202
wandb: validation_loss 11.93801
wandb: validation_rmse 3.45514
wandb: 
wandb: 🚀 View run vague-sweep-528 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ru1ig03f
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_230259-ru1ig03f/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: detyzbre with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231009-detyzbre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-529
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/detyzbre
wandb:                                                                                
wandb: 🚀 View run laced-sweep-529 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/detyzbre
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231009-detyzbre/logs
wandb: Agent Starting Run: q0qcylml with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231016-q0qcylml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-530
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q0qcylml
wandb:                                                                                
wandb: 🚀 View run silver-sweep-530 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q0qcylml
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231016-q0qcylml/logs
wandb: Agent Starting Run: tez3sot1 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231022-tez3sot1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-531
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tez3sot1
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run super-sweep-531 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tez3sot1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231022-tez3sot1/logs
Run tez3sot1 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run tez3sot1 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 3ab9ehka with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231027-3ab9ehka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-532
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ab9ehka
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run crisp-sweep-532 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ab9ehka
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231027-3ab9ehka/logs
wandb: Agent Starting Run: rx4rjlue with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231037-rx4rjlue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-533
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rx4rjlue
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -64: [64, -64]
wandb:                                                                                
wandb: 🚀 View run pious-sweep-533 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rx4rjlue
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231037-rx4rjlue/logs
Run rx4rjlue errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -64: [64, -64]

wandb: ERROR Run rx4rjlue errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -64: [64, -64]
wandb: ERROR 
wandb: Agent Starting Run: fazggtbk with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231043-fazggtbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-534
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fazggtbk
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -832: [32, -832]
wandb:                                                                                
wandb: 🚀 View run classic-sweep-534 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fazggtbk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231043-fazggtbk/logs
Run fazggtbk errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -832: [32, -832]

wandb: ERROR Run fazggtbk errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -832: [32, -832]
wandb: ERROR 
wandb: Agent Starting Run: um6oc4gt with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231048-um6oc4gt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-535
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/um6oc4gt
wandb:                                                                                
wandb: 🚀 View run apricot-sweep-535 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/um6oc4gt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231048-um6oc4gt/logs
wandb: Agent Starting Run: wlg0ej7g with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231053-wlg0ej7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-536
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wlg0ej7g
wandb:                                                                                
wandb: 🚀 View run divine-sweep-536 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wlg0ej7g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231053-wlg0ej7g/logs
wandb: Agent Starting Run: sfqkn3r7 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231059-sfqkn3r7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-537
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sfqkn3r7
wandb:                                                                                
wandb: 🚀 View run mild-sweep-537 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sfqkn3r7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231059-sfqkn3r7/logs
wandb: Agent Starting Run: arsfy8hk with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231104-arsfy8hk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-538
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/arsfy8hk
wandb:                                                                                
wandb: 🚀 View run noble-sweep-538 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/arsfy8hk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231104-arsfy8hk/logs
wandb: Agent Starting Run: yjcso6zv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231109-yjcso6zv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-539
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yjcso6zv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 10.50581
wandb:      train_rmse 3.24127
wandb: validation_loss 11.67406
wandb: validation_rmse 3.41673
wandb: 
wandb: 🚀 View run vague-sweep-539 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yjcso6zv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231109-yjcso6zv/logs
wandb: Agent Starting Run: c8446dkc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231818-c8446dkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-540
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c8446dkc
wandb:                                                                                
wandb: 🚀 View run deep-sweep-540 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c8446dkc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231818-c8446dkc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: oxci2saz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231832-oxci2saz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-541
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oxci2saz
wandb:                                                                                
wandb: 🚀 View run amber-sweep-541 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oxci2saz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231832-oxci2saz/logs
wandb: Agent Starting Run: 82tqbqms with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_231838-82tqbqms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-542
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/82tqbqms
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▅▄▃▃▂▁
wandb:      train_rmse █▇▆▅▅▄▃▃▂▁
wandb: validation_loss █▇▄▄▄▃▁▂▂▁
wandb: validation_rmse █▇▅▄▄▃▁▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 781.98229
wandb:      train_rmse 27.96395
wandb: validation_loss 748.24731
wandb: validation_rmse 27.35411
wandb: 
wandb: 🚀 View run decent-sweep-542 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/82tqbqms
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_231838-82tqbqms/logs
wandb: Agent Starting Run: 6ifntxra with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232011-6ifntxra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-543
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ifntxra
wandb:                                                                                
wandb: 🚀 View run major-sweep-543 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ifntxra
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232011-6ifntxra/logs
wandb: Agent Starting Run: 5xesq6fv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232017-5xesq6fv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-544
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5xesq6fv
wandb:                                                                                
wandb: 🚀 View run colorful-sweep-544 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5xesq6fv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232017-5xesq6fv/logs
wandb: Agent Starting Run: ejw8kpqj with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232022-ejw8kpqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-545
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ejw8kpqj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇▅▆▅▄▃▂▁
wandb:      train_rmse █▇▇▅▆▅▄▃▂▁
wandb: validation_loss █▇▆▆▅▄▃▃▂▁
wandb: validation_rmse █▇▆▆▅▄▃▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 938.78264
wandb:      train_rmse 30.63956
wandb: validation_loss 939.84283
wandb: validation_rmse 30.65686
wandb: 
wandb: 🚀 View run logical-sweep-545 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ejw8kpqj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232022-ejw8kpqj/logs
wandb: Agent Starting Run: gn9z9ikt with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232156-gn9z9ikt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-546
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gn9z9ikt
wandb:                                                                                
wandb: 🚀 View run pleasant-sweep-546 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gn9z9ikt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232156-gn9z9ikt/logs
wandb: Agent Starting Run: 9kal6iy9 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232201-9kal6iy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-547
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9kal6iy9
wandb:                                                                                
wandb: 🚀 View run pleasant-sweep-547 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9kal6iy9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232201-9kal6iy9/logs
wandb: Agent Starting Run: mmymgw9z with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232207-mmymgw9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-548
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mmymgw9z
wandb:                                                                                
wandb: 🚀 View run breezy-sweep-548 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mmymgw9z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232207-mmymgw9z/logs
wandb: Agent Starting Run: zc288lgs with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232212-zc288lgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-549
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zc288lgs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▂▂▂▂▁▁▁
wandb:      train_rmse █▃▃▃▂▂▂▁▁▁
wandb: validation_loss █▅▄▄▃▃▂▂▁▁
wandb: validation_rmse █▅▄▄▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 370.80753
wandb:      train_rmse 19.25636
wandb: validation_loss 364.8096
wandb: validation_rmse 19.09999
wandb: 
wandb: 🚀 View run happy-sweep-549 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zc288lgs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232212-zc288lgs/logs
wandb: Agent Starting Run: 4a67bxwi with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232340-4a67bxwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-550
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4a67bxwi
wandb:                                                                                
wandb: 🚀 View run lilac-sweep-550 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4a67bxwi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232340-4a67bxwi/logs
wandb: Agent Starting Run: o4s5xy6u with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232346-o4s5xy6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-551
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o4s5xy6u
wandb:                                                                                
wandb: 🚀 View run hardy-sweep-551 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o4s5xy6u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232346-o4s5xy6u/logs
wandb: Agent Starting Run: ge8l8oxx with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232352-ge8l8oxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-552
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ge8l8oxx
wandb:                                                                                
wandb: 🚀 View run neat-sweep-552 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ge8l8oxx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232352-ge8l8oxx/logs
wandb: Agent Starting Run: 36zwqq7z with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_232357-36zwqq7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-553
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/36zwqq7z
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 7.14655
wandb:      train_rmse 2.6733
wandb: validation_loss 5.74556
wandb: validation_rmse 2.39699
wandb: 
wandb: 🚀 View run polar-sweep-553 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/36zwqq7z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232357-36zwqq7z/logs
wandb: Agent Starting Run: 08zlr2bi with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233102-08zlr2bi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-554
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/08zlr2bi
wandb:                                                                                
wandb: 🚀 View run trim-sweep-554 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/08zlr2bi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233102-08zlr2bi/logs
wandb: Agent Starting Run: jsg6z6w8 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233107-jsg6z6w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-555
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jsg6z6w8
wandb:                                                                                
wandb: 🚀 View run iconic-sweep-555 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jsg6z6w8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233107-jsg6z6w8/logs
wandb: Agent Starting Run: 0efb3gay with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233112-0efb3gay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-556
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0efb3gay
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run distinctive-sweep-556 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0efb3gay
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233112-0efb3gay/logs
wandb: Agent Starting Run: bkf71ubc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233123-bkf71ubc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-557
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bkf71ubc
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run fluent-sweep-557 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bkf71ubc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233123-bkf71ubc/logs
wandb: Agent Starting Run: 7wbhxnuf with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233128-7wbhxnuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-558
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7wbhxnuf
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run revived-sweep-558 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7wbhxnuf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233128-7wbhxnuf/logs
Run 7wbhxnuf errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 7wbhxnuf errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: bxp8qif6 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233138-bxp8qif6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-559
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bxp8qif6
wandb:                                                                                
wandb: 🚀 View run dashing-sweep-559 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bxp8qif6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233138-bxp8qif6/logs
wandb: Agent Starting Run: j0wev9cz with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233145-j0wev9cz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-560
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j0wev9cz
wandb:                                                                                
wandb: 🚀 View run cool-sweep-560 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j0wev9cz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233145-j0wev9cz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2sb3qzn5 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233230-2sb3qzn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-561
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2sb3qzn5
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run faithful-sweep-561 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2sb3qzn5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233230-2sb3qzn5/logs
wandb: Agent Starting Run: 48jovokc with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233240-48jovokc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-562
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/48jovokc
wandb:                                                                                
wandb: 🚀 View run earthy-sweep-562 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/48jovokc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233240-48jovokc/logs
wandb: Agent Starting Run: hpmxzwxf with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233246-hpmxzwxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-563
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hpmxzwxf
wandb:                                                                                
wandb: 🚀 View run dandy-sweep-563 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hpmxzwxf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233246-hpmxzwxf/logs
wandb: Agent Starting Run: 6n8kp6wj with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233252-6n8kp6wj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-564
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6n8kp6wj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▁▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse ▂▅█▂▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 19.29484
wandb:      train_rmse 4.39259
wandb: validation_loss 14.22492
wandb: validation_rmse 3.77159
wandb: 
wandb: 🚀 View run fast-sweep-564 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6n8kp6wj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233252-6n8kp6wj/logs
wandb: Agent Starting Run: q9xt6d17 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_233956-q9xt6d17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-565
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q9xt6d17
wandb:                                                                                
wandb: 🚀 View run curious-sweep-565 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q9xt6d17
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_233956-q9xt6d17/logs
wandb: Agent Starting Run: p3a5nh31 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234002-p3a5nh31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-566
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p3a5nh31
wandb:                                                                                
wandb: 🚀 View run spring-sweep-566 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p3a5nh31
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234002-p3a5nh31/logs
wandb: Agent Starting Run: nfpwkzyr with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234007-nfpwkzyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-567
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nfpwkzyr
wandb:                                                                                
wandb: 🚀 View run proud-sweep-567 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nfpwkzyr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234007-nfpwkzyr/logs
wandb: Agent Starting Run: hdldxkr7 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234012-hdldxkr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-568
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hdldxkr7
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run flowing-sweep-568 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hdldxkr7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234012-hdldxkr7/logs
wandb: Agent Starting Run: s9w4zuw1 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234018-s9w4zuw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-569
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s9w4zuw1
wandb:                                                                                
wandb: 🚀 View run silvery-sweep-569 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s9w4zuw1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234018-s9w4zuw1/logs
wandb: Agent Starting Run: 6hsmocow with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234023-6hsmocow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-570
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6hsmocow
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▂▁▁▁▁▁
wandb: validation_loss █▄▂▂▃▁▄▂▁▄
wandb: validation_rmse █▄▃▃▄▁▄▂▁▄
wandb: 
wandb: Run summary:
wandb:      train_loss 61.83594
wandb:      train_rmse 7.86358
wandb: validation_loss 204.36732
wandb: validation_rmse 14.29571
wandb: 
wandb: 🚀 View run twilight-sweep-570 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6hsmocow
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234023-6hsmocow/logs
wandb: Agent Starting Run: 8cyf61a8 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234152-8cyf61a8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-571
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8cyf61a8
wandb:                                                                                
wandb: 🚀 View run stellar-sweep-571 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8cyf61a8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234152-8cyf61a8/logs
wandb: Agent Starting Run: h03kl92k with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234157-h03kl92k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-572
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h03kl92k
wandb:                                                                                
wandb: 🚀 View run jumping-sweep-572 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h03kl92k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234157-h03kl92k/logs
wandb: Agent Starting Run: r0ir78in with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234203-r0ir78in
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-573
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r0ir78in
wandb:                                                                                
wandb: 🚀 View run deep-sweep-573 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r0ir78in
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234203-r0ir78in/logs
wandb: Agent Starting Run: teeu9etw with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234208-teeu9etw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-574
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/teeu9etw
wandb:                                                                                
wandb: 🚀 View run copper-sweep-574 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/teeu9etw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234208-teeu9etw/logs
wandb: Agent Starting Run: tcfv49ou with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234213-tcfv49ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-575
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tcfv49ou
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▂▂▂▂▁▂▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▁
wandb: validation_loss ▇▆▂▃█▆▂▆▁▃
wandb: validation_rmse ▇▆▂▃█▆▂▆▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 109.01238
wandb:      train_rmse 10.4409
wandb: validation_loss 261.71854
wandb: validation_rmse 16.17772
wandb: 
wandb: 🚀 View run major-sweep-575 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tcfv49ou
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234213-tcfv49ou/logs
wandb: Agent Starting Run: s9t5sykz with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234342-s9t5sykz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-576
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s9t5sykz
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run valiant-sweep-576 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s9t5sykz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234342-s9t5sykz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r3wmny5t with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234357-r3wmny5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-577
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r3wmny5t
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (6 x 30). Kernel size: (7 x 3). Kernel size can't be greater than actual input size
wandb:                                                                                
wandb: 🚀 View run comfy-sweep-577 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r3wmny5t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234357-r3wmny5t/logs
Run r3wmny5t errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (6 x 30). Kernel size: (7 x 3). Kernel size can't be greater than actual input size

wandb: ERROR Run r3wmny5t errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
wandb: ERROR     return self._conv_forward(input, self.weight, self.bias)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
wandb: ERROR     return F.conv2d(input, weight, bias, self.stride,
wandb: ERROR RuntimeError: Calculated padded input size per channel: (6 x 30). Kernel size: (7 x 3). Kernel size can't be greater than actual input size
wandb: ERROR 
wandb: Agent Starting Run: 1mg1ezn5 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234403-1mg1ezn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-578
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1mg1ezn5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▅▄▄▃▂▁
wandb:      train_rmse █▇▆▆▅▄▄▃▂▁
wandb: validation_loss █▅▅▄▃▃▂▂▁▁
wandb: validation_rmse █▅▅▄▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 938.68057
wandb:      train_rmse 30.63789
wandb: validation_loss 936.88412
wandb: validation_rmse 30.60856
wandb: 
wandb: 🚀 View run legendary-sweep-578 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1mg1ezn5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234403-1mg1ezn5/logs
wandb: Agent Starting Run: r39r736d with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234531-r39r736d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-579
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r39r736d
wandb:                                                                                
wandb: 🚀 View run honest-sweep-579 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r39r736d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234531-r39r736d/logs
wandb: Agent Starting Run: si0f6tgx with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234536-si0f6tgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-580
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/si0f6tgx
wandb:                                                                                
wandb: 🚀 View run vital-sweep-580 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/si0f6tgx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234536-si0f6tgx/logs
wandb: Agent Starting Run: vcnqcrpi with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234542-vcnqcrpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-581
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vcnqcrpi
wandb:                                                                                
wandb: 🚀 View run dauntless-sweep-581 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vcnqcrpi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234542-vcnqcrpi/logs
wandb: Agent Starting Run: m4qki7ew with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234547-m4qki7ew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-582
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m4qki7ew
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run stoic-sweep-582 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m4qki7ew
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234547-m4qki7ew/logs
wandb: Agent Starting Run: xkkydik5 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_234553-xkkydik5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-583
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xkkydik5
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.008 MB of 0.008 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▁▂▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 20.71294
wandb:      train_rmse 4.55115
wandb: validation_loss 47.85345
wandb: validation_rmse 6.91762
wandb: 
wandb: 🚀 View run silver-sweep-583 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xkkydik5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234553-xkkydik5/logs
wandb: Agent Starting Run: e9i8caz6 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235302-e9i8caz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-584
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e9i8caz6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss ▁▄█▆▇▇▆▆▇▇
wandb: validation_rmse ▁▄█▆▇▇▆▆▇▇
wandb: 
wandb: Run summary:
wandb:      train_loss 68.82199
wandb:      train_rmse 8.2959
wandb: validation_loss 373.79558
wandb: validation_rmse 19.33379
wandb: 
wandb: 🚀 View run scarlet-sweep-584 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e9i8caz6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235302-e9i8caz6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8o7wpv12 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235440-8o7wpv12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-585
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8o7wpv12
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run sparkling-sweep-585 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8o7wpv12
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235440-8o7wpv12/logs
wandb: Agent Starting Run: j8syy8lr with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235446-j8syy8lr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-586
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j8syy8lr
wandb:                                                                                
wandb: 🚀 View run cool-sweep-586 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/j8syy8lr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235446-j8syy8lr/logs
wandb: Agent Starting Run: c2rkf2dp with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235451-c2rkf2dp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-587
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c2rkf2dp
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [32, -256]
wandb:                                                                                
wandb: 🚀 View run stoic-sweep-587 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c2rkf2dp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235451-c2rkf2dp/logs
Run c2rkf2dp errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -256: [32, -256]

wandb: ERROR Run c2rkf2dp errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -256: [32, -256]
wandb: ERROR 
wandb: Agent Starting Run: o2vz7rzw with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235457-o2vz7rzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-588
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o2vz7rzw
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run upbeat-sweep-588 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o2vz7rzw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235457-o2vz7rzw/logs
wandb: Agent Starting Run: qu5vb8kk with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235502-qu5vb8kk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-589
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qu5vb8kk
wandb:                                                                                
wandb: 🚀 View run likely-sweep-589 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qu5vb8kk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235502-qu5vb8kk/logs
wandb: Agent Starting Run: kj3wec14 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235507-kj3wec14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-590
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kj3wec14
wandb:                                                                                
wandb: 🚀 View run sweepy-sweep-590 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kj3wec14
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235507-kj3wec14/logs
wandb: Agent Starting Run: inw5q0fm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235513-inw5q0fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-591
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/inw5q0fm
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run soft-sweep-591 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/inw5q0fm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235513-inw5q0fm/logs
wandb: Agent Starting Run: 0urscdbo with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235519-0urscdbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-592
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0urscdbo
wandb:                                                                                
wandb: 🚀 View run electric-sweep-592 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0urscdbo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235519-0urscdbo/logs
wandb: Agent Starting Run: a0gezx8h with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235524-a0gezx8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-593
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a0gezx8h
wandb:                                                                                
wandb: 🚀 View run lemon-sweep-593 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a0gezx8h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235524-a0gezx8h/logs
wandb: Agent Starting Run: iuylt7fa with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241120_235529-iuylt7fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-594
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iuylt7fa
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 12.54157
wandb:      train_rmse 3.54141
wandb: validation_loss 7.32049
wandb: validation_rmse 2.70564
wandb: 
wandb: 🚀 View run dainty-sweep-594 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iuylt7fa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_235529-iuylt7fa/logs
wandb: Agent Starting Run: rjw0mz74 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000244-rjw0mz74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-595
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rjw0mz74
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-595 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rjw0mz74
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000244-rjw0mz74/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 42iamrvf with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000259-42iamrvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-596
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/42iamrvf
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run super-sweep-596 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/42iamrvf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000259-42iamrvf/logs
wandb: Agent Starting Run: tr01qv6q with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000305-tr01qv6q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-597
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tr01qv6q
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 59.85674
wandb:      train_rmse 7.73671
wandb: validation_loss 97.01441
wandb: validation_rmse 9.84959
wandb: 
wandb: 🚀 View run unique-sweep-597 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tr01qv6q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000305-tr01qv6q/logs
wandb: Agent Starting Run: 2b0jxxvz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000438-2b0jxxvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-598
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2b0jxxvz
wandb:                                                                                
wandb: 🚀 View run divine-sweep-598 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2b0jxxvz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000438-2b0jxxvz/logs
wandb: Agent Starting Run: oe4lfolo with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000443-oe4lfolo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-599
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oe4lfolo
wandb:                                                                                
wandb: 🚀 View run royal-sweep-599 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oe4lfolo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000443-oe4lfolo/logs
wandb: Agent Starting Run: f6br19ta with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000449-f6br19ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-600
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f6br19ta
wandb:                                                                                
wandb: 🚀 View run jumping-sweep-600 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f6br19ta
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000449-f6br19ta/logs
wandb: Agent Starting Run: mry978v8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000454-mry978v8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-601
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mry978v8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▂▂▂▂▂▁▁▁
wandb:      train_rmse █▄▂▂▂▃▂▂▁▁
wandb: validation_loss ▂▂▁▄█▁▄▅▂▇
wandb: validation_rmse ▂▂▁▄█▁▄▅▂▇
wandb: 
wandb: Run summary:
wandb:      train_loss 143.4068
wandb:      train_rmse 11.97526
wandb: validation_loss 316.58159
wandb: validation_rmse 17.79274
wandb: 
wandb: 🚀 View run laced-sweep-601 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mry978v8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000454-mry978v8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x07dalmm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000632-x07dalmm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-602
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x07dalmm
wandb:                                                                                
wandb: 🚀 View run happy-sweep-602 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x07dalmm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000632-x07dalmm/logs
wandb: Agent Starting Run: o4qias0a with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000638-o4qias0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-603
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o4qias0a
wandb:                                                                                
wandb: 🚀 View run vague-sweep-603 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o4qias0a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000638-o4qias0a/logs
wandb: Agent Starting Run: l3yuyp6h with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000643-l3yuyp6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-604
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l3yuyp6h
wandb:                                                                                
wandb: 🚀 View run feasible-sweep-604 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l3yuyp6h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000643-l3yuyp6h/logs
wandb: Agent Starting Run: oxvcervl with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000649-oxvcervl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-605
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oxvcervl
wandb:                                                                                
wandb: 🚀 View run eager-sweep-605 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oxvcervl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000649-oxvcervl/logs
wandb: Agent Starting Run: wql2fl8y with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000654-wql2fl8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-606
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wql2fl8y
wandb:                                                                                
wandb: 🚀 View run stellar-sweep-606 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wql2fl8y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000654-wql2fl8y/logs
wandb: Agent Starting Run: oavc1i65 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000659-oavc1i65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-607
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oavc1i65
wandb:                                                                                
wandb: 🚀 View run royal-sweep-607 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oavc1i65
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000659-oavc1i65/logs
wandb: Agent Starting Run: 5wynj2vz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000705-5wynj2vz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-608
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5wynj2vz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▇▆▅▃▁▁▁▁
wandb:      train_rmse ██▇▇▅▃▁▁▁▁
wandb: validation_loss █▇▇▆▄▂▁▁▁▁
wandb: validation_rmse ██▇▆▅▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 66.54591
wandb:      train_rmse 8.15757
wandb: validation_loss 72.49345
wandb: validation_rmse 8.51431
wandb: 
wandb: 🚀 View run magic-sweep-608 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5wynj2vz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000705-5wynj2vz/logs
wandb: Agent Starting Run: 30jrdjnx with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000838-30jrdjnx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-609
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/30jrdjnx
wandb:                                                                                
wandb: 🚀 View run visionary-sweep-609 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/30jrdjnx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000838-30jrdjnx/logs
wandb: Agent Starting Run: r9f7rkrd with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_000843-r9f7rkrd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-610
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r9f7rkrd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▃▂▂▂▁▁
wandb:      train_rmse █▆▅▄▄▃▂▂▁▁
wandb: validation_loss █▇▅▄▃▃▂▂▁▁
wandb: validation_rmse █▇▆▅▄▃▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 171.05011
wandb:      train_rmse 13.07861
wandb: validation_loss 162.01224
wandb: validation_rmse 12.7284
wandb: 
wandb: 🚀 View run fancy-sweep-610 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r9f7rkrd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_000843-r9f7rkrd/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yhwruekg with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001021-yhwruekg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-611
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yhwruekg
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-611 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yhwruekg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001021-yhwruekg/logs
wandb: Agent Starting Run: d63yq6w5 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001027-d63yq6w5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-612
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d63yq6w5
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run gentle-sweep-612 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d63yq6w5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001027-d63yq6w5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xfuejizj with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001042-xfuejizj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-613
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xfuejizj
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run radiant-sweep-613 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xfuejizj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001042-xfuejizj/logs
wandb: Agent Starting Run: qhpwze6m with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001048-qhpwze6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-614
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qhpwze6m
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▅▃▃▂▂▁
wandb:      train_rmse █▆▆▅▅▄▃▂▂▁
wandb: validation_loss ▆█▇▅▅▄▃▃▂▁
wandb: validation_rmse ▆█▇▆▅▄▃▄▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 799.03777
wandb:      train_rmse 28.26726
wandb: validation_loss 752.9809
wandb: validation_rmse 27.4405
wandb: 
wandb: 🚀 View run balmy-sweep-614 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qhpwze6m
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001048-qhpwze6m/logs
wandb: Agent Starting Run: w5g1votk with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001221-w5g1votk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-615
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w5g1votk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 76.48051
wandb:      train_rmse 8.74531
wandb: validation_loss 73.4591
wandb: validation_rmse 8.57083
wandb: 
wandb: 🚀 View run azure-sweep-615 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w5g1votk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001221-w5g1votk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: em9d56pm with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001359-em9d56pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-616
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/em9d56pm
wandb:                                                                                
wandb: 🚀 View run giddy-sweep-616 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/em9d56pm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001359-em9d56pm/logs
wandb: Agent Starting Run: fs1vcw6l with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001405-fs1vcw6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-617
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fs1vcw6l
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▄▃▃▂▂▁▁▁
wandb:      train_rmse █▆▅▄▃▃▂▂▁▁
wandb: validation_loss █▆▅▄▃▂▂▂▁▁
wandb: validation_rmse █▆▅▄▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 159.04165
wandb:      train_rmse 12.61117
wandb: validation_loss 154.14614
wandb: validation_rmse 12.41556
wandb: 
wandb: 🚀 View run dauntless-sweep-617 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fs1vcw6l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001405-fs1vcw6l/logs
wandb: Agent Starting Run: apitdf9e with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001544-apitdf9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-618
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/apitdf9e
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (4 x 27). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
wandb:                                                                                
wandb: 🚀 View run restful-sweep-618 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/apitdf9e
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001544-apitdf9e/logs
Run apitdf9e errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (4 x 27). Kernel size: (5 x 5). Kernel size can't be greater than actual input size

wandb: ERROR Run apitdf9e errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
wandb: ERROR     return self._conv_forward(input, self.weight, self.bias)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
wandb: ERROR     return F.conv2d(input, weight, bias, self.stride,
wandb: ERROR RuntimeError: Calculated padded input size per channel: (4 x 27). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
wandb: ERROR 
wandb: Agent Starting Run: 4aq7jnfy with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001549-4aq7jnfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-619
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4aq7jnfy
wandb:                                                                                
wandb: 🚀 View run colorful-sweep-619 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4aq7jnfy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001549-4aq7jnfy/logs
wandb: Agent Starting Run: dir1yahx with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001554-dir1yahx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-620
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dir1yahx
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-620 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dir1yahx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001554-dir1yahx/logs
wandb: Agent Starting Run: d5avgjp3 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001600-d5avgjp3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-621
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d5avgjp3
wandb:                                                                                
wandb: 🚀 View run gallant-sweep-621 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d5avgjp3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001600-d5avgjp3/logs
wandb: Agent Starting Run: 5w5uqfaj with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001605-5w5uqfaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-622
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5w5uqfaj
wandb:                                                                                
wandb: 🚀 View run different-sweep-622 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5w5uqfaj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001605-5w5uqfaj/logs
wandb: Agent Starting Run: af9iwee0 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001610-af9iwee0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-623
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/af9iwee0
wandb:                                                                                
wandb: 🚀 View run peach-sweep-623 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/af9iwee0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001610-af9iwee0/logs
wandb: Agent Starting Run: oaqw60n4 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001616-oaqw60n4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-624
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oaqw60n4
wandb:                                                                                
wandb: 🚀 View run devout-sweep-624 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oaqw60n4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001616-oaqw60n4/logs
wandb: Agent Starting Run: znealfm7 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001621-znealfm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-625
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/znealfm7
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run earnest-sweep-625 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/znealfm7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001621-znealfm7/logs
wandb: Agent Starting Run: 59u26anc with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001626-59u26anc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-626
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/59u26anc
wandb:                                                                                
wandb: 🚀 View run noble-sweep-626 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/59u26anc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001626-59u26anc/logs
wandb: Agent Starting Run: 25yln7fn with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001632-25yln7fn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-627
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/25yln7fn
wandb:                                                                                
wandb: 🚀 View run magic-sweep-627 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/25yln7fn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001632-25yln7fn/logs
wandb: Agent Starting Run: 1zt6f6ji with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001637-1zt6f6ji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-628
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1zt6f6ji
wandb:                                                                                
wandb: 🚀 View run zesty-sweep-628 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1zt6f6ji
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001637-1zt6f6ji/logs
wandb: Agent Starting Run: o3lbn8rr with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001642-o3lbn8rr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-629
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o3lbn8rr
wandb:                                                                                
wandb: 🚀 View run wise-sweep-629 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/o3lbn8rr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001642-o3lbn8rr/logs
wandb: Agent Starting Run: yi5ntjju with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001648-yi5ntjju
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-630
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yi5ntjju
wandb:                                                                                
wandb: 🚀 View run smooth-sweep-630 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yi5ntjju
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001648-yi5ntjju/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xq9p252w with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001722-xq9p252w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-631
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xq9p252w
wandb:                                                                                
wandb: 🚀 View run gallant-sweep-631 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xq9p252w
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001722-xq9p252w/logs
wandb: Agent Starting Run: mta3edbc with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001726-mta3edbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-632
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mta3edbc
wandb:                                                                                
wandb: 🚀 View run electric-sweep-632 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mta3edbc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001726-mta3edbc/logs
wandb: Agent Starting Run: 2hznv1m2 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001732-2hznv1m2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-633
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2hznv1m2
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run toasty-sweep-633 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2hznv1m2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001732-2hznv1m2/logs
Run 2hznv1m2 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 2hznv1m2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: peji0yz5 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001737-peji0yz5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-634
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/peji0yz5
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run sweet-sweep-634 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/peji0yz5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001737-peji0yz5/logs
Run peji0yz5 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run peji0yz5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 4ni8zjhp with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001742-4ni8zjhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-635
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4ni8zjhp
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run noble-sweep-635 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4ni8zjhp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001742-4ni8zjhp/logs
wandb: Agent Starting Run: fh5q6s08 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001748-fh5q6s08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-636
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fh5q6s08
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▁▁▁▅▂▆▂▃▄█
wandb: validation_rmse ▁▁▁▅▂▆▃▃▅█
wandb: 
wandb: Run summary:
wandb:      train_loss 73.12668
wandb:      train_rmse 8.55141
wandb: validation_loss 386.17976
wandb: validation_rmse 19.65146
wandb: 
wandb: 🚀 View run snowy-sweep-636 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fh5q6s08
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001748-fh5q6s08/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4f8jkhx9 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001926-4f8jkhx9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-637
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4f8jkhx9
wandb:                                                                                
wandb: 🚀 View run electric-sweep-637 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4f8jkhx9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001926-4f8jkhx9/logs
wandb: Agent Starting Run: 9w7w4qzc with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001931-9w7w4qzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-638
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9w7w4qzc
wandb:                                                                                
wandb: 🚀 View run honest-sweep-638 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9w7w4qzc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001931-9w7w4qzc/logs
wandb: Agent Starting Run: 8gr3smpu with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001937-8gr3smpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-639
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8gr3smpu
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run devoted-sweep-639 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8gr3smpu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001937-8gr3smpu/logs
wandb: Agent Starting Run: e5s6o4na with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001942-e5s6o4na
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-640
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e5s6o4na
wandb:                                                                                
wandb: 🚀 View run icy-sweep-640 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e5s6o4na
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001942-e5s6o4na/logs
wandb: Agent Starting Run: ulltlg94 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001947-ulltlg94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-641
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ulltlg94
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-641 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ulltlg94
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001947-ulltlg94/logs
wandb: Agent Starting Run: v9koxz6k with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001953-v9koxz6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-642
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v9koxz6k
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run rosy-sweep-642 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v9koxz6k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001953-v9koxz6k/logs
wandb: Agent Starting Run: xfpkwcus with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_001958-xfpkwcus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-643
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xfpkwcus
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run wandering-sweep-643 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xfpkwcus
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_001958-xfpkwcus/logs
wandb: Agent Starting Run: d437xohb with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_002003-d437xohb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-644
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d437xohb
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇█▂▂▂▄▂▄▂▂▂▄▁▂▁▂▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▂▂▁▁▁▁
wandb: validation_rmse █▇█▃▃▂▅▂▅▃▂▂▅▂▂▂▂▁▂▂▁▂▂▂▂▁▁▁▁▂▁▁▁▁▃▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 8.59592
wandb:      train_rmse 2.93188
wandb: validation_loss 6.46316
wandb: validation_rmse 2.54227
wandb: 
wandb: 🚀 View run peachy-sweep-644 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d437xohb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_002003-d437xohb/logs
wandb: Agent Starting Run: 3gscw6hc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_002703-3gscw6hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-645
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3gscw6hc
wandb:                                                                                
wandb: 🚀 View run dainty-sweep-645 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3gscw6hc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_002703-3gscw6hc/logs
wandb: Agent Starting Run: pwnepmi9 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_002708-pwnepmi9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-646
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pwnepmi9
wandb:                                                                                
wandb: 🚀 View run mild-sweep-646 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pwnepmi9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_002708-pwnepmi9/logs
wandb: Agent Starting Run: 4d4qujeq with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_002714-4d4qujeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-647
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4d4qujeq
wandb:                                                                                
wandb: 🚀 View run swift-sweep-647 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4d4qujeq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_002714-4d4qujeq/logs
wandb: Agent Starting Run: wym1c11g with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_002719-wym1c11g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-648
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wym1c11g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▄▃▂▂▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss █▄▅▃▄▄▂▂▁▂
wandb: validation_rmse █▄▅▃▄▄▂▃▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 755.03482
wandb:      train_rmse 27.4779
wandb: validation_loss 668.50821
wandb: validation_rmse 25.85553
wandb: 
wandb: 🚀 View run true-sweep-648 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wym1c11g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_002719-wym1c11g/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bspjgpyj with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_002857-bspjgpyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-649
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bspjgpyj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▄▅▇▄▁█▃▃▃▄
wandb:      train_rmse ▄▅▇▄▁█▃▃▃▄
wandb: validation_loss ▁▇██▆▇▇▆▆▆
wandb: validation_rmse ▁▇██▆▇▇▆▆▆
wandb: 
wandb: Run summary:
wandb:      train_loss 970.52271
wandb:      train_rmse 31.15321
wandb: validation_loss 970.99222
wandb: validation_rmse 31.16075
wandb: 
wandb: 🚀 View run comic-sweep-649 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bspjgpyj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_002857-bspjgpyj/logs
wandb: Agent Starting Run: fz8d8ky3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003025-fz8d8ky3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-650
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fz8d8ky3
wandb:                                                                                
wandb: 🚀 View run desert-sweep-650 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fz8d8ky3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003025-fz8d8ky3/logs
wandb: Agent Starting Run: pyyug0mx with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003031-pyyug0mx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-651
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pyyug0mx
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-651 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pyyug0mx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003031-pyyug0mx/logs
wandb: Agent Starting Run: g1plg6et with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003037-g1plg6et
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-652
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g1plg6et
wandb:                                                                                
wandb: 🚀 View run youthful-sweep-652 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g1plg6et
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003037-g1plg6et/logs
wandb: Agent Starting Run: jnnz5ur2 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003042-jnnz5ur2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-653
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jnnz5ur2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▇█▆▅▅▃▅▂▃▁
wandb:      train_rmse ▇█▆▅▅▃▅▂▃▁
wandb: validation_loss ▆▇██▆▅▅▃▁▁
wandb: validation_rmse ▆▇██▆▅▅▃▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 908.78963
wandb:      train_rmse 30.14614
wandb: validation_loss 909.16547
wandb: validation_rmse 30.15237
wandb: 
wandb: 🚀 View run silver-sweep-653 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jnnz5ur2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003042-jnnz5ur2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xykd9ev8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003220-xykd9ev8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-654
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xykd9ev8
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run volcanic-sweep-654 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xykd9ev8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003220-xykd9ev8/logs
wandb: Agent Starting Run: ojycprya with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003226-ojycprya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-655
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ojycprya
wandb:                                                                                
wandb: 🚀 View run rose-sweep-655 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ojycprya
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003226-ojycprya/logs
wandb: Agent Starting Run: z3jw3d7y with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003231-z3jw3d7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-656
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z3jw3d7y
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss ▁█▇█▄▃▆▇▄▁
wandb: validation_rmse ▁███▄▄▆▇▅▁
wandb: 
wandb: Run summary:
wandb:      train_loss 67.9075
wandb:      train_rmse 8.2406
wandb: validation_loss 72.96353
wandb: validation_rmse 8.54187
wandb: 
wandb: 🚀 View run light-sweep-656 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z3jw3d7y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003231-z3jw3d7y/logs
wandb: Agent Starting Run: jsy8dy1t with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_003404-jsy8dy1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-657
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jsy8dy1t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ██▇▆▆▄▄▃▃▂▂▂▂▂▁▁▁▂▁▂▁▂▂▁▁▁▂▁▂▂▁▁▁▁▃▁▁▁▁▁
wandb: validation_rmse ██▇▇▆▅▅▃▃▃▂▂▃▃▂▂▂▂▁▂▁▃▂▂▁▁▃▁▂▂▁▁▂▁▃▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 6.96576
wandb:      train_rmse 2.63927
wandb: validation_loss 8.17211
wandb: validation_rmse 2.85869
wandb: 
wandb: 🚀 View run avid-sweep-657 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jsy8dy1t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003404-jsy8dy1t/logs
wandb: Agent Starting Run: mhlkutds with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004110-mhlkutds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-658
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mhlkutds
wandb:                                                                                
wandb: 🚀 View run robust-sweep-658 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mhlkutds
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004110-mhlkutds/logs
wandb: Agent Starting Run: k6zcj0om with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004115-k6zcj0om
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-659
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k6zcj0om
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run stellar-sweep-659 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k6zcj0om
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004115-k6zcj0om/logs
Run k6zcj0om errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run k6zcj0om errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: tr5atsot with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004121-tr5atsot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-660
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tr5atsot
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▅▄▃▂▂▁
wandb:      train_rmse █▇▇▆▅▄▃▃▂▁
wandb: validation_loss █▇▆▆▅▄▃▂▂▁
wandb: validation_rmse █▇▆▆▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 532.85578
wandb:      train_rmse 23.08367
wandb: validation_loss 594.07837
wandb: validation_rmse 24.37372
wandb: 
wandb: 🚀 View run restful-sweep-660 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tr5atsot
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004121-tr5atsot/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: q9nhfvqe with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004258-q9nhfvqe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-661
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q9nhfvqe
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run good-sweep-661 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q9nhfvqe
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004258-q9nhfvqe/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wc2qmdxb with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004313-wc2qmdxb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-662
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wc2qmdxb
wandb:                                                                                
wandb: 🚀 View run neat-sweep-662 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wc2qmdxb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004313-wc2qmdxb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fmmosiia with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004329-fmmosiia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-663
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fmmosiia
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run twilight-sweep-663 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fmmosiia
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004329-fmmosiia/logs
wandb: Agent Starting Run: 3lkix7ne with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004335-3lkix7ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-664
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3lkix7ne
wandb:                                                                                
wandb: 🚀 View run fresh-sweep-664 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3lkix7ne
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004335-3lkix7ne/logs
wandb: Agent Starting Run: g50ymm59 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004340-g50ymm59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-665
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g50ymm59
wandb:                                                                                
wandb: 🚀 View run lively-sweep-665 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g50ymm59
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004340-g50ymm59/logs
wandb: Agent Starting Run: ptbe52wv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004346-ptbe52wv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-666
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ptbe52wv
wandb:                                                                                
wandb: 🚀 View run fearless-sweep-666 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ptbe52wv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004346-ptbe52wv/logs
wandb: Agent Starting Run: tdvtwn9z with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004352-tdvtwn9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-667
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tdvtwn9z
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▃▄▂▃▁▁
wandb:      train_rmse █▆▅▅▃▄▂▃▁▁
wandb: validation_loss ▄▇▇█▁▄▃▅▁▂
wandb: validation_rmse ▄▇▇█▁▄▃▅▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 893.28893
wandb:      train_rmse 29.88794
wandb: validation_loss 891.521
wandb: validation_rmse 29.85835
wandb: 
wandb: 🚀 View run dashing-sweep-667 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tdvtwn9z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004352-tdvtwn9z/logs
wandb: Agent Starting Run: hd6db5rp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004525-hd6db5rp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-668
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hd6db5rp
wandb:                                                                                
wandb: 🚀 View run comfy-sweep-668 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hd6db5rp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004525-hd6db5rp/logs
wandb: Agent Starting Run: de5q6sla with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004530-de5q6sla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-669
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/de5q6sla
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run stoic-sweep-669 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/de5q6sla
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004530-de5q6sla/logs
wandb: Agent Starting Run: 1hqlld7t with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004535-1hqlld7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-670
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1hqlld7t
wandb:                                                                                
wandb: 🚀 View run pretty-sweep-670 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1hqlld7t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004535-1hqlld7t/logs
wandb: Agent Starting Run: jpmoxcvv with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004541-jpmoxcvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-671
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jpmoxcvv
wandb:                                                                                
wandb: 🚀 View run bright-sweep-671 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jpmoxcvv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004541-jpmoxcvv/logs
wandb: Agent Starting Run: v3f3h4ll with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004546-v3f3h4ll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-672
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v3f3h4ll
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -896: [128, -896]
wandb:                                                                                
wandb: 🚀 View run efficient-sweep-672 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v3f3h4ll
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004546-v3f3h4ll/logs
Run v3f3h4ll errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -896: [128, -896]

wandb: ERROR Run v3f3h4ll errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -896: [128, -896]
wandb: ERROR 
wandb: Agent Starting Run: x359inin with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004551-x359inin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-673
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x359inin
wandb:                                                                                
wandb: 🚀 View run worldly-sweep-673 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x359inin
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004551-x359inin/logs
wandb: Agent Starting Run: 1rbnf0fq with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004557-1rbnf0fq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-674
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1rbnf0fq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▇▇▆▅▄▃▂▁
wandb:      train_rmse ██▇▇▆▅▅▄▂▁
wandb: validation_loss ██▇▇▆▅▅▄▂▁
wandb: validation_rmse ██▇▇▇▅▅▄▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 508.31441
wandb:      train_rmse 22.54583
wandb: validation_loss 450.78357
wandb: validation_rmse 21.23166
wandb: 
wandb: 🚀 View run cool-sweep-674 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1rbnf0fq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004557-1rbnf0fq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k0ielp2h with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004735-k0ielp2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-675
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k0ielp2h
wandb:                                                                                
wandb: 🚀 View run denim-sweep-675 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k0ielp2h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004735-k0ielp2h/logs
wandb: Agent Starting Run: ah3d4qh8 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004740-ah3d4qh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-676
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ah3d4qh8
wandb:                                                                                
wandb: 🚀 View run feasible-sweep-676 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ah3d4qh8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004740-ah3d4qh8/logs
wandb: Agent Starting Run: 4eh4yqgg with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004746-4eh4yqgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-677
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4eh4yqgg
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run cerulean-sweep-677 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4eh4yqgg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004746-4eh4yqgg/logs
wandb: Agent Starting Run: m06xtmyc with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004751-m06xtmyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-678
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m06xtmyc
wandb:                                                                                
wandb: 🚀 View run olive-sweep-678 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m06xtmyc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004751-m06xtmyc/logs
wandb: Agent Starting Run: l22frl9n with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004757-l22frl9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-679
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l22frl9n
wandb:                                                                                
wandb: 🚀 View run zany-sweep-679 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l22frl9n
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004757-l22frl9n/logs
wandb: Agent Starting Run: yxv52289 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004802-yxv52289
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-680
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yxv52289
wandb:                                                                                
wandb: 🚀 View run earthy-sweep-680 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yxv52289
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004802-yxv52289/logs
wandb: Agent Starting Run: zengfhcz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004808-zengfhcz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-681
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zengfhcz
wandb:                                                                                
wandb: 🚀 View run bright-sweep-681 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zengfhcz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004808-zengfhcz/logs
wandb: Agent Starting Run: 4xc16i37 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004813-4xc16i37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-682
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4xc16i37
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run polar-sweep-682 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4xc16i37
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004813-4xc16i37/logs
wandb: Agent Starting Run: 7p3jaz1w with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004818-7p3jaz1w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-683
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7p3jaz1w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▃▃▂▂▁▁
wandb:      train_rmse █▆▅▄▃▃▂▂▁▁
wandb: validation_loss █▆▅▄▃▃▂▂▁▁
wandb: validation_rmse █▆▅▄▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 985.23506
wandb:      train_rmse 31.38845
wandb: validation_loss 982.3541
wandb: validation_rmse 31.34253
wandb: 
wandb: 🚀 View run deep-sweep-683 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7p3jaz1w
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004818-7p3jaz1w/logs
wandb: Agent Starting Run: curgx9lz with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_004952-curgx9lz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-684
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/curgx9lz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 1.958
wandb:      train_rmse 1.39928
wandb: validation_loss 6.2892
wandb: validation_rmse 2.50783
wandb: 
wandb: 🚀 View run lively-sweep-684 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/curgx9lz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_004952-curgx9lz/logs
wandb: Agent Starting Run: wzaxd4su with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005706-wzaxd4su
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-685
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wzaxd4su
wandb:                                                                                
wandb: 🚀 View run honest-sweep-685 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wzaxd4su
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005706-wzaxd4su/logs
wandb: Agent Starting Run: 92dje6rn with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005711-92dje6rn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-686
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/92dje6rn
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run pious-sweep-686 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/92dje6rn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005711-92dje6rn/logs
wandb: Agent Starting Run: 5kj939u5 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005721-5kj939u5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-687
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5kj939u5
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
    test_outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: integer out of range
wandb:                                                                                
wandb: 🚀 View run silvery-sweep-687 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5kj939u5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005721-5kj939u5/logs
Run 5kj939u5 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
    test_outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: integer out of range

wandb: ERROR Run 5kj939u5 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
wandb: ERROR     test_outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: integer out of range
wandb: ERROR 
wandb: Agent Starting Run: d9zrlyf7 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005737-d9zrlyf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-688
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d9zrlyf7
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-688 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d9zrlyf7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005737-d9zrlyf7/logs
wandb: Agent Starting Run: qb5atqjs with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005742-qb5atqjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-689
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qb5atqjs
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run dauntless-sweep-689 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qb5atqjs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005742-qb5atqjs/logs
wandb: Agent Starting Run: spdyjko8 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005748-spdyjko8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-690
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/spdyjko8
wandb:                                                                                
wandb: 🚀 View run logical-sweep-690 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/spdyjko8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005748-spdyjko8/logs
wandb: Agent Starting Run: f986rlmr with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005753-f986rlmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-691
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f986rlmr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇█▄▁▅▄▄▆
wandb:      train_rmse █▇▇█▄▁▅▄▄▆
wandb: validation_loss ▆▁▁▂▄▅▃▇█▂
wandb: validation_rmse ▆▁▁▂▄▅▃▇█▂
wandb: 
wandb: Run summary:
wandb:      train_loss 984.89417
wandb:      train_rmse 31.38302
wandb: validation_loss 976.7717
wandb: validation_rmse 31.25335
wandb: 
wandb: 🚀 View run dark-sweep-691 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f986rlmr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005753-f986rlmr/logs
wandb: Agent Starting Run: wm0an4av with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005927-wm0an4av
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-692
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wm0an4av
wandb:                                                                                
wandb: 🚀 View run smart-sweep-692 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wm0an4av
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005927-wm0an4av/logs
wandb: Agent Starting Run: zyxustui with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_005932-zyxustui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-693
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zyxustui
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▁▂▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▁▁▁▁
wandb: validation_loss █▂▁▂▂▃▂▁▁▂
wandb: validation_rmse █▃▂▃▂▃▂▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 95.92357
wandb:      train_rmse 9.79406
wandb: validation_loss 207.21228
wandb: validation_rmse 14.39487
wandb: 
wandb: 🚀 View run fragrant-sweep-693 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zyxustui
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005932-zyxustui/logs
wandb: Agent Starting Run: s1ymfgpf with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010105-s1ymfgpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-694
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s1ymfgpf
wandb:                                                                                
wandb: 🚀 View run solar-sweep-694 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s1ymfgpf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010105-s1ymfgpf/logs
wandb: Agent Starting Run: aknbymyq with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010110-aknbymyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-695
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aknbymyq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▃▂▂▁▁
wandb:      train_rmse █▆▅▅▄▃▂▂▁▁
wandb: validation_loss █▆▄▅▃▃▂▁▂▁
wandb: validation_rmse █▆▄▅▃▃▂▁▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 917.96157
wandb:      train_rmse 30.29788
wandb: validation_loss 908.18665
wandb: validation_rmse 30.13614
wandb: 
wandb: 🚀 View run dry-sweep-695 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/aknbymyq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010110-aknbymyq/logs
wandb: Agent Starting Run: g0wb7pu6 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010244-g0wb7pu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-696
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g0wb7pu6
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x3x27). Calculated output size: (16x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run frosty-sweep-696 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g0wb7pu6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010244-g0wb7pu6/logs
Run g0wb7pu6 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x3x27). Calculated output size: (16x0x6). Output size is too small

wandb: ERROR Run g0wb7pu6 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (16x3x27). Calculated output size: (16x0x6). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: k1wopcev with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010249-k1wopcev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-697
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k1wopcev
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run leafy-sweep-697 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k1wopcev
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010249-k1wopcev/logs
wandb: Agent Starting Run: 250z9t02 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010254-250z9t02
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-698
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/250z9t02
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run pretty-sweep-698 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/250z9t02
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010254-250z9t02/logs
Run 250z9t02 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 250z9t02 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: n6xhcfv1 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010301-n6xhcfv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-699
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/n6xhcfv1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▄▃▂▂▁
wandb:      train_rmse █▇▆▅▅▄▃▂▂▁
wandb: validation_loss █▇▆▅▅▄▃▂▂▁
wandb: validation_rmse █▇▆▅▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 536.28704
wandb:      train_rmse 23.15787
wandb: validation_loss 661.24338
wandb: validation_rmse 25.71465
wandb: 
wandb: 🚀 View run noble-sweep-699 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/n6xhcfv1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010301-n6xhcfv1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rxeezdjs with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010444-rxeezdjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-700
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rxeezdjs
wandb:                                                                                
wandb: 🚀 View run silver-sweep-700 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rxeezdjs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010444-rxeezdjs/logs
wandb: Agent Starting Run: ol33bwdz with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010450-ol33bwdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-701
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ol33bwdz
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run wild-sweep-701 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ol33bwdz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010450-ol33bwdz/logs
wandb: Agent Starting Run: czzin4ft with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010455-czzin4ft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-702
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/czzin4ft
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-702 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/czzin4ft
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010455-czzin4ft/logs
wandb: Agent Starting Run: 5b025x3j with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010501-5b025x3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-703
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5b025x3j
wandb:                                                                                
wandb: 🚀 View run major-sweep-703 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5b025x3j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010501-5b025x3j/logs
wandb: Agent Starting Run: w849lclw with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010506-w849lclw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-704
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w849lclw
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-704 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w849lclw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010506-w849lclw/logs
wandb: Agent Starting Run: pfw5wd4u with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010512-pfw5wd4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-705
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pfw5wd4u
wandb:                                                                                
wandb: 🚀 View run vital-sweep-705 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pfw5wd4u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010512-pfw5wd4u/logs
wandb: Agent Starting Run: y1w2kipx with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010517-y1w2kipx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-706
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y1w2kipx
wandb:                                                                                
wandb: 🚀 View run firm-sweep-706 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y1w2kipx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010517-y1w2kipx/logs
wandb: Agent Starting Run: 2l7zjh1i with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_010522-2l7zjh1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-707
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2l7zjh1i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▆▅▄▃▂▂▂▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂
wandb: validation_rmse █▇▅▅▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 4.94836
wandb:      train_rmse 2.22449
wandb: validation_loss 12.74025
wandb: validation_rmse 3.56935
wandb: 
wandb: 🚀 View run stellar-sweep-707 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2l7zjh1i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_010522-2l7zjh1i/logs
wandb: Agent Starting Run: 5nhrcuvc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011237-5nhrcuvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-708
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5nhrcuvc
wandb:                                                                                
wandb: 🚀 View run good-sweep-708 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5nhrcuvc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011237-5nhrcuvc/logs
wandb: Agent Starting Run: ovzov938 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011242-ovzov938
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-709
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ovzov938
wandb:                                                                                
wandb: 🚀 View run jumping-sweep-709 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ovzov938
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011242-ovzov938/logs
wandb: Agent Starting Run: y594d3sq with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011248-y594d3sq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-710
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y594d3sq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▇█▅▅▄▄▄▃▂▁
wandb:      train_rmse ▇█▅▅▄▄▄▃▂▁
wandb: validation_loss ██▇▆▅▄▄▃▂▁
wandb: validation_rmse ██▇▆▅▄▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 935.56371
wandb:      train_rmse 30.58699
wandb: validation_loss 926.18976
wandb: validation_rmse 30.43337
wandb: 
wandb: 🚀 View run wandering-sweep-710 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y594d3sq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011248-y594d3sq/logs
wandb: Agent Starting Run: m124z0zl with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011421-m124z0zl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-711
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m124z0zl
wandb:                                                                                
wandb: 🚀 View run genial-sweep-711 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m124z0zl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011421-m124z0zl/logs
wandb: Agent Starting Run: sdxil24v with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011426-sdxil24v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-712
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sdxil24v
wandb:                                                                                
wandb: 🚀 View run splendid-sweep-712 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sdxil24v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011426-sdxil24v/logs
wandb: Agent Starting Run: s8ptk0zo with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011432-s8ptk0zo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-713
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s8ptk0zo
wandb:                                                                                
wandb: 🚀 View run super-sweep-713 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s8ptk0zo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011432-s8ptk0zo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r6u0ynit with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011447-r6u0ynit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-714
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r6u0ynit
wandb:                                                                                
wandb: 🚀 View run amber-sweep-714 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/r6u0ynit
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011447-r6u0ynit/logs
wandb: Agent Starting Run: 0xxvvvqn with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_011453-0xxvvvqn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-715
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0xxvvvqn
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▁▂▁▁▁▁▁▁▁▁
wandb: validation_loss ▇▆█▅▅▆▄▃▇▅▄▂▃▃▄▂▇▃▃▄▁▄▃▄▄▅▂▂▆▂▁▁▂▂▂▂▂▃▁▂
wandb: validation_rmse ▇▆█▆▆▇▅▄▇▆▃▄▄▄▅▃▇▄▄▅▂▄▄▅▅▃▂▇▂▃▁▂▃▃▃▃▄▂▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 6.37297
wandb:      train_rmse 2.52447
wandb: validation_loss 33.06269
wandb: validation_rmse 5.75002
wandb: 
wandb: 🚀 View run avid-sweep-715 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0xxvvvqn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_011453-0xxvvvqn/logs
wandb: Agent Starting Run: q1yoo6sw with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_012202-q1yoo6sw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-716
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q1yoo6sw
wandb:                                                                                
wandb: 🚀 View run mild-sweep-716 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/q1yoo6sw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_012202-q1yoo6sw/logs
wandb: Agent Starting Run: l7vyi9jr with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_012208-l7vyi9jr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-717
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l7vyi9jr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 22.13309
wandb:      train_rmse 4.70458
wandb: validation_loss 11.77086
wandb: validation_rmse 3.43087
wandb: 
wandb: 🚀 View run polished-sweep-717 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/l7vyi9jr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_012208-l7vyi9jr/logs
wandb: Agent Starting Run: ztfzjw5u with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_012912-ztfzjw5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-718
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ztfzjw5u
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -32: [1, -32]
wandb:                                                                                
wandb: 🚀 View run apricot-sweep-718 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ztfzjw5u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_012912-ztfzjw5u/logs
Run ztfzjw5u errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
    fc_layers.append(nn.Linear(input_dim, 1))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -32: [1, -32]

wandb: ERROR Run ztfzjw5u errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 72, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, 1))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -32: [1, -32]
wandb: ERROR 
wandb: Agent Starting Run: bnfmjqtp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_012917-bnfmjqtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-719
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bnfmjqtp
wandb:                                                                                
wandb: 🚀 View run elated-sweep-719 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bnfmjqtp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_012917-bnfmjqtp/logs
wandb: Agent Starting Run: 8iwd5x1d with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_012923-8iwd5x1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-720
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8iwd5x1d
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▆▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 13.78255
wandb:      train_rmse 3.71249
wandb: validation_loss 6.69845
wandb: validation_rmse 2.58814
wandb: 
wandb: 🚀 View run devout-sweep-720 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8iwd5x1d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_012923-8iwd5x1d/logs
wandb: Agent Starting Run: tnfot6rg with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013633-tnfot6rg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-721
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tnfot6rg
wandb:                                                                                
wandb: 🚀 View run skilled-sweep-721 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tnfot6rg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013633-tnfot6rg/logs
wandb: Agent Starting Run: e98m095k with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013638-e98m095k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-722
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e98m095k
wandb:                                                                                
wandb: 🚀 View run devoted-sweep-722 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e98m095k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013638-e98m095k/logs
wandb: Agent Starting Run: 01bjszay with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013643-01bjszay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-723
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/01bjszay
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▁▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss █▇▆▅▄▃▃▂▂▁
wandb: validation_rmse █▇▆▅▄▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 385.47295
wandb:      train_rmse 19.63346
wandb: validation_loss 370.5609
wandb: validation_rmse 19.24996
wandb: 
wandb: 🚀 View run effortless-sweep-723 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/01bjszay
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013643-01bjszay/logs
wandb: Agent Starting Run: vzra9yxq with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013817-vzra9yxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-724
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vzra9yxq
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x52). Calculated output size: (32x0x13). Output size is too small
wandb:                                                                                
wandb: 🚀 View run laced-sweep-724 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vzra9yxq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013817-vzra9yxq/logs
Run vzra9yxq errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x52). Calculated output size: (32x0x13). Output size is too small

wandb: ERROR Run vzra9yxq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x2x52). Calculated output size: (32x0x13). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: i7cv1dxk with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013822-i7cv1dxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-725
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i7cv1dxk
wandb:                                                                                
wandb: 🚀 View run vital-sweep-725 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i7cv1dxk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013822-i7cv1dxk/logs
wandb: Agent Starting Run: blvc5ngj with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013828-blvc5ngj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-726
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/blvc5ngj
wandb:                                                                                
wandb: 🚀 View run wandering-sweep-726 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/blvc5ngj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013828-blvc5ngj/logs
wandb: Agent Starting Run: k11d5wnp with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013833-k11d5wnp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-727
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k11d5wnp
wandb:                                                                                
wandb: 🚀 View run chocolate-sweep-727 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k11d5wnp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013833-k11d5wnp/logs
wandb: Agent Starting Run: 8sqylv9q with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013838-8sqylv9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-728
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8sqylv9q
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run olive-sweep-728 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8sqylv9q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013838-8sqylv9q/logs
wandb: Agent Starting Run: dkjpaod5 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013843-dkjpaod5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-729
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dkjpaod5
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run fragrant-sweep-729 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dkjpaod5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013843-dkjpaod5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s1zzn5sa with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013859-s1zzn5sa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-730
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s1zzn5sa
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x4). Calculated output size: (32x0x1). Output size is too small
wandb:                                                                                
wandb: 🚀 View run robust-sweep-730 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s1zzn5sa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013859-s1zzn5sa/logs
Run s1zzn5sa errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x4). Calculated output size: (32x0x1). Output size is too small

wandb: ERROR Run s1zzn5sa errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x3x4). Calculated output size: (32x0x1). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: xzpobnyf with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013910-xzpobnyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-731
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xzpobnyf
wandb:                                                                                
wandb: 🚀 View run visionary-sweep-731 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xzpobnyf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013910-xzpobnyf/logs
wandb: Agent Starting Run: 8vsrwjnq with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013916-8vsrwjnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-732
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8vsrwjnq
wandb:                                                                                
wandb: 🚀 View run avid-sweep-732 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8vsrwjnq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013916-8vsrwjnq/logs
wandb: Agent Starting Run: ljmqgtff with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013922-ljmqgtff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-733
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ljmqgtff
wandb:                                                                                
wandb: 🚀 View run major-sweep-733 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ljmqgtff
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013922-ljmqgtff/logs
wandb: Agent Starting Run: e1b0waiz with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013927-e1b0waiz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-734
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e1b0waiz
wandb:                                                                                
wandb: 🚀 View run different-sweep-734 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e1b0waiz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013927-e1b0waiz/logs
wandb: Agent Starting Run: uj243g0j with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_013932-uj243g0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-735
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uj243g0j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▄▄▄▄▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▅▅▅▄▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▆▆▆▆▆▅▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 5.8766
wandb:      train_rmse 2.42417
wandb: validation_loss 7.74863
wandb: validation_rmse 2.78364
wandb: 
wandb: 🚀 View run fresh-sweep-735 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uj243g0j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013932-uj243g0j/logs
wandb: Agent Starting Run: e51lpxdj with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_014642-e51lpxdj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-736
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e51lpxdj
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run ethereal-sweep-736 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/e51lpxdj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_014642-e51lpxdj/logs
wandb: Agent Starting Run: ldt6czej with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_014647-ldt6czej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-737
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ldt6czej
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run stoic-sweep-737 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ldt6czej
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_014647-ldt6czej/logs
wandb: Agent Starting Run: w3ka4d8u with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_014653-w3ka4d8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-738
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w3ka4d8u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▁▂▁▁▁
wandb:      train_rmse █▃▂▂▂▁▂▂▂▁
wandb: validation_loss ▃▅▃█▁▁▄▁▂▇
wandb: validation_rmse ▃▅▄█▁▁▄▁▂▇
wandb: 
wandb: Run summary:
wandb:      train_loss 21.96256
wandb:      train_rmse 4.68642
wandb: validation_loss 231.0174
wandb: validation_rmse 15.19926
wandb: 
wandb: 🚀 View run exalted-sweep-738 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w3ka4d8u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_014653-w3ka4d8u/logs
wandb: Agent Starting Run: 7i9pchlb with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_014826-7i9pchlb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-739
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7i9pchlb
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 9.32377
wandb:      train_rmse 3.05348
wandb: validation_loss 11.80748
wandb: validation_rmse 3.4362
wandb: 
wandb: 🚀 View run light-sweep-739 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7i9pchlb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_014826-7i9pchlb/logs
wandb: Agent Starting Run: 7lg71hff with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015536-7lg71hff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-740
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7lg71hff
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run clean-sweep-740 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7lg71hff
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015536-7lg71hff/logs
wandb: Agent Starting Run: 3elysqwq with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015542-3elysqwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-741
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3elysqwq
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x55). Calculated output size: (32x0x13). Output size is too small
wandb: - 0.007 MB of 0.007 MB uploadedwandb: \ 0.007 MB of 0.007 MB uploadedwandb:                                                                                
wandb: 🚀 View run noble-sweep-741 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3elysqwq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015542-3elysqwq/logs
Run 3elysqwq errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x55). Calculated output size: (32x0x13). Output size is too small

wandb: ERROR Run 3elysqwq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x2x55). Calculated output size: (32x0x13). Output size is too small
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0u7c8rm5 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015557-0u7c8rm5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-742
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0u7c8rm5
wandb:                                                                                
wandb: 🚀 View run proud-sweep-742 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0u7c8rm5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015557-0u7c8rm5/logs
wandb: Agent Starting Run: wzxux1v4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015603-wzxux1v4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-743
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wzxux1v4
wandb:                                                                                
wandb: 🚀 View run eager-sweep-743 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wzxux1v4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015603-wzxux1v4/logs
wandb: Agent Starting Run: nrtxhnk5 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015608-nrtxhnk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-744
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nrtxhnk5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▃▃▂▁▁▁
wandb:      train_rmse █▄▃▂▃▃▂▂▁▁
wandb: validation_loss █▃▅▃▅▂▁▃▂▂
wandb: validation_rmse █▃▅▃▅▂▁▃▃▃
wandb: 
wandb: Run summary:
wandb:      train_loss 204.51879
wandb:      train_rmse 14.30101
wandb: validation_loss 460.62045
wandb: validation_rmse 21.46207
wandb: 
wandb: 🚀 View run solar-sweep-744 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nrtxhnk5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015608-nrtxhnk5/logs
wandb: Agent Starting Run: 065lspj3 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015742-065lspj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-745
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/065lspj3
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run morning-sweep-745 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/065lspj3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015742-065lspj3/logs
wandb: Agent Starting Run: z213py48 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015747-z213py48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-746
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z213py48
wandb:                                                                                
wandb: 🚀 View run feasible-sweep-746 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z213py48
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015747-z213py48/logs
wandb: Agent Starting Run: 49dz12px with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015752-49dz12px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-747
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/49dz12px
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▂▂▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▁▁▁
wandb: validation_loss ▂▅█▇▇▂▅▃▃▁
wandb: validation_rmse ▂▅█▇▇▂▅▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 56.45585
wandb:      train_rmse 7.51371
wandb: validation_loss 561.22992
wandb: validation_rmse 23.69029
wandb: 
wandb: 🚀 View run cosmic-sweep-747 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/49dz12px
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015752-49dz12px/logs
wandb: Agent Starting Run: hv10z8i1 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_015920-hv10z8i1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-748
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hv10z8i1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▇▇▅█▄▅▄▆▅▁
wandb:      train_rmse ▇▇▅█▄▅▄▆▅▁
wandb: validation_loss █▄▆▁█▆▆▄▂▆
wandb: validation_rmse █▄▆▁█▆▆▄▂▆
wandb: 
wandb: Run summary:
wandb:      train_loss 970.34665
wandb:      train_rmse 31.15039
wandb: validation_loss 980.7854
wandb: validation_rmse 31.31749
wandb: 
wandb: 🚀 View run wandering-sweep-748 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hv10z8i1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_015920-hv10z8i1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jsxf6hfl with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_020058-jsxf6hfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-749
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jsxf6hfl
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run glowing-sweep-749 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jsxf6hfl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020058-jsxf6hfl/logs
wandb: Agent Starting Run: feql669v with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_020104-feql669v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-750
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/feql669v
wandb:                                                                                
wandb: 🚀 View run wobbly-sweep-750 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/feql669v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020104-feql669v/logs
wandb: Agent Starting Run: of9n1rpc with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_020110-of9n1rpc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-751
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/of9n1rpc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▁▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss █▇▆▅▄▃▃▂▁▁
wandb: validation_rmse █▇▆▅▄▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 314.06769
wandb:      train_rmse 17.72195
wandb: validation_loss 326.10422
wandb: validation_rmse 18.05836
wandb: 
wandb: 🚀 View run soft-sweep-751 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/of9n1rpc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020110-of9n1rpc/logs
wandb: Agent Starting Run: 2m48kvpe with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_020243-2m48kvpe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-752
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2m48kvpe
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run comic-sweep-752 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2m48kvpe
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020243-2m48kvpe/logs
wandb: Agent Starting Run: wbg9tcsd with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_020254-wbg9tcsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-753
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wbg9tcsd
wandb:                                                                                
wandb: 🚀 View run desert-sweep-753 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wbg9tcsd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020254-wbg9tcsd/logs
wandb: Agent Starting Run: ozik3gvt with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_020259-ozik3gvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-754
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ozik3gvt
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▂▃▅▂▂▁▂▁▁▄▃▂▂▁▂▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb: validation_rmse █▅▃▃▄▅▂▂▂▂▂▁▄▄▃▂▂▂▂▁▃▃▂▂▂▂▁▁▁▁▁▁▁▂▃▁▁▁▃▂
wandb: 
wandb: Run summary:
wandb:      train_loss 4.13377
wandb:      train_rmse 2.03317
wandb: validation_loss 8.39298
wandb: validation_rmse 2.89706
wandb: 
wandb: 🚀 View run jolly-sweep-754 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ozik3gvt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020259-ozik3gvt/logs
wandb: Agent Starting Run: le2tgi79 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021004-le2tgi79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-755
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/le2tgi79
wandb:                                                                                
wandb: 🚀 View run trim-sweep-755 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/le2tgi79
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021004-le2tgi79/logs
wandb: Agent Starting Run: vcraev9q with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021009-vcraev9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-756
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vcraev9q
wandb:                                                                                
wandb: 🚀 View run pious-sweep-756 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vcraev9q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021009-vcraev9q/logs
wandb: Agent Starting Run: x0ol7it4 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021014-x0ol7it4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-757
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x0ol7it4
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run solar-sweep-757 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x0ol7it4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021014-x0ol7it4/logs
wandb: Agent Starting Run: nt0nosl2 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021020-nt0nosl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-758
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nt0nosl2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▇▆▆▄▃▃▂▁
wandb:      train_rmse ██▇▆▆▄▃▃▂▁
wandb: validation_loss █▄▄▃▃▃▂▂▁▁
wandb: validation_rmse █▄▄▃▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 945.53926
wandb:      train_rmse 30.74962
wandb: validation_loss 961.66864
wandb: validation_rmse 31.01078
wandb: 
wandb: 🚀 View run hearty-sweep-758 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nt0nosl2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021020-nt0nosl2/logs
wandb: Agent Starting Run: x306xp4a with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021153-x306xp4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-759
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x306xp4a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▁▁
wandb:      train_rmse █▆▅▄▄▃▂▂▁▁
wandb: validation_loss █▆▅▅▄▃▃▂▁▁
wandb: validation_rmse █▆▅▅▄▃▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 821.05312
wandb:      train_rmse 28.65402
wandb: validation_loss 845.19135
wandb: validation_rmse 29.07217
wandb: 
wandb: 🚀 View run royal-sweep-759 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x306xp4a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021153-x306xp4a/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1ic5k13g with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021331-1ic5k13g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-760
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1ic5k13g
wandb:                                                                                
wandb: 🚀 View run polar-sweep-760 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1ic5k13g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021331-1ic5k13g/logs
wandb: Agent Starting Run: ztboc81b with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021337-ztboc81b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-761
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ztboc81b
wandb:                                                                                
wandb: 🚀 View run lucky-sweep-761 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ztboc81b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021337-ztboc81b/logs
wandb: Agent Starting Run: gumr4ycm with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021342-gumr4ycm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-762
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gumr4ycm
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 🚀 View run cosmic-sweep-762 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gumr4ycm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021342-gumr4ycm/logs
Run gumr4ycm errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run gumr4ycm errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: apo9e5af with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021357-apo9e5af
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-763
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/apo9e5af
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run ancient-sweep-763 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/apo9e5af
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021357-apo9e5af/logs
wandb: Agent Starting Run: iqcdexbm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021403-iqcdexbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-764
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iqcdexbm
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run icy-sweep-764 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/iqcdexbm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021403-iqcdexbm/logs
wandb: Agent Starting Run: mxuqzgop with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021409-mxuqzgop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-765
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mxuqzgop
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▁▁▁
wandb:      train_rmse █▃▃▃▂▂▂▂▂▁
wandb: validation_loss ▆▅▇▆▄▇▆▁██
wandb: validation_rmse ▆▅▇▆▄▇▆▁██
wandb: 
wandb: Run summary:
wandb:      train_loss 46.64036
wandb:      train_rmse 6.82937
wandb: validation_loss 164.61482
wandb: validation_rmse 12.83023
wandb: 
wandb: 🚀 View run dark-sweep-765 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mxuqzgop
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021409-mxuqzgop/logs
wandb: Agent Starting Run: m9yhcrst with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021537-m9yhcrst
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-766
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m9yhcrst
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ███▄▇▄▃▃▄▁
wandb:      train_rmse ███▄▇▄▃▃▄▁
wandb: validation_loss ▇█▇▆▄▄▁▁▄▂
wandb: validation_rmse ▇█▇▆▄▄▁▁▄▃
wandb: 
wandb: Run summary:
wandb:      train_loss 970.64277
wandb:      train_rmse 31.15514
wandb: validation_loss 942.71356
wandb: validation_rmse 30.70364
wandb: 
wandb: 🚀 View run dazzling-sweep-766 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m9yhcrst
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021537-m9yhcrst/logs
wandb: Agent Starting Run: u5kuhqat with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_021705-u5kuhqat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-767
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u5kuhqat
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▇▆▇▂▂▃█▂▂▁▁▂▁▆▂▆▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▃▂▂▂▂▁▁▁▃
wandb: validation_rmse ▇▆▃▇▂▂█▃▂▁▃▁▂▁▆▃▆▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▃▂▂▂▁▁▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 0.2888
wandb:      train_rmse 0.53741
wandb: validation_loss 9.23035
wandb: validation_rmse 3.03815
wandb: 
wandb: 🚀 View run fragrant-sweep-767 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u5kuhqat
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_021705-u5kuhqat/logs
wandb: Agent Starting Run: phpleoqs with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_022410-phpleoqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-768
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/phpleoqs
wandb:                                                                                
wandb: 🚀 View run deft-sweep-768 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/phpleoqs
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_022410-phpleoqs/logs
wandb: Agent Starting Run: t0p4jlin with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_022415-t0p4jlin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-769
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t0p4jlin
wandb:                                                                                
wandb: 🚀 View run crisp-sweep-769 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t0p4jlin
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_022415-t0p4jlin/logs
wandb: Agent Starting Run: lowrjv3v with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_022420-lowrjv3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-770
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lowrjv3v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 1.41085
wandb:      train_rmse 1.18779
wandb: validation_loss 9.45618
wandb: validation_rmse 3.07509
wandb: 
wandb: 🚀 View run fluent-sweep-770 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lowrjv3v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_022420-lowrjv3v/logs
wandb: Agent Starting Run: vdhf8q3e with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023131-vdhf8q3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-771
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vdhf8q3e
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run northern-sweep-771 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vdhf8q3e
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023131-vdhf8q3e/logs
wandb: Agent Starting Run: ji2lxm7h with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023136-ji2lxm7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-772
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ji2lxm7h
wandb:                                                                                
wandb: 🚀 View run crisp-sweep-772 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ji2lxm7h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023136-ji2lxm7h/logs
wandb: Agent Starting Run: d1wyj6ao with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023142-d1wyj6ao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-773
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d1wyj6ao
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run chocolate-sweep-773 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/d1wyj6ao
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023142-d1wyj6ao/logs
wandb: Agent Starting Run: pq6ue3i7 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023152-pq6ue3i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-774
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pq6ue3i7
wandb:                                                                                
wandb: 🚀 View run grateful-sweep-774 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pq6ue3i7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023152-pq6ue3i7/logs
wandb: Agent Starting Run: jglqvx18 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023157-jglqvx18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-775
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jglqvx18
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 66.01853
wandb:      train_rmse 8.12518
wandb: validation_loss 71.89164
wandb: validation_rmse 8.47889
wandb: 
wandb: 🚀 View run avid-sweep-775 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jglqvx18
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023157-jglqvx18/logs
wandb: Agent Starting Run: ceya6o6s with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023325-ceya6o6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-776
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ceya6o6s
wandb:                                                                                
wandb: 🚀 View run lunar-sweep-776 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ceya6o6s
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023325-ceya6o6s/logs
wandb: Agent Starting Run: 6ro9baae with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023331-6ro9baae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-777
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ro9baae
wandb:                                                                                
wandb: 🚀 View run stoic-sweep-777 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6ro9baae
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023331-6ro9baae/logs
wandb: Agent Starting Run: jwvgyvkx with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_023337-jwvgyvkx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-778
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jwvgyvkx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 3.18068
wandb:      train_rmse 1.78345
wandb: validation_loss 4.85752
wandb: validation_rmse 2.20398
wandb: 
wandb: 🚀 View run swept-sweep-778 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jwvgyvkx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_023337-jwvgyvkx/logs
wandb: Agent Starting Run: fef1htkj with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024053-fef1htkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-779
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fef1htkj
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run robust-sweep-779 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fef1htkj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024053-fef1htkj/logs
wandb: Agent Starting Run: 64z77d7y with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024058-64z77d7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-780
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/64z77d7y
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▆▃▄▃▂▁▃▆
wandb:      train_rmse █▄▆▃▄▃▂▁▃▆
wandb: validation_loss █▆▅▄▄▃▂▂▁▁
wandb: validation_rmse █▆▅▄▄▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 979.77849
wandb:      train_rmse 31.30141
wandb: validation_loss 974.21643
wandb: validation_rmse 31.21244
wandb: 
wandb: 🚀 View run cosmic-sweep-780 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/64z77d7y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024058-64z77d7y/logs
wandb: Agent Starting Run: s2m3sw8c with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024232-s2m3sw8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-781
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s2m3sw8c
wandb:                                                                                
wandb: 🚀 View run summer-sweep-781 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s2m3sw8c
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024232-s2m3sw8c/logs
wandb: Agent Starting Run: 44rfq3qm with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024237-44rfq3qm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-782
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/44rfq3qm
wandb:                                                                                
wandb: 🚀 View run blooming-sweep-782 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/44rfq3qm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024237-44rfq3qm/logs
wandb: Agent Starting Run: myjx2xlb with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024243-myjx2xlb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-783
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/myjx2xlb
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run comic-sweep-783 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/myjx2xlb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024243-myjx2xlb/logs
wandb: Agent Starting Run: 8uy0htil with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024248-8uy0htil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-784
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8uy0htil
wandb:                                                                                
wandb: 🚀 View run ancient-sweep-784 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8uy0htil
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024248-8uy0htil/logs
wandb: Agent Starting Run: 15tklhxp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_024253-15tklhxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-785
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/15tklhxp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 5.94677
wandb:      train_rmse 2.4386
wandb: validation_loss 7.78673
wandb: validation_rmse 2.79047
wandb: 
wandb: 🚀 View run northern-sweep-785 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/15tklhxp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024253-15tklhxp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ljyynapp with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025007-ljyynapp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-786
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ljyynapp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅█▅▄▇▁▅▂▄
wandb:      train_rmse █▅█▅▄▇▁▅▂▄
wandb: validation_loss ▂▁▆▃▅▅██▇▆
wandb: validation_rmse ▂▁▆▃▅▅██▇▆
wandb: 
wandb: Run summary:
wandb:      train_loss 1021.1984
wandb:      train_rmse 31.9562
wandb: validation_loss 998.0152
wandb: validation_rmse 31.59138
wandb: 
wandb: 🚀 View run sweepy-sweep-786 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ljyynapp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025007-ljyynapp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8xn9bkvr with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025147-8xn9bkvr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-787
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8xn9bkvr
wandb:                                                                                
wandb: 🚀 View run divine-sweep-787 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8xn9bkvr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025147-8xn9bkvr/logs
wandb: Agent Starting Run: v7iwz664 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025153-v7iwz664
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-788
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v7iwz664
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 49.10381
wandb:      train_rmse 7.00741
wandb: validation_loss 54.22618
wandb: validation_rmse 7.36384
wandb: 
wandb: 🚀 View run ethereal-sweep-788 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v7iwz664
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025153-v7iwz664/logs
wandb: Agent Starting Run: qcui3qgp with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025914-qcui3qgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-789
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qcui3qgp
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-789 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qcui3qgp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025914-qcui3qgp/logs
wandb: Agent Starting Run: 2x90vgj7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025919-2x90vgj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-790
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2x90vgj7
wandb:                                                                                
wandb: 🚀 View run crisp-sweep-790 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2x90vgj7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025919-2x90vgj7/logs
wandb: Agent Starting Run: 77c8ybfh with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025924-77c8ybfh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-791
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/77c8ybfh
wandb:                                                                                
wandb: 🚀 View run fast-sweep-791 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/77c8ybfh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025924-77c8ybfh/logs
wandb: Agent Starting Run: nqkhfl53 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025930-nqkhfl53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-792
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nqkhfl53
wandb:                                                                                
wandb: 🚀 View run astral-sweep-792 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nqkhfl53
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025930-nqkhfl53/logs
wandb: Agent Starting Run: qnltqmi4 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_025935-qnltqmi4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-793
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qnltqmi4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▇▆▅▅▄▃▂▂▁
wandb: validation_rmse █▇▆▆▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 718.78418
wandb:      train_rmse 26.81015
wandb: validation_loss 701.79614
wandb: validation_rmse 26.49144
wandb: 
wandb: 🚀 View run whole-sweep-793 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qnltqmi4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_025935-qnltqmi4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mx4ulek7 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030114-mx4ulek7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-794
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mx4ulek7
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run colorful-sweep-794 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mx4ulek7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030114-mx4ulek7/logs
wandb: Agent Starting Run: v4u940hn with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030119-v4u940hn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-795
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v4u940hn
wandb:                                                                                
wandb: 🚀 View run noble-sweep-795 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v4u940hn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030119-v4u940hn/logs
wandb: Agent Starting Run: zsx2h2z4 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030125-zsx2h2z4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-796
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zsx2h2z4
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x26). Calculated output size: (32x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run olive-sweep-796 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zsx2h2z4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030125-zsx2h2z4/logs
Run zsx2h2z4 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x3x26). Calculated output size: (32x0x6). Output size is too small

wandb: ERROR Run zsx2h2z4 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x3x26). Calculated output size: (32x0x6). Output size is too small
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xunftidg with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030140-xunftidg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-797
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xunftidg
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x3x11). Calculated output size: (64x0x2). Output size is too small
wandb:                                                                                
wandb: 🚀 View run rural-sweep-797 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xunftidg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030140-xunftidg/logs
Run xunftidg errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x3x11). Calculated output size: (64x0x2). Output size is too small

wandb: ERROR Run xunftidg errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (64x3x11). Calculated output size: (64x0x2). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: lcy9opn6 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030146-lcy9opn6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-798
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lcy9opn6
wandb:                                                                                
wandb: 🚀 View run eternal-sweep-798 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lcy9opn6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030146-lcy9opn6/logs
wandb: Agent Starting Run: 97pywsfm with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030151-97pywsfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-799
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/97pywsfm
wandb:                                                                                
wandb: 🚀 View run volcanic-sweep-799 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/97pywsfm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030151-97pywsfm/logs
wandb: Agent Starting Run: mggcona6 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030157-mggcona6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-800
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mggcona6
wandb:                                                                                
wandb: 🚀 View run rose-sweep-800 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mggcona6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030157-mggcona6/logs
wandb: Agent Starting Run: xnq9tkv2 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030202-xnq9tkv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-801
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xnq9tkv2
wandb:                                                                                
wandb: 🚀 View run divine-sweep-801 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xnq9tkv2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030202-xnq9tkv2/logs
wandb: Agent Starting Run: p5ohypcz with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030208-p5ohypcz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-802
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p5ohypcz
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -64: [32, -64]
wandb:                                                                                
wandb: 🚀 View run revived-sweep-802 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p5ohypcz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030208-p5ohypcz/logs
Run p5ohypcz errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -64: [32, -64]

wandb: ERROR Run p5ohypcz errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -64: [32, -64]
wandb: ERROR 
wandb: Agent Starting Run: ec01fi4v with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030213-ec01fi4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-803
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ec01fi4v
wandb:                                                                                
wandb: 🚀 View run pious-sweep-803 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ec01fi4v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030213-ec01fi4v/logs
wandb: Agent Starting Run: jqh6ooii with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030219-jqh6ooii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-804
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jqh6ooii
wandb:                                                                                
wandb: 🚀 View run clear-sweep-804 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jqh6ooii
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030219-jqh6ooii/logs
wandb: Agent Starting Run: rl4444ey with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030224-rl4444ey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-805
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rl4444ey
wandb:                                                                                
wandb: 🚀 View run crimson-sweep-805 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rl4444ey
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030224-rl4444ey/logs
wandb: Agent Starting Run: oyz5ngom with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030229-oyz5ngom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-806
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oyz5ngom
wandb:                                                                                
wandb: 🚀 View run pretty-sweep-806 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/oyz5ngom
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030229-oyz5ngom/logs
wandb: Agent Starting Run: 3gsmlfte with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030235-3gsmlfte
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-807
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3gsmlfte
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run amber-sweep-807 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3gsmlfte
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030235-3gsmlfte/logs
wandb: Agent Starting Run: u4og9c56 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030240-u4og9c56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-808
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u4og9c56
wandb:                                                                                
wandb: 🚀 View run proud-sweep-808 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u4og9c56
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030240-u4og9c56/logs
wandb: Agent Starting Run: ertk8pr3 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030246-ertk8pr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-809
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ertk8pr3
wandb:                                                                                
wandb: 🚀 View run absurd-sweep-809 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ertk8pr3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030246-ertk8pr3/logs
wandb: Agent Starting Run: sv96q7pp with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030252-sv96q7pp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-810
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sv96q7pp
wandb:                                                                                
wandb: 🚀 View run absurd-sweep-810 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sv96q7pp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030252-sv96q7pp/logs
wandb: Agent Starting Run: jrplisd4 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030257-jrplisd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-811
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jrplisd4
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run devout-sweep-811 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jrplisd4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030257-jrplisd4/logs
wandb: Agent Starting Run: 75ae43e3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030308-75ae43e3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-812
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/75ae43e3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▅▄▃▂▂▁
wandb:      train_rmse █▇▆▆▅▄▃▃▂▁
wandb: validation_loss █▇▆▆▅▄▄▃▃▁
wandb: validation_rmse █▇▆▆▅▅▄▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 801.57112
wandb:      train_rmse 28.31203
wandb: validation_loss 857.44363
wandb: validation_rmse 29.28214
wandb: 
wandb: 🚀 View run fluent-sweep-812 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/75ae43e3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030308-75ae43e3/logs
wandb: Agent Starting Run: 9ryzln1x with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030437-9ryzln1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-813
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9ryzln1x
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run vital-sweep-813 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9ryzln1x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030437-9ryzln1x/logs
wandb: Agent Starting Run: sy9v2qdc with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030442-sy9v2qdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-814
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sy9v2qdc
wandb:                                                                                
wandb: 🚀 View run noble-sweep-814 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sy9v2qdc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030442-sy9v2qdc/logs
wandb: Agent Starting Run: gj51zx0t with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030447-gj51zx0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-815
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gj51zx0t
wandb:                                                                                
wandb: 🚀 View run robust-sweep-815 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gj51zx0t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030447-gj51zx0t/logs
wandb: Agent Starting Run: ubkqxnpj with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030453-ubkqxnpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-816
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ubkqxnpj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▇█▆▅▄▃▄▂▃▁
wandb:      train_rmse ▇█▆▅▄▃▄▂▃▁
wandb: validation_loss ▁▂▃▄▅▆▆▇▇█
wandb: validation_rmse ▁▂▃▄▅▆▆▇▇█
wandb: 
wandb: Run summary:
wandb:      train_loss 964.82674
wandb:      train_rmse 31.06166
wandb: validation_loss 1175.11646
wandb: validation_rmse 34.27997
wandb: 
wandb: 🚀 View run pious-sweep-816 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ubkqxnpj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030453-ubkqxnpj/logs
wandb: Agent Starting Run: 4a5pzpz1 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030621-4a5pzpz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-817
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4a5pzpz1
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run celestial-sweep-817 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4a5pzpz1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030621-4a5pzpz1/logs
wandb: Agent Starting Run: ps5zmvy5 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030627-ps5zmvy5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-818
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ps5zmvy5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▅▃▃▂▂▁
wandb:      train_rmse █▇▆▆▅▃▃▂▂▁
wandb: validation_loss █▇▇▆▅▄▃▃▂▁
wandb: validation_rmse █▇▇▆▅▄▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 790.98988
wandb:      train_rmse 28.12454
wandb: validation_loss 776.26004
wandb: validation_rmse 27.86144
wandb: 
wandb: 🚀 View run fragrant-sweep-818 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ps5zmvy5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030627-ps5zmvy5/logs
wandb: Agent Starting Run: an7is8af with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030813-an7is8af
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-819
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/an7is8af
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x3). Calculated output size: (32x0x0). Output size is too small
wandb:                                                                                
wandb: 🚀 View run winter-sweep-819 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/an7is8af
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030813-an7is8af/logs
Run an7is8af errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x3). Calculated output size: (32x0x0). Output size is too small

wandb: ERROR Run an7is8af errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x2x3). Calculated output size: (32x0x0). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: sd9mp13b with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030818-sd9mp13b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-820
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sd9mp13b
wandb:                                                                                
wandb: 🚀 View run amber-sweep-820 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sd9mp13b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030818-sd9mp13b/logs
wandb: Agent Starting Run: 5j9ogszv with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030823-5j9ogszv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-821
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5j9ogszv
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-821 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5j9ogszv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030823-5j9ogszv/logs
wandb: Agent Starting Run: jk5e46jx with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_030829-jk5e46jx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-822
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jk5e46jx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▃▃█▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse ▄▃▅█▂▂▂▂▃▂▂▂▂▁▁▂▁▁▂▁▁▂▂▁▁▁▂▁▁▁▁▁▂▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 4.21082
wandb:      train_rmse 2.05203
wandb: validation_loss 11.9055
wandb: validation_rmse 3.45044
wandb: 
wandb: 🚀 View run ethereal-sweep-822 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jk5e46jx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_030829-jk5e46jx/logs
wandb: Agent Starting Run: trwyya7h with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_031554-trwyya7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-823
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/trwyya7h
wandb:                                                                                
wandb: 🚀 View run astral-sweep-823 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/trwyya7h
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_031554-trwyya7h/logs
wandb: Agent Starting Run: ii4yx5dl with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_031601-ii4yx5dl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-824
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ii4yx5dl
wandb:                                                                                
wandb: 🚀 View run distinctive-sweep-824 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ii4yx5dl
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_031601-ii4yx5dl/logs
wandb: Agent Starting Run: 5s6i6qzp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_031607-5s6i6qzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-825
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5s6i6qzp
wandb:                                                                                
wandb: 🚀 View run wise-sweep-825 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5s6i6qzp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_031607-5s6i6qzp/logs
wandb: Agent Starting Run: c8om3c3z with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_031612-c8om3c3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-826
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c8om3c3z
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 1.35191
wandb:      train_rmse 1.16271
wandb: validation_loss 2.67973
wandb: validation_rmse 1.63699
wandb: 
wandb: 🚀 View run hopeful-sweep-826 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c8om3c3z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_031612-c8om3c3z/logs
wandb: Agent Starting Run: 5gz4ma8g with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032323-5gz4ma8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-827
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5gz4ma8g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▃▂▂▂▂▂▁▂
wandb: validation_rmse █▅▃▂▂▃▂▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 71.76045
wandb:      train_rmse 8.47115
wandb: validation_loss 229.39026
wandb: validation_rmse 15.14563
wandb: 
wandb: 🚀 View run robust-sweep-827 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5gz4ma8g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032323-5gz4ma8g/logs
wandb: Agent Starting Run: cost1xw9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032453-cost1xw9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-828
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cost1xw9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▆▆▆█▇▃▁▄▄▄
wandb:      train_rmse ▆▆▆█▇▃▁▄▄▄
wandb: validation_loss █▇▆▅▄▃▄▂▃▁
wandb: validation_rmse █▇▆▅▄▃▄▂▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 855.0389
wandb:      train_rmse 29.24105
wandb: validation_loss 884.53885
wandb: validation_rmse 29.7412
wandb: 
wandb: 🚀 View run misunderstood-sweep-828 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cost1xw9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032453-cost1xw9/logs
wandb: Agent Starting Run: 7vth5fyt with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032622-7vth5fyt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-829
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7vth5fyt
wandb:                                                                                
wandb: 🚀 View run misty-sweep-829 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7vth5fyt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032622-7vth5fyt/logs
wandb: Agent Starting Run: zt24fn0i with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032628-zt24fn0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-830
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zt24fn0i
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run light-sweep-830 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zt24fn0i
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032628-zt24fn0i/logs
wandb: Agent Starting Run: 4iis59z8 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032633-4iis59z8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-831
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4iis59z8
wandb:                                                                                
wandb: 🚀 View run treasured-sweep-831 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4iis59z8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032633-4iis59z8/logs
wandb: Agent Starting Run: 78029cio with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032638-78029cio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-832
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/78029cio
wandb:                                                                                
wandb: 🚀 View run good-sweep-832 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/78029cio
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032638-78029cio/logs
wandb: Agent Starting Run: 7du6hmjn with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032644-7du6hmjn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-833
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7du6hmjn
wandb:                                                                                
wandb: 🚀 View run stilted-sweep-833 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7du6hmjn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032644-7du6hmjn/logs
wandb: Agent Starting Run: 3joyi3x9 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032654-3joyi3x9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-834
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3joyi3x9
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run sweet-sweep-834 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3joyi3x9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032654-3joyi3x9/logs
wandb: Agent Starting Run: 2axmlq6t with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032659-2axmlq6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-835
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2axmlq6t
wandb:                                                                                
wandb: 🚀 View run daily-sweep-835 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2axmlq6t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032659-2axmlq6t/logs
wandb: Agent Starting Run: t5rihsa1 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032705-t5rihsa1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-836
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t5rihsa1
wandb:                                                                                
wandb: 🚀 View run fiery-sweep-836 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/t5rihsa1
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032705-t5rihsa1/logs
wandb: Agent Starting Run: dzdimnav with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032710-dzdimnav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-837
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dzdimnav
wandb:                                                                                
wandb: 🚀 View run golden-sweep-837 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dzdimnav
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032710-dzdimnav/logs
wandb: Agent Starting Run: 5mx8r1py with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032716-5mx8r1py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-838
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5mx8r1py
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▅▁▃▆▁▁▁▁▁█
wandb: validation_rmse ▅▁▃▆▁▁▁▁▁█
wandb: 
wandb: Run summary:
wandb:      train_loss 70.17576
wandb:      train_rmse 8.3771
wandb: validation_loss 79.75992
wandb: validation_rmse 8.93084
wandb: 
wandb: 🚀 View run atomic-sweep-838 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5mx8r1py
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032716-5mx8r1py/logs
wandb: Agent Starting Run: 0jkvp0wk with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032849-0jkvp0wk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-839
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0jkvp0wk
wandb:                                                                                
wandb: 🚀 View run lilac-sweep-839 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0jkvp0wk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032849-0jkvp0wk/logs
wandb: Agent Starting Run: xfj52454 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032859-xfj52454
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-840
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xfj52454
wandb:                                                                                
wandb: 🚀 View run stilted-sweep-840 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xfj52454
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032859-xfj52454/logs
wandb: Agent Starting Run: s2pe9xh2 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032905-s2pe9xh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-841
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s2pe9xh2
wandb:                                                                                
wandb: 🚀 View run smart-sweep-841 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s2pe9xh2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032905-s2pe9xh2/logs
wandb: Agent Starting Run: p279z3xa with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032910-p279z3xa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-842
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p279z3xa
wandb:                                                                                
wandb: 🚀 View run fallen-sweep-842 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p279z3xa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032910-p279z3xa/logs
wandb: Agent Starting Run: srbdu871 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_032916-srbdu871
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-843
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/srbdu871
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▁▁
wandb:      train_rmse █▇▆▅▅▄▃▂▁▁
wandb: validation_loss ███▆▇▇▄▇▂▁
wandb: validation_rmse ███▆▇▇▅▇▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 400.59368
wandb:      train_rmse 20.01484
wandb: validation_loss 354.85968
wandb: validation_rmse 18.83772
wandb: 
wandb: 🚀 View run treasured-sweep-843 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/srbdu871
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_032916-srbdu871/logs
wandb: Agent Starting Run: k1llnonz with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_033052-k1llnonz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-844
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k1llnonz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 5.82292
wandb:      train_rmse 2.41307
wandb: validation_loss 7.97128
wandb: validation_rmse 2.82334
wandb: 
wandb: 🚀 View run blooming-sweep-844 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k1llnonz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_033052-k1llnonz/logs
wandb: Agent Starting Run: 1i1vrhcd with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_033837-1i1vrhcd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-845
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1i1vrhcd
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run misunderstood-sweep-845 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1i1vrhcd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_033837-1i1vrhcd/logs
wandb: Agent Starting Run: hk8h6ami with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_033842-hk8h6ami
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-846
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hk8h6ami
wandb:                                                                                
wandb: 🚀 View run polar-sweep-846 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hk8h6ami
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_033842-hk8h6ami/logs
wandb: Agent Starting Run: f168jczk with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_033848-f168jczk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-847
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f168jczk
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run fanciful-sweep-847 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f168jczk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_033848-f168jczk/logs
wandb: Agent Starting Run: m1wxe1uy with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_033853-m1wxe1uy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-848
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m1wxe1uy
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 72.65833
wandb:      train_rmse 8.52399
wandb: validation_loss 73.46702
wandb: validation_rmse 8.57129
wandb: 
wandb: 🚀 View run worldly-sweep-848 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m1wxe1uy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_033853-m1wxe1uy/logs
wandb: Agent Starting Run: 5hfw5v5a with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034028-5hfw5v5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-849
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5hfw5v5a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 10.32302
wandb:      train_rmse 3.21295
wandb: validation_loss 11.98461
wandb: validation_rmse 3.46188
wandb: 
wandb: 🚀 View run rich-sweep-849 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5hfw5v5a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034028-5hfw5v5a/logs
wandb: Agent Starting Run: grp3cf66 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034733-grp3cf66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-850
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/grp3cf66
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run confused-sweep-850 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/grp3cf66
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034733-grp3cf66/logs
wandb: Agent Starting Run: 7dvgy9fr with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034739-7dvgy9fr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-851
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7dvgy9fr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▅▄█▅▁▂▇█
wandb:      train_rmse █▄▅▄█▅▁▂▇█
wandb: validation_loss █▆▅▄▃▃▂▂▁▁
wandb: validation_rmse █▆▅▄▃▃▂▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 949.12351
wandb:      train_rmse 30.80785
wandb: validation_loss 946.46283
wandb: validation_rmse 30.76464
wandb: 
wandb: 🚀 View run amber-sweep-851 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7dvgy9fr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034739-7dvgy9fr/logs
wandb: Agent Starting Run: 4l5mssw2 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034907-4l5mssw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-852
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4l5mssw2
wandb:                                                                                
wandb: 🚀 View run hearty-sweep-852 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4l5mssw2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034907-4l5mssw2/logs
wandb: Agent Starting Run: zb4h8m8l with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034912-zb4h8m8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-853
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zb4h8m8l
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run sweepy-sweep-853 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zb4h8m8l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034912-zb4h8m8l/logs
wandb: Agent Starting Run: 0ykv57wh with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034923-0ykv57wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-854
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ykv57wh
wandb:                                                                                
wandb: 🚀 View run clear-sweep-854 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0ykv57wh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034923-0ykv57wh/logs
wandb: Agent Starting Run: vofzgr9q with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034928-vofzgr9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-855
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vofzgr9q
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run wise-sweep-855 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vofzgr9q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034928-vofzgr9q/logs
wandb: Agent Starting Run: eb9fcm71 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034934-eb9fcm71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-856
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eb9fcm71
wandb:                                                                                
wandb: 🚀 View run earnest-sweep-856 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eb9fcm71
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034934-eb9fcm71/logs
wandb: Agent Starting Run: 2infd78n with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_034939-2infd78n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-857
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2infd78n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▂▁▁▁▂▁▁▂
wandb:      train_rmse █▁▂▂▁▁▂▁▁▂
wandb: validation_loss ▂▃█▂▁▁▂▄▅▆
wandb: validation_rmse ▂▃█▂▁▁▂▄▅▆
wandb: 
wandb: Run summary:
wandb:      train_loss 72.68938
wandb:      train_rmse 8.52581
wandb: validation_loss 79.34838
wandb: validation_rmse 8.90777
wandb: 
wandb: 🚀 View run apricot-sweep-857 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2infd78n
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_034939-2infd78n/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: m19a6rup with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_035117-m19a6rup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-858
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m19a6rup
wandb:                                                                                
wandb: 🚀 View run expert-sweep-858 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/m19a6rup
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_035117-m19a6rup/logs
wandb: Agent Starting Run: 0yicte44 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_035123-0yicte44
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-859
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0yicte44
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▁▁▂▁▂▂▁▂▁▂▁▂▁▁▁▂▂▂▁▁▂▂▁▁▁▂▁▁▁▁▁▃▁▂▁▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 14.29839
wandb:      train_rmse 3.78132
wandb: validation_loss 5.24566
wandb: validation_rmse 2.29034
wandb: 
wandb: 🚀 View run pretty-sweep-859 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0yicte44
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_035123-0yicte44/logs
wandb: Agent Starting Run: vxnbtt45 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_040107-vxnbtt45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-860
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vxnbtt45
wandb:                                                                                
wandb: 🚀 View run clear-sweep-860 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vxnbtt45
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_040107-vxnbtt45/logs
wandb: Agent Starting Run: 32uen9kk with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_040113-32uen9kk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-861
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/32uen9kk
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run fallen-sweep-861 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/32uen9kk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_040113-32uen9kk/logs
wandb: Agent Starting Run: hncrokvr with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_040123-hncrokvr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-862
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hncrokvr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▄▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 4.81032
wandb:      train_rmse 2.19324
wandb: validation_loss 6.95399
wandb: validation_rmse 2.63704
wandb: 
wandb: 🚀 View run glorious-sweep-862 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hncrokvr
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_040123-hncrokvr/logs
wandb: Agent Starting Run: kl9ot7oc with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_040829-kl9ot7oc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-863
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kl9ot7oc
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-863 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kl9ot7oc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_040829-kl9ot7oc/logs
wandb: Agent Starting Run: 57g9qib9 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_040834-57g9qib9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-864
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/57g9qib9
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▁▁
wandb:      train_rmse █▇▆▅▄▃▃▂▂▁
wandb: validation_loss █▇▆▅▄▃▃▂▁▁
wandb: validation_rmse █▇▆▅▄▃▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 516.2075
wandb:      train_rmse 22.7202
wandb: validation_loss 513.03586
wandb: validation_rmse 22.65029
wandb: 
wandb: 🚀 View run gentle-sweep-864 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/57g9qib9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_040834-57g9qib9/logs
wandb: Agent Starting Run: z3nm2vxe with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_041003-z3nm2vxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-865
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z3nm2vxe
wandb:                                                                                
wandb: 🚀 View run firm-sweep-865 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z3nm2vxe
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_041003-z3nm2vxe/logs
wandb: Agent Starting Run: 3htsjqiu with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_041008-3htsjqiu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-866
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3htsjqiu
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run astral-sweep-866 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3htsjqiu
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_041008-3htsjqiu/logs
wandb: Agent Starting Run: 6revl9ls with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_041014-6revl9ls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-867
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6revl9ls
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▂▁▁▁▁▁▁▁
wandb:      train_rmse █▅▂▁▁▁▁▁▁▁
wandb: validation_loss █▃▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 117.08696
wandb:      train_rmse 10.82067
wandb: validation_loss 75.79333
wandb: validation_rmse 8.70594
wandb: 
wandb: 🚀 View run royal-sweep-867 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6revl9ls
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_041014-6revl9ls/logs
wandb: Agent Starting Run: vtsk29ag with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_041207-vtsk29ag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-868
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vtsk29ag
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▃▂▁▁▁▁▁▁
wandb:      train_rmse █▅▄▂▂▁▁▁▁▁
wandb: validation_loss █▅▃▂▁▁▁▁▁▁
wandb: validation_rmse █▅▃▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 82.63073
wandb:      train_rmse 9.09014
wandb: validation_loss 74.59077
wandb: validation_rmse 8.63659
wandb: 
wandb: 🚀 View run lively-sweep-868 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vtsk29ag
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_041207-vtsk29ag/logs
wandb: Agent Starting Run: df8t063r with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_041523-df8t063r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-869
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/df8t063r
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run electric-sweep-869 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/df8t063r
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_041523-df8t063r/logs
Run df8t063r errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run df8t063r errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 72czlw7b with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_041529-72czlw7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-870
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/72czlw7b
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 3.14396
wandb:      train_rmse 1.77312
wandb: validation_loss 6.55904
wandb: validation_rmse 2.56106
wandb: 
wandb: 🚀 View run legendary-sweep-870 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/72czlw7b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_041529-72czlw7b/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mckydmot with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042300-mckydmot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-871
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mckydmot
wandb:                                                                                
wandb: 🚀 View run swept-sweep-871 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mckydmot
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042300-mckydmot/logs
wandb: Agent Starting Run: typqueso with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042308-typqueso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-872
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/typqueso
wandb:                                                                                
wandb: 🚀 View run winter-sweep-872 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/typqueso
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042308-typqueso/logs
wandb: Agent Starting Run: ixtzof63 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042313-ixtzof63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-873
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ixtzof63
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run vague-sweep-873 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ixtzof63
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042313-ixtzof63/logs
wandb: Agent Starting Run: 63nn1dll with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042319-63nn1dll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-874
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/63nn1dll
wandb:                                                                                
wandb: 🚀 View run magic-sweep-874 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/63nn1dll
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042319-63nn1dll/logs
wandb: Agent Starting Run: 7fzztl9e with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042324-7fzztl9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-875
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7fzztl9e
wandb:                                                                                
wandb: 🚀 View run cerulean-sweep-875 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7fzztl9e
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042324-7fzztl9e/logs
wandb: Agent Starting Run: nqrm5c3u with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042331-nqrm5c3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-876
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nqrm5c3u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▄▄▃▂▂▁
wandb:      train_rmse █▇▆▆▄▄▃▂▂▁
wandb: validation_loss ███▆▆▄▃▃▂▁
wandb: validation_rmse ███▆▆▄▃▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 946.89246
wandb:      train_rmse 30.77162
wandb: validation_loss 984.71194
wandb: validation_rmse 31.38012
wandb: 
wandb: 🚀 View run amber-sweep-876 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nqrm5c3u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042331-nqrm5c3u/logs
wandb: Agent Starting Run: ytj6zmu5 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042459-ytj6zmu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-877
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ytj6zmu5
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run glorious-sweep-877 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ytj6zmu5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042459-ytj6zmu5/logs
wandb: Agent Starting Run: qwx4rv0f with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042505-qwx4rv0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-878
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qwx4rv0f
wandb:                                                                                
wandb: 🚀 View run likely-sweep-878 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qwx4rv0f
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042505-qwx4rv0f/logs
wandb: Agent Starting Run: te1ref35 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042510-te1ref35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-879
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/te1ref35
wandb:                                                                                
wandb: 🚀 View run clean-sweep-879 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/te1ref35
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042510-te1ref35/logs
wandb: Agent Starting Run: jxxrxpvf with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042515-jxxrxpvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-880
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxxrxpvf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▁▁▁▁▁▁
wandb: validation_loss █▄▂▂▁▁▁▁▁▁
wandb: validation_rmse █▄▃▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 99.41457
wandb:      train_rmse 9.97069
wandb: validation_loss 69.69861
wandb: validation_rmse 8.34857
wandb: 
wandb: 🚀 View run lilac-sweep-880 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxxrxpvf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042515-jxxrxpvf/logs
wandb: Agent Starting Run: hdqlgwvc with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042649-hdqlgwvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-881
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hdqlgwvc
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x57). Calculated output size: (32x0x14). Output size is too small
wandb:                                                                                
wandb: 🚀 View run twilight-sweep-881 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hdqlgwvc
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042649-hdqlgwvc/logs
Run hdqlgwvc errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x2x57). Calculated output size: (32x0x14). Output size is too small

wandb: ERROR Run hdqlgwvc errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x2x57). Calculated output size: (32x0x14). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: umcyrbtp with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042655-umcyrbtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-882
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/umcyrbtp
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run vital-sweep-882 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/umcyrbtp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042655-umcyrbtp/logs
Run umcyrbtp errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run umcyrbtp errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: x7t2rnaa with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042700-x7t2rnaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-883
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x7t2rnaa
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-883 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/x7t2rnaa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042700-x7t2rnaa/logs
wandb: Agent Starting Run: rc10yd3l with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042705-rc10yd3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-884
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rc10yd3l
wandb:                                                                                
wandb: 🚀 View run prime-sweep-884 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/rc10yd3l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042705-rc10yd3l/logs
wandb: Agent Starting Run: a7fhr1rv with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042711-a7fhr1rv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-885
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a7fhr1rv
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-885 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a7fhr1rv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042711-a7fhr1rv/logs
Run a7fhr1rv errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run a7fhr1rv errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: cw8i5zdx with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_042716-cw8i5zdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-886
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cw8i5zdx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▆▅▄▄▄▂▃▇▄▂▆▃▁▂▃▁█▁▃▁▂▃▁▁▁▂▅▁▁▂▁▃▁▁▁▁▂▂▂▁
wandb: validation_rmse ▃▇▆▅▄▄▃▄▄▇▃▂▆▄▁▄▂▁█▁▂▃▄▁▁▄▂▆▁▁▇▂▁▂▁▁▃▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 5.41639
wandb:      train_rmse 2.32731
wandb: validation_loss 5.2089
wandb: validation_rmse 2.2823
wandb: 
wandb: 🚀 View run efficient-sweep-886 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cw8i5zdx
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_042716-cw8i5zdx/logs
wandb: Agent Starting Run: xs3jvjf6 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_043417-xs3jvjf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-887
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xs3jvjf6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: train_loss ▁                                       
wandb: train_rmse ▁                                       
wandb: 
wandb: Run summary:
wandb:      train_loss nan
wandb:      train_rmse nan
wandb: validation_loss nan
wandb: validation_rmse nan
wandb: 
wandb: 🚀 View run true-sweep-887 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xs3jvjf6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_043417-xs3jvjf6/logs
wandb: Agent Starting Run: snxqvoln with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044121-snxqvoln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-888
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/snxqvoln
wandb:                                                                                
wandb: 🚀 View run peach-sweep-888 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/snxqvoln
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044121-snxqvoln/logs
wandb: Agent Starting Run: 2wb7ksxv with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044126-2wb7ksxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-889
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2wb7ksxv
wandb:                                                                                
wandb: 🚀 View run iconic-sweep-889 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2wb7ksxv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044126-2wb7ksxv/logs
wandb: Agent Starting Run: 6l7iuxjm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044132-6l7iuxjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-890
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6l7iuxjm
wandb:                                                                                
wandb: 🚀 View run flowing-sweep-890 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6l7iuxjm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044132-6l7iuxjm/logs
wandb: Agent Starting Run: 8b3pi0rj with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044137-8b3pi0rj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-891
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8b3pi0rj
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run vibrant-sweep-891 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8b3pi0rj
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044137-8b3pi0rj/logs
wandb: Agent Starting Run: u8jadx2n with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044143-u8jadx2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-892
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u8jadx2n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▃▂▂▁▁▁▁▁
wandb:      train_rmse █▇▄▂▂▂▁▁▁▁
wandb: validation_loss █▆▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 189.36103
wandb:      train_rmse 13.76085
wandb: validation_loss 92.80219
wandb: validation_rmse 9.63339
wandb: 
wandb: 🚀 View run legendary-sweep-892 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u8jadx2n
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044143-u8jadx2n/logs
wandb: Agent Starting Run: mpe06gem with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044316-mpe06gem
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-893
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mpe06gem
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run different-sweep-893 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mpe06gem
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044316-mpe06gem/logs
Run mpe06gem errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run mpe06gem errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 9bazmsya with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044321-9bazmsya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-894
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9bazmsya
wandb:                                                                                
wandb: 🚀 View run good-sweep-894 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9bazmsya
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044321-9bazmsya/logs
wandb: Agent Starting Run: ourm1l1g with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044326-ourm1l1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-895
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ourm1l1g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▁▄▅█▄▆▇█▄▆
wandb: validation_rmse ▁▄▅█▄▆▇█▅▆
wandb: 
wandb: Run summary:
wandb:      train_loss 74.39699
wandb:      train_rmse 8.62537
wandb: validation_loss 83.25818
wandb: validation_rmse 9.12459
wandb: 
wandb: 🚀 View run wise-sweep-895 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ourm1l1g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044326-ourm1l1g/logs
wandb: Agent Starting Run: cdxlhhid with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044454-cdxlhhid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-896
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cdxlhhid
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run upbeat-sweep-896 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/cdxlhhid
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044454-cdxlhhid/logs
wandb: Agent Starting Run: qlyipn0e with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044501-qlyipn0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-897
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qlyipn0e
wandb:                                                                                
wandb: 🚀 View run bumbling-sweep-897 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qlyipn0e
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044501-qlyipn0e/logs
wandb: Agent Starting Run: mf9glt7m with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044506-mf9glt7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-898
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mf9glt7m
wandb:                                                                                
wandb: 🚀 View run quiet-sweep-898 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mf9glt7m
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044506-mf9glt7m/logs
wandb: Agent Starting Run: vlfgtzhd with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044512-vlfgtzhd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-899
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vlfgtzhd
wandb:                                                                                
wandb: 🚀 View run polished-sweep-899 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vlfgtzhd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044512-vlfgtzhd/logs
wandb: Agent Starting Run: ptmin0tf with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044517-ptmin0tf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-900
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ptmin0tf
wandb:                                                                                
wandb: 🚀 View run autumn-sweep-900 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ptmin0tf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044517-ptmin0tf/logs
wandb: Agent Starting Run: ls66ijx9 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044522-ls66ijx9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-901
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ls66ijx9
wandb:                                                                                
wandb: 🚀 View run breezy-sweep-901 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ls66ijx9
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044522-ls66ijx9/logs
wandb: Agent Starting Run: eh4f5105 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044528-eh4f5105
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-902
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eh4f5105
wandb:                                                                                
wandb: 🚀 View run jumping-sweep-902 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eh4f5105
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044528-eh4f5105/logs
wandb: Agent Starting Run: 1k3xa0c7 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044533-1k3xa0c7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-903
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1k3xa0c7
wandb:                                                                                
wandb: 🚀 View run generous-sweep-903 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1k3xa0c7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044533-1k3xa0c7/logs
wandb: Agent Starting Run: vxsgfji7 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044539-vxsgfji7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-904
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vxsgfji7
wandb:                                                                                
wandb: 🚀 View run gallant-sweep-904 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vxsgfji7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044539-vxsgfji7/logs
wandb: Agent Starting Run: 3bdt8l30 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044544-3bdt8l30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-905
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3bdt8l30
wandb:                                                                                
wandb: 🚀 View run silvery-sweep-905 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3bdt8l30
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044544-3bdt8l30/logs
wandb: Agent Starting Run: smvipak7 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044555-smvipak7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-906
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/smvipak7
wandb:                                                                                
wandb: 🚀 View run dainty-sweep-906 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/smvipak7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044555-smvipak7/logs
wandb: Agent Starting Run: 4ar24hl4 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044600-4ar24hl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-907
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4ar24hl4
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run drawn-sweep-907 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4ar24hl4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044600-4ar24hl4/logs
wandb: Agent Starting Run: zrt0aif6 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044605-zrt0aif6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-908
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zrt0aif6
wandb:                                                                                
wandb: 🚀 View run dulcet-sweep-908 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zrt0aif6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044605-zrt0aif6/logs
wandb: Agent Starting Run: 87eou896 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044611-87eou896
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-909
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/87eou896
wandb:                                                                                
wandb: 🚀 View run driven-sweep-909 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/87eou896
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044611-87eou896/logs
wandb: Agent Starting Run: 8sig9aes with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044616-8sig9aes
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-910
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8sig9aes
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▄▃▂▂▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss ▃█▇▆▅▅▃▃▃▁
wandb: validation_rmse ▃█▇▇▅▅▃▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 745.14455
wandb:      train_rmse 27.29734
wandb: validation_loss 751.7923
wandb: validation_rmse 27.41883
wandb: 
wandb: 🚀 View run revived-sweep-910 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8sig9aes
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044616-8sig9aes/logs
wandb: Agent Starting Run: i1gtpl0v with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044807-i1gtpl0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-911
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i1gtpl0v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆██▄▃▂▅▁
wandb:      train_rmse █▇▆██▄▃▂▅▁
wandb: validation_loss █▇▆▆▅▄▃▂▂▁
wandb: validation_rmse █▇▆▆▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 968.44797
wandb:      train_rmse 31.1199
wandb: validation_loss 968.85104
wandb: validation_rmse 31.12637
wandb: 
wandb: 🚀 View run crimson-sweep-911 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i1gtpl0v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044807-i1gtpl0v/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f2nqokb3 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_044945-f2nqokb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-912
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f2nqokb3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▇▆▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 20.77096
wandb:      train_rmse 4.55752
wandb: validation_loss 7.21602
wandb: validation_rmse 2.68626
wandb: 
wandb: 🚀 View run true-sweep-912 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f2nqokb3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_044945-f2nqokb3/logs
wandb: Agent Starting Run: dspgbqin with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_045646-dspgbqin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-913
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dspgbqin
wandb:                                                                                
wandb: 🚀 View run tough-sweep-913 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dspgbqin
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_045646-dspgbqin/logs
wandb: Agent Starting Run: a3fdykd0 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_045651-a3fdykd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-914
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a3fdykd0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▂▂▁▁
wandb:      train_rmse █▇▆▅▄▄▃▂▁▁
wandb: validation_loss █▇▆▅▄▃▂▂▁▁
wandb: validation_rmse █▇▆▅▄▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 293.31058
wandb:      train_rmse 17.12631
wandb: validation_loss 264.43282
wandb: validation_rmse 16.26139
wandb: 
wandb: 🚀 View run frosty-sweep-914 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a3fdykd0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_045651-a3fdykd0/logs
wandb: Agent Starting Run: tuxb7u9l with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_045918-tuxb7u9l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-915
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tuxb7u9l
wandb:                                                                                
wandb: 🚀 View run light-sweep-915 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/tuxb7u9l
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_045918-tuxb7u9l/logs
wandb: Agent Starting Run: a4qadbo2 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_045923-a4qadbo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-916
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a4qadbo2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 69.32155
wandb:      train_rmse 8.32596
wandb: validation_loss 73.30208
wandb: validation_rmse 8.56166
wandb: 
wandb: 🚀 View run genial-sweep-916 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a4qadbo2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_045923-a4qadbo2/logs
wandb: Agent Starting Run: bwh471fd with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050051-bwh471fd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-917
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bwh471fd
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x2x55). Calculated output size: (16x0x13). Output size is too small
wandb:                                                                                
wandb: 🚀 View run radiant-sweep-917 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/bwh471fd
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050051-bwh471fd/logs
Run bwh471fd errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x2x55). Calculated output size: (16x0x13). Output size is too small

wandb: ERROR Run bwh471fd errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (16x2x55). Calculated output size: (16x0x13). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: nt94jzug with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050056-nt94jzug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-918
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nt94jzug
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run grateful-sweep-918 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/nt94jzug
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050056-nt94jzug/logs
Run nt94jzug errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run nt94jzug errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: meaoxa9k with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050102-meaoxa9k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-919
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/meaoxa9k
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
    test_outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: integer out of range
wandb:                                                                                
wandb: 🚀 View run woven-sweep-919 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/meaoxa9k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050102-meaoxa9k/logs
Run meaoxa9k errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
    test_outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: integer out of range

wandb: ERROR Run meaoxa9k errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
wandb: ERROR     test_outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: integer out of range
wandb: ERROR 
wandb: Agent Starting Run: vflzgdsb with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050117-vflzgdsb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-920
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vflzgdsb
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run denim-sweep-920 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vflzgdsb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050117-vflzgdsb/logs
wandb: Agent Starting Run: 10s8ti19 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050123-10s8ti19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-921
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/10s8ti19
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▆▁▁▁▁▁▁▁
wandb:      train_rmse ██▆▁▁▁▁▁▁▁
wandb: validation_loss █▇▂▁▁▁▁▁▁▁
wandb: validation_rmse █▇▃▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 67.10861
wandb:      train_rmse 8.19198
wandb: validation_loss 74.31149
wandb: validation_rmse 8.62041
wandb: 
wandb: 🚀 View run wild-sweep-921 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/10s8ti19
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050123-10s8ti19/logs
wandb: Agent Starting Run: g1f0b386 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050256-g1f0b386
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-922
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g1f0b386
wandb:                                                                                
wandb: 🚀 View run stilted-sweep-922 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/g1f0b386
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050256-g1f0b386/logs
wandb: Agent Starting Run: ps9yz5h3 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050302-ps9yz5h3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-923
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ps9yz5h3
wandb:                                                                                
wandb: 🚀 View run super-sweep-923 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ps9yz5h3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050302-ps9yz5h3/logs
wandb: Agent Starting Run: 4yqnsxku with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050307-4yqnsxku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-924
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4yqnsxku
wandb:                                                                                
wandb: 🚀 View run desert-sweep-924 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4yqnsxku
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050307-4yqnsxku/logs
wandb: Agent Starting Run: 5wh2hs5d with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050312-5wh2hs5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-925
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5wh2hs5d
wandb:                                                                                
wandb: 🚀 View run pleasant-sweep-925 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5wh2hs5d
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050312-5wh2hs5d/logs
wandb: Agent Starting Run: u42m2uy5 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050318-u42m2uy5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-926
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u42m2uy5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▅▃▁▂▄▅█▂▆▃
wandb:      train_rmse ▅▃▁▂▄▅█▂▆▃
wandb: validation_loss ▂▁▇█▅▃▄▆▇▄
wandb: validation_rmse ▂▁▇█▅▃▄▆▇▄
wandb: 
wandb: Run summary:
wandb:      train_loss 982.65239
wandb:      train_rmse 31.34729
wandb: validation_loss 977.72263
wandb: validation_rmse 31.26856
wandb: 
wandb: 🚀 View run super-sweep-926 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u42m2uy5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050318-u42m2uy5/logs
wandb: Agent Starting Run: it0s257v with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050446-it0s257v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-927
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/it0s257v
wandb:                                                                                
wandb: 🚀 View run devout-sweep-927 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/it0s257v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050446-it0s257v/logs
wandb: Agent Starting Run: p9kq7reb with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050452-p9kq7reb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-928
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p9kq7reb
wandb:                                                                                
wandb: 🚀 View run graceful-sweep-928 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/p9kq7reb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050452-p9kq7reb/logs
wandb: Agent Starting Run: 5m37c963 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050457-5m37c963
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-929
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5m37c963
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 🚀 View run cool-sweep-929 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5m37c963
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050457-5m37c963/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: hr9t61gf with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050512-hr9t61gf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-930
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hr9t61gf
wandb:                                                                                
wandb: 🚀 View run sweet-sweep-930 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hr9t61gf
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050512-hr9t61gf/logs
wandb: Agent Starting Run: zx1djpux with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050518-zx1djpux
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-931
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zx1djpux
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▆▄▄▃▂▁▁
wandb:      train_rmse █▇▆▆▄▄▃▂▁▁
wandb: validation_loss █▇▇▆▅▄▃▂▁▁
wandb: validation_rmse █▇▇▆▅▄▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 826.56909
wandb:      train_rmse 28.75011
wandb: validation_loss 703.36417
wandb: validation_rmse 26.52101
wandb: 
wandb: 🚀 View run denim-sweep-931 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zx1djpux
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050518-zx1djpux/logs
wandb: Agent Starting Run: 0h6qhafn with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050651-0h6qhafn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-932
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0h6qhafn
wandb:                                                                                
wandb: 🚀 View run bright-sweep-932 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0h6qhafn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050651-0h6qhafn/logs
wandb: Agent Starting Run: 7gdn8cpw with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050657-7gdn8cpw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-933
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7gdn8cpw
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run bright-sweep-933 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7gdn8cpw
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050657-7gdn8cpw/logs
wandb: Agent Starting Run: 69ix6kz4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050702-69ix6kz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-934
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/69ix6kz4
wandb:                                                                                
wandb: 🚀 View run iconic-sweep-934 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/69ix6kz4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050702-69ix6kz4/logs
wandb: Agent Starting Run: 5siwxojq with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050707-5siwxojq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-935
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5siwxojq
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run mild-sweep-935 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5siwxojq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050707-5siwxojq/logs
Run 5siwxojq errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run 5siwxojq errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: c921uzjn with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050713-c921uzjn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-936
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c921uzjn
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run hearty-sweep-936 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/c921uzjn
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050713-c921uzjn/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4l2irf0v with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050728-4l2irf0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-937
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4l2irf0v
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run soft-sweep-937 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4l2irf0v
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050728-4l2irf0v/logs
wandb: Agent Starting Run: uchtau7g with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050734-uchtau7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-938
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uchtau7g
wandb:                                                                                
wandb: 🚀 View run peachy-sweep-938 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/uchtau7g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050734-uchtau7g/logs
wandb: Agent Starting Run: wca4tbse with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050739-wca4tbse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-939
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wca4tbse
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▄▃▂▁▁
wandb:      train_rmse █▇▇▆▅▄▃▂▁▁
wandb: validation_loss █▇▆▅▄▃▃▂▂▁
wandb: validation_rmse █▇▆▅▅▄▃▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 408.86978
wandb:      train_rmse 20.22053
wandb: validation_loss 339.96869
wandb: validation_rmse 18.43824
wandb: 
wandb: 🚀 View run giddy-sweep-939 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/wca4tbse
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050739-wca4tbse/logs
wandb: Agent Starting Run: pugijiva with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_050913-pugijiva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-940
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pugijiva
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ▆▆▇▅█▆▆▄▅▁
wandb:      train_rmse ▆▆▇▅█▆▆▄▅▁
wandb: validation_loss █▄▄▃▃▃▂▂▂▁
wandb: validation_rmse █▄▄▃▃▃▂▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 965.38089
wandb:      train_rmse 31.07058
wandb: validation_loss 958.36258
wandb: validation_rmse 30.95743
wandb: 
wandb: 🚀 View run wandering-sweep-940 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/pugijiva
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_050913-pugijiva/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f14psudy with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051051-f14psudy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-941
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f14psudy
wandb:                                                                                
wandb: 🚀 View run earthy-sweep-941 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/f14psudy
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051051-f14psudy/logs
wandb: Agent Starting Run: btomkg33 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051057-btomkg33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-942
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/btomkg33
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run dulcet-sweep-942 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/btomkg33
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051057-btomkg33/logs
Run btomkg33 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run btomkg33 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: 3tpreotz with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051102-3tpreotz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-943
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3tpreotz
wandb:                                                                                
wandb: 🚀 View run iconic-sweep-943 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3tpreotz
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051102-3tpreotz/logs
wandb: Agent Starting Run: 939vpzxv with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051107-939vpzxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-944
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/939vpzxv
wandb:                                                                                
wandb: 🚀 View run fancy-sweep-944 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/939vpzxv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051107-939vpzxv/logs
wandb: Agent Starting Run: twird533 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051113-twird533
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-945
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/twird533
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run fallen-sweep-945 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/twird533
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051113-twird533/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jxy90gqi with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051128-jxy90gqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-946
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxy90gqi
wandb:                                                                                
wandb: 🚀 View run mild-sweep-946 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/jxy90gqi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051128-jxy90gqi/logs
wandb: Agent Starting Run: emgzwuaq with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051134-emgzwuaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-947
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/emgzwuaq
wandb:                                                                                
wandb: 🚀 View run still-sweep-947 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/emgzwuaq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051134-emgzwuaq/logs
wandb: Agent Starting Run: yxv32pix with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051139-yxv32pix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-948
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yxv32pix
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-948 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yxv32pix
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051139-yxv32pix/logs
wandb: Agent Starting Run: 1txe7q3s with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051145-1txe7q3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-949
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1txe7q3s
wandb:                                                                                
wandb: 🚀 View run efficient-sweep-949 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1txe7q3s
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051145-1txe7q3s/logs
wandb: Agent Starting Run: v0cv29tv with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051150-v0cv29tv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-950
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v0cv29tv
wandb:                                                                                
wandb: 🚀 View run trim-sweep-950 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/v0cv29tv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051150-v0cv29tv/logs
wandb: Agent Starting Run: maauu6e7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051155-maauu6e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-951
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/maauu6e7
wandb:                                                                                
wandb: 🚀 View run efficient-sweep-951 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/maauu6e7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051155-maauu6e7/logs
wandb: Agent Starting Run: 6pfbj1op with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051201-6pfbj1op
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-952
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6pfbj1op
wandb:                                                                                
wandb: 🚀 View run fragrant-sweep-952 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/6pfbj1op
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051201-6pfbj1op/logs
wandb: Agent Starting Run: lmik0qz7 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051206-lmik0qz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-953
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lmik0qz7
wandb:                                                                                
wandb: 🚀 View run giddy-sweep-953 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lmik0qz7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051206-lmik0qz7/logs
wandb: Agent Starting Run: 8w6jkr6a with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051212-8w6jkr6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-954
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8w6jkr6a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss ██▃▂▁▁▄▅▅▆
wandb:      train_rmse ██▃▂▁▁▄▅▅▆
wandb: validation_loss ▃█▁▆▄▆▅▁▆▃
wandb: validation_rmse ▃█▁▆▄▆▅▁▆▃
wandb: 
wandb: Run summary:
wandb:      train_loss 995.68586
wandb:      train_rmse 31.55449
wandb: validation_loss 985.76443
wandb: validation_rmse 31.39689
wandb: 
wandb: 🚀 View run astral-sweep-954 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/8w6jkr6a
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051212-8w6jkr6a/logs
wandb: Agent Starting Run: 9vpgast5 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051340-9vpgast5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-955
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9vpgast5
wandb:                                                                                
wandb: 🚀 View run pleasant-sweep-955 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/9vpgast5
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051340-9vpgast5/logs
wandb: Agent Starting Run: 3ao5x8we with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051350-3ao5x8we
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-956
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ao5x8we
wandb:                                                                                
wandb: 🚀 View run resilient-sweep-956 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ao5x8we
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051350-3ao5x8we/logs
wandb: Agent Starting Run: 3ue6z9sb with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051355-3ue6z9sb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-957
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ue6z9sb
wandb:                                                                                
wandb: 🚀 View run celestial-sweep-957 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3ue6z9sb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051355-3ue6z9sb/logs
wandb: Agent Starting Run: catdp91u with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051401-catdp91u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-958
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/catdp91u
wandb:                                                                                
wandb: 🚀 View run celestial-sweep-958 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/catdp91u
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051401-catdp91u/logs
wandb: Agent Starting Run: ehrlci13 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051406-ehrlci13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-959
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ehrlci13
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run eager-sweep-959 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ehrlci13
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051406-ehrlci13/logs
wandb: Agent Starting Run: y29w6s8z with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051412-y29w6s8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-960
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y29w6s8z
wandb:                                                                                
wandb: 🚀 View run worthy-sweep-960 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/y29w6s8z
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051412-y29w6s8z/logs
wandb: Agent Starting Run: 4b2sq5yv with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051417-4b2sq5yv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-961
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4b2sq5yv
wandb:                                                                                
wandb: 🚀 View run radiant-sweep-961 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/4b2sq5yv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051417-4b2sq5yv/logs
wandb: Agent Starting Run: zcv0hism with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051422-zcv0hism
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-962
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zcv0hism
wandb:                                                                                
wandb: 🚀 View run cerulean-sweep-962 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zcv0hism
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051422-zcv0hism/logs
wandb: Agent Starting Run: u8e22omq with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051428-u8e22omq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-963
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u8e22omq
wandb:                                                                                
wandb: 🚀 View run treasured-sweep-963 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/u8e22omq
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051428-u8e22omq/logs
wandb: Agent Starting Run: 7jyz84gm with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051433-7jyz84gm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-964
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7jyz84gm
wandb:                                                                                
wandb: 🚀 View run copper-sweep-964 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7jyz84gm
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051433-7jyz84gm/logs
wandb: Agent Starting Run: ntdl161y with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051438-ntdl161y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-965
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ntdl161y
wandb:                                                                                
wandb: 🚀 View run valiant-sweep-965 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ntdl161y
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051438-ntdl161y/logs
wandb: Agent Starting Run: vdvdpjfh with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051444-vdvdpjfh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-966
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vdvdpjfh
wandb:                                                                                
wandb: 🚀 View run autumn-sweep-966 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/vdvdpjfh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051444-vdvdpjfh/logs
wandb: Agent Starting Run: hf4lbvch with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051449-hf4lbvch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-967
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hf4lbvch
wandb:                                                                                
wandb: 🚀 View run expert-sweep-967 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hf4lbvch
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051449-hf4lbvch/logs
wandb: Agent Starting Run: dnoqdj1p with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051455-dnoqdj1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-968
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dnoqdj1p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▂▂▁▁▁▂▂
wandb: validation_rmse █▂▁▃▂▁▂▁▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 122.9102
wandb:      train_rmse 11.08649
wandb: validation_loss 71.76861
wandb: validation_rmse 8.47164
wandb: 
wandb: 🚀 View run soft-sweep-968 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/dnoqdj1p
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051455-dnoqdj1p/logs
wandb: Agent Starting Run: a6g7mfjo with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051623-a6g7mfjo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-969
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a6g7mfjo
wandb:                                                                                
wandb: 🚀 View run silver-sweep-969 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/a6g7mfjo
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051623-a6g7mfjo/logs
wandb: Agent Starting Run: sjtd52wi with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051628-sjtd52wi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-970
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sjtd52wi
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run glamorous-sweep-970 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sjtd52wi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051628-sjtd52wi/logs
wandb: Agent Starting Run: 1yejxlr3 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051634-1yejxlr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-971
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1yejxlr3
wandb:                                                                                
wandb: 🚀 View run lilac-sweep-971 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/1yejxlr3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051634-1yejxlr3/logs
wandb: Agent Starting Run: i3puxs2g with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051639-i3puxs2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-972
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i3puxs2g
wandb:                                                                                
wandb: 🚀 View run rosy-sweep-972 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/i3puxs2g
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051639-i3puxs2g/logs
wandb: Agent Starting Run: s0ywujih with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051645-s0ywujih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-973
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s0ywujih
wandb:                                                                                
wandb: 🚀 View run divine-sweep-973 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s0ywujih
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051645-s0ywujih/logs
wandb: Agent Starting Run: n2n6er4n with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051650-n2n6er4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-974
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/n2n6er4n
wandb:                                                                                
wandb: 🚀 View run hopeful-sweep-974 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/n2n6er4n
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051650-n2n6er4n/logs
wandb: Agent Starting Run: 7ufi7566 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051655-7ufi7566
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-975
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7ufi7566
wandb:                                                                                
wandb: 🚀 View run faithful-sweep-975 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/7ufi7566
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051655-7ufi7566/logs
wandb: Agent Starting Run: w33ss91s with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051701-w33ss91s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-976
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w33ss91s
wandb:                                                                                
wandb: 🚀 View run rosy-sweep-976 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w33ss91s
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051701-w33ss91s/logs
wandb: Agent Starting Run: mrgf78d0 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051706-mrgf78d0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-977
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mrgf78d0
wandb:                                                                                
wandb: 🚀 View run sleek-sweep-977 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/mrgf78d0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051706-mrgf78d0/logs
wandb: Agent Starting Run: noy49u6b with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051712-noy49u6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-978
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/noy49u6b
wandb:                                                                                
wandb: 🚀 View run noble-sweep-978 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/noy49u6b
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051712-noy49u6b/logs
wandb: Agent Starting Run: yegn46p7 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051717-yegn46p7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-979
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yegn46p7
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run sandy-sweep-979 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yegn46p7
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051717-yegn46p7/logs
wandb: Agent Starting Run: 2keq7uwt with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051722-2keq7uwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-980
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2keq7uwt
wandb:                                                                                
wandb: 🚀 View run dauntless-sweep-980 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2keq7uwt
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051722-2keq7uwt/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2ypv6rie with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051747-2ypv6rie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-981
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2ypv6rie
wandb:                                                                                
wandb: 🚀 View run silvery-sweep-981 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/2ypv6rie
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051747-2ypv6rie/logs
wandb: Agent Starting Run: fr4sm9bv with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051753-fr4sm9bv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-982
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fr4sm9bv
wandb:                                                                                
wandb: 🚀 View run clear-sweep-982 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fr4sm9bv
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051753-fr4sm9bv/logs
wandb: Agent Starting Run: h8gtljnp with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051758-h8gtljnp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-983
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h8gtljnp
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb:                                                                                
wandb: 🚀 View run hardy-sweep-983 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h8gtljnp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051758-h8gtljnp/logs
wandb: Agent Starting Run: qfycddpi with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x1
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051803-qfycddpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-984
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qfycddpi
wandb:                                                                                
wandb: 🚀 View run expert-sweep-984 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qfycddpi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051803-qfycddpi/logs
wandb: Agent Starting Run: ovosp4n3 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051809-ovosp4n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-985
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ovosp4n3
wandb:                                                                                
wandb: 🚀 View run snowy-sweep-985 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ovosp4n3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051809-ovosp4n3/logs
wandb: Agent Starting Run: z6c9lbq3 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051814-z6c9lbq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-986
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z6c9lbq3
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x2x24). Calculated output size: (16x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run confused-sweep-986 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/z6c9lbq3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051814-z6c9lbq3/logs
Run z6c9lbq3 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (16x2x24). Calculated output size: (16x0x6). Output size is too small

wandb: ERROR Run z6c9lbq3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (16x2x24). Calculated output size: (16x0x6). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: sdahrplp with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051819-sdahrplp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-987
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sdahrplp
wandb:                                                                                
wandb: 🚀 View run frosty-sweep-987 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/sdahrplp
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051819-sdahrplp/logs
wandb: Agent Starting Run: eo9q84g0 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051825-eo9q84g0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-988
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eo9q84g0
wandb:                                                                                
wandb: 🚀 View run toasty-sweep-988 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/eo9q84g0
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051825-eo9q84g0/logs
wandb: Agent Starting Run: 5djk8h7j with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051831-5djk8h7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-989
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5djk8h7j
wandb:                                                                                
wandb: 🚀 View run toasty-sweep-989 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/5djk8h7j
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051831-5djk8h7j/logs
wandb: Agent Starting Run: xwbpz1hb with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051836-xwbpz1hb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-990
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xwbpz1hb
wandb:                                                                                
wandb: 🚀 View run swift-sweep-990 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/xwbpz1hb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051836-xwbpz1hb/logs
wandb: Agent Starting Run: h3idtbdg with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.3
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051842-h3idtbdg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-991
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h3idtbdg
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run wise-sweep-991 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h3idtbdg
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051842-h3idtbdg/logs
wandb: Agent Starting Run: zv5ngxb2 with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051847-zv5ngxb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-992
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zv5ngxb2
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
    test_outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: integer out of range
wandb:                                                                                
wandb: 🚀 View run helpful-sweep-992 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/zv5ngxb2
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051847-zv5ngxb2/logs
Run zv5ngxb2 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
    test_outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: integer out of range

wandb: ERROR Run zv5ngxb2 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 241, in train
wandb: ERROR     test_outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: integer out of range
wandb: ERROR 
wandb: Agent Starting Run: kkfmd12t with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.4
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051908-kkfmd12t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-993
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kkfmd12t
wandb:                                                                                
wandb: 🚀 View run radiant-sweep-993 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/kkfmd12t
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051908-kkfmd12t/logs
wandb: Agent Starting Run: fdxhmql3 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.1
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 2
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051914-fdxhmql3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-994
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fdxhmql3
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run rich-sweep-994 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/fdxhmql3
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051914-fdxhmql3/logs
Run fdxhmql3 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run fdxhmql3 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: gxou7e2x with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051919-gxou7e2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-995
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gxou7e2x
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -832: [128, -832]
wandb:                                                                                
wandb: 🚀 View run graceful-sweep-995 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/gxou7e2x
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051919-gxou7e2x/logs
Run gxou7e2x errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
    model = CNN_97(
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
    fc_layers.append(nn.Linear(input_dim, hidden_units))
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -832: [128, -832]

wandb: ERROR Run gxou7e2x errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 104, in train
wandb: ERROR     model = CNN_97(
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 64, in __init__
wandb: ERROR     fc_layers.append(nn.Linear(input_dim, hidden_units))
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/linear.py", line 99, in __init__
wandb: ERROR     self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
wandb: ERROR RuntimeError: Trying to create tensor with negative dimension -832: [128, -832]
wandb: ERROR 
wandb: Agent Starting Run: 3j212e5k with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051925-3j212e5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-996
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3j212e5k
wandb:                                                                                
wandb: 🚀 View run comfy-sweep-996 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/3j212e5k
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051925-3j212e5k/logs
wandb: Agent Starting Run: 95o8q4kk with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051930-95o8q4kk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-997
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/95o8q4kk
wandb:                                                                                
wandb: 🚀 View run zany-sweep-997 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/95o8q4kk
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051930-95o8q4kk/logs
wandb: Agent Starting Run: qj8quyq4 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Xavier_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051935-qj8quyq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-998
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qj8quyq4
wandb:                                                                                
wandb: 🚀 View run treasured-sweep-998 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/qj8quyq4
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051935-qj8quyq4/logs
wandb: Agent Starting Run: s2b4vzmi with config:
wandb: 	activation_fn: Tanh
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 5x5
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: Adam
wandb: 	out_channels: 16
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051941-s2b4vzmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-999
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s2b4vzmi
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero
wandb:                                                                                
wandb: 🚀 View run rosy-sweep-999 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s2b4vzmi
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051941-s2b4vzmi/logs
Run s2b4vzmi errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
    model.apply(weights_init_map[config.weights_init])
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
    module.apply(fn)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
    fn(self)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
    'Uniform': lambda m: weights_init_uniform_rule(m),
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
    y = 1.0/n**.5
ZeroDivisionError: float division by zero

wandb: ERROR Run s2b4vzmi errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 140, in train
wandb: ERROR     model.apply(weights_init_map[config.weights_init])
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 895, in apply
wandb: ERROR     module.apply(fn)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 896, in apply
wandb: ERROR     fn(self)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 122, in <lambda>
wandb: ERROR     'Uniform': lambda m: weights_init_uniform_rule(m),
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 91, in weights_init_uniform_rule
wandb: ERROR     y = 1.0/n**.5
wandb: ERROR ZeroDivisionError: float division by zero
wandb: ERROR 
wandb: Agent Starting Run: yqz4cpq6 with config:
wandb: 	activation_fn: Mish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.7
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Xavier_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051946-yqz4cpq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-1000
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yqz4cpq6
wandb:                                                                                
wandb: 🚀 View run firm-sweep-1000 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/yqz4cpq6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051946-yqz4cpq6/logs
wandb: Agent Starting Run: lt3vfivh with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051951-lt3vfivh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-1001
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lt3vfivh
wandb:                                                                                
wandb: 🚀 View run laced-sweep-1001 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/lt3vfivh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051951-lt3vfivh/logs
wandb: Agent Starting Run: ytpr99wa with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_051957-ytpr99wa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-1002
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ytpr99wa
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:499: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb:                                                                                
wandb: 🚀 View run hopeful-sweep-1002 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ytpr99wa
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051957-ytpr99wa/logs
wandb: Agent Starting Run: hip6pk48 with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: SGD
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 3
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052002-hip6pk48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-1003
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hip6pk48
/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x1x26). Calculated output size: (32x0x6). Output size is too small
wandb:                                                                                
wandb: 🚀 View run elated-sweep-1003 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/hip6pk48
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052002-hip6pk48/logs
Run hip6pk48 errored:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
    avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
    outputs = model(spectrogram)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
    x = self.conv_layers(input_data)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
    return if_false(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (32x1x26). Calculated output size: (32x0x6). Output size is too small

wandb: ERROR Run hip6pk48 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 231, in train
wandb: ERROR     avg_loss = train_one_epoch(loss_fn, model, train_data_loader, optimizer)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/modular_train_test.py", line 56, in train_one_epoch
wandb: ERROR     outputs = model(spectrogram)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/scripts/models.py", line 76, in forward
wandb: ERROR     x = self.conv_layers(input_data)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 219, in forward
wandb: ERROR     input = module(input)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
wandb: ERROR     return self._call_impl(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
wandb: ERROR     return forward_call(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/modules/pooling.py", line 164, in forward
wandb: ERROR     return F.max_pool2d(input, self.kernel_size, self.stride,
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/_jit_internal.py", line 503, in fn
wandb: ERROR     return if_false(*args, **kwargs)
wandb: ERROR   File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 796, in _max_pool2d
wandb: ERROR     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
wandb: ERROR RuntimeError: Given input size: (32x1x26). Calculated output size: (32x0x6). Output size is too small
wandb: ERROR 
wandb: Agent Starting Run: h87c27i8 with config:
wandb: 	activation_fn: Sigmoid
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x5
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.2
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdaGrad
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052008-h87c27i8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-1004
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h87c27i8
wandb:                                                                                
wandb: 🚀 View run exalted-sweep-1004 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/h87c27i8
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052008-h87c27i8/logs
wandb: Agent Starting Run: s3uflj26 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 5x7
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.8
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: SGD
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.01
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052013-s3uflj26
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-1005
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s3uflj26
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇▆▅▄▄▃▂▁
wandb:      train_rmse ██▇▇▆▅▄▃▂▁
wandb: validation_loss ▁▁▁█▁▁▁▁▁▁
wandb: validation_rmse ▁▁▁█▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 206.01413
wandb:      train_rmse 14.35319
wandb: validation_loss 155.99622
wandb: validation_rmse 12.48984
wandb: 
wandb: 🚀 View run stellar-sweep-1005 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/s3uflj26
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052013-s3uflj26/logs
wandb: Agent Starting Run: k7ynnpqb with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 7x5
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 3
wandb: 	pooling_size: 1
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Uniform
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052147-k7ynnpqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-1006
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k7ynnpqb
wandb:                                                                                
wandb: 🚀 View run dry-sweep-1006 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/k7ynnpqb
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052147-k7ynnpqb/logs
wandb: Agent Starting Run: w0unv76q with config:
wandb: 	activation_fn: LeakyReLU
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 7x3
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.5
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 4
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052152-w0unv76q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-1007
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w0unv76q
wandb:                                                                                
wandb: 🚀 View run curious-sweep-1007 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/w0unv76q
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052152-w0unv76q/logs
wandb: Agent Starting Run: ds9hx2s6 with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 16
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x7
wandb: 	learning_rate: 1e-06
wandb: 	linear_dropout: 0.4
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 1
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 8
wandb: 	padding: 1
wandb: 	pooling_size: 4
wandb: 	stride: 2
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052157-ds9hx2s6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-1008
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ds9hx2s6
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run tough-sweep-1008 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/ds9hx2s6
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052157-ds9hx2s6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 3133, in agent_heartbeat
wandb: Agent Starting Run: 0nmu2gbh with config:
wandb: 	activation_fn: Swish
wandb: 	batch_size: 64
wandb: 	conv_dropout: 0.2
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 1x3
wandb: 	learning_rate: 1e-05
wandb: 	linear_dropout: 0.1
wandb: 	momentum: 0.9
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 3
wandb: 	optimizer: Adam
wandb: 	out_channels: 8
wandb: 	padding: 0
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Xavier_normal
    response = self.gql(
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 372, in gql
    ret = self._retry_gql(
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/sdk/lib/retry.py", line 131, in __call__
    result = self._call_fn(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 400, in execute
    return self.client.execute(*args, **kwargs)  # type: ignore
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/sdk/lib/gql_request.py", line 58, in execute
    request = self.session.post(self.url, **post_args)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/requests/sessions.py", line 579, in request
    settings = self.merge_environment_settings(
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/requests/sessions.py", line 760, in merge_environment_settings
    env_proxies = get_environ_proxies(url, no_proxy=no_proxy)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/requests/utils.py", line 835, in get_environ_proxies
    return getproxies()
  File "/usr/lib64/python3.9/urllib/request.py", line 2508, in getproxies_environment
    for name, value in os.environ.items():
  File "/usr/lib64/python3.9/_collections_abc.py", line 851, in __iter__
    yield (key, self._mapping[key])
  File "/usr/lib64/python3.9/os.py", line 679, in __getitem__
    raise KeyError(key) from None
KeyError: 'WANDB_SERVICE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib64/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/usr/lib64/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/agents/pyagent.py", line 165, in _heartbeat
    commands = self._api.agent_heartbeat(self._agent_id, {}, run_status)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/apis/internal.py", line 157, in agent_heartbeat
    return self.api.agent_heartbeat(*args, **kwargs)
  File "/zhome/fb/0/212723/DL/p4_velocity/DL_97_venv/lib64/python3.9/site-packages/wandb/sdk/internal/internal_api.py", line 3144, in agent_heartbeat
    message = ast.literal_eval(e.args[0])["message"]
  File "/usr/lib64/python3.9/ast.py", line 105, in literal_eval
    return _convert(node_or_string)
  File "/usr/lib64/python3.9/ast.py", line 104, in _convert
    return _convert_signed_num(node)
  File "/usr/lib64/python3.9/ast.py", line 78, in _convert_signed_num
    return _convert_num(node)
  File "/usr/lib64/python3.9/ast.py", line 69, in _convert_num
    _raise_malformed_node(node)
  File "/usr/lib64/python3.9/ast.py", line 66, in _raise_malformed_node
    raise ValueError(f'malformed node or string: {node!r}')
ValueError: malformed node or string: <ast.Name object at 0x7f1ab5b8e9a0>
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/fb/0/212723/DL/p4_velocity/git/DeepLearning97/wandb/run-20241121_052213-0nmu2gbh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-1009
wandb: ⭐️ View project at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: 🧹 View sweep at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/sweeps/j2yrn3og
wandb: 🚀 View run at https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0nmu2gbh
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb:                                                                                
wandb: 🚀 View run sage-sweep-1009 at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097/runs/0nmu2gbh
wandb: ⭐️ View project at: https://wandb.ai/raimo-sieber-technical-university-of-munich/Deep%20Learning%20Project%20Group%2097
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_052213-0nmu2gbh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Ctrl + C detected. Stopping sweep.
Terminated
