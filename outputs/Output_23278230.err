Loaded module: cuda/11.8
Loaded dependency [python3/3.10.13]: sqlite3/3.45.1
Loaded dependency [python3/3.10.13]: gcc/12.3.0-binutils-2.40
Loaded module: python3/3.10.13

Loading python3/3.10.13
  Loading requirement: sqlite3/3.45.1 gcc/12.3.0-binutils-2.40
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: s232735 (s232735-danmarks-tekniske-universitet-dtu). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /zhome/cf/5/202847/.netrc
wandb: Agent Starting Run: qa2zecyg with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_182321-qa2zecyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-1
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qa2zecyg
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.007 MB of 0.007 MB uploadedwandb: | 0.007 MB of 0.007 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▁▁▁▁▁
wandb: validation_loss █▄▃▂▁▁▁▁▁▁
wandb: validation_rmse █▅▃▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 9.14633
wandb:      train_rmse 3.02429
wandb: validation_loss 89.14062
wandb: validation_rmse 9.44143
wandb: 
wandb: 🚀 View run smart-sweep-1 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qa2zecyg
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_182321-qa2zecyg/logs
wandb: Agent Starting Run: 7gta20ga with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_182647-7gta20ga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-2
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/7gta20ga
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▂▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▃▄▄▄▄
wandb: validation_rmse █▆▃▂▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▄▄▅▅▅▅
wandb: 
wandb: Run summary:
wandb:      train_loss 5.02853
wandb:      train_rmse 2.24244
wandb: validation_loss 77.1084
wandb: validation_rmse 8.78114
wandb: 
wandb: 🚀 View run cosmic-sweep-2 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/7gta20ga
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_182647-7gta20ga/logs
wandb: Agent Starting Run: gqx3goz4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_183254-gqx3goz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-3
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/gqx3goz4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.0
wandb:      train_rmse 0.00167
wandb: validation_loss 5.50421
wandb: validation_rmse 2.3461
wandb: 
wandb: 🚀 View run clear-sweep-3 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/gqx3goz4
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_183254-gqx3goz4/logs
wandb: Agent Starting Run: r7usz8mr with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_184333-r7usz8mr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-4
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/r7usz8mr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▁▁▁▁
wandb:      train_rmse █▄▃▃▂▂▂▁▁▁
wandb: validation_loss ▃▁▃▅▅▄▇▅▆█
wandb: validation_rmse ▃▁▃▆▅▄▇▅▆█
wandb: 
wandb: Run summary:
wandb:      train_loss 11.14083
wandb:      train_rmse 3.33779
wandb: validation_loss 463.21057
wandb: validation_rmse 21.52233
wandb: 
wandb: 🚀 View run glorious-sweep-4 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/r7usz8mr
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_184333-r7usz8mr/logs
wandb: Agent Starting Run: f2pxoyql with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_184553-f2pxoyql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-5
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/f2pxoyql
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.35889
wandb:      train_rmse 0.59907
wandb: validation_loss 4.81574
wandb: validation_rmse 2.19448
wandb: 
wandb: 🚀 View run curious-sweep-5 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/f2pxoyql
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_184553-f2pxoyql/logs
wandb: Agent Starting Run: 63ly4fl5 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_185643-63ly4fl5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-6
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/63ly4fl5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▁▁▁▁
wandb: validation_loss ▄▃▂▁▅▂▄▄▂█
wandb: validation_rmse ▄▃▂▁▅▂▅▄▂█
wandb: 
wandb: Run summary:
wandb:      train_loss 11.12968
wandb:      train_rmse 3.33612
wandb: validation_loss 316.04425
wandb: validation_rmse 17.77763
wandb: 
wandb: 🚀 View run fearless-sweep-6 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/63ly4fl5
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_185643-63ly4fl5/logs
wandb: Agent Starting Run: feytpeza with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_185902-feytpeza
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-7
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/feytpeza
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▁▁▂▂▂▃▂▃
wandb: validation_rmse █▁▂▁▂▂▂▃▂▃
wandb: 
wandb: Run summary:
wandb:      train_loss 6.94944
wandb:      train_rmse 2.63618
wandb: validation_loss 137.31526
wandb: validation_rmse 11.71816
wandb: 
wandb: 🚀 View run lilac-sweep-7 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/feytpeza
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_185902-feytpeza/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mqu0ngos with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_190127-mqu0ngos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-8
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/mqu0ngos
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁
wandb: validation_rmse █▃▃▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.18876
wandb:      train_rmse 0.43447
wandb: validation_loss 5.20853
wandb: validation_rmse 2.28222
wandb: 
wandb: 🚀 View run good-sweep-8 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/mqu0ngos
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_190127-mqu0ngos/logs
wandb: Agent Starting Run: fpymv5uu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_191222-fpymv5uu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-9
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/fpymv5uu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▃▂▂▁▁
wandb:      train_rmse █▆▅▅▄▃▂▂▁▁
wandb: validation_loss █▄▄▃▄▄▃▂▁▁
wandb: validation_rmse █▄▄▃▄▄▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 792.20994
wandb:      train_rmse 28.14622
wandb: validation_loss 814.81348
wandb: validation_rmse 28.54494
wandb: 
wandb: 🚀 View run lemon-sweep-9 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/fpymv5uu
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_191222-fpymv5uu/logs
wandb: Agent Starting Run: 4b680o7n with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_191436-4b680o7n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-10
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4b680o7n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▄▄▃▂▂▁
wandb:      train_rmse █▆▆▅▄▄▃▂▂▁
wandb: validation_loss █▄▃▃▃▂▂▁▂▁
wandb: validation_rmse █▄▃▄▃▂▂▁▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 835.65119
wandb:      train_rmse 28.90763
wandb: validation_loss 836.4584
wandb: validation_rmse 28.92159
wandb: 
wandb: 🚀 View run winter-sweep-10 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4b680o7n
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_191436-4b680o7n/logs
wandb: Agent Starting Run: m7xksg67 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_191651-m7xksg67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-11
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/m7xksg67
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.00067
wandb:      train_rmse 0.02592
wandb: validation_loss 5.26334
wandb: validation_rmse 2.2942
wandb: 
wandb: 🚀 View run fresh-sweep-11 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/m7xksg67
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_191651-m7xksg67/logs
wandb: Agent Starting Run: ray2um9t with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_192726-ray2um9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-12
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ray2um9t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▁▁▁▁
wandb: validation_loss ▁▁▂▃▂▅▃▄█▃
wandb: validation_rmse ▁▁▂▄▂▅▃▄█▃
wandb: 
wandb: Run summary:
wandb:      train_loss 7.148
wandb:      train_rmse 2.67357
wandb: validation_loss 116.84069
wandb: validation_rmse 10.80929
wandb: 
wandb: 🚀 View run solar-sweep-12 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ray2um9t
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_192726-ray2um9t/logs
wandb: Agent Starting Run: vsa8730i with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_192940-vsa8730i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-13
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vsa8730i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▂
wandb:      train_rmse █▂▁▂▁▁▁▁▁▂
wandb: validation_loss ▅▃▃▅▃▆█▃▄▁
wandb: validation_rmse ▅▃▃▅▃▆█▃▄▁
wandb: 
wandb: Run summary:
wandb:      train_loss 27.09171
wandb:      train_rmse 5.20497
wandb: validation_loss 286.13699
wandb: validation_rmse 16.91558
wandb: 
wandb: 🚀 View run atomic-sweep-13 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vsa8730i
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_192940-vsa8730i/logs
wandb: Agent Starting Run: rsx52bn3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_193154-rsx52bn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-14
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/rsx52bn3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.12764
wandb:      train_rmse 0.35727
wandb: validation_loss 5.51666
wandb: validation_rmse 2.34876
wandb: 
wandb: 🚀 View run happy-sweep-14 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/rsx52bn3
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_193154-rsx52bn3/logs
wandb: Agent Starting Run: yxs8v4ih with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_194240-yxs8v4ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-15
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yxs8v4ih
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▂▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▂▁▁▂▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁
wandb: validation_loss ▅▃▃▂▂▂▆▂▂█▁▄▄▃▂▂▁▂▂▆▃▃▁▁▁▁▁▁▂▁▂▃▂▂▁▂▂▁▂▁
wandb: validation_rmse ▅▃▂▃▅▆▂▃█▄▄▅▄▂▃▃▃▂▆▂▃▁▁▁▁▁▂▂▁▄▄▂▂▁▃▃▁▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 55.56075
wandb:      train_rmse 7.45391
wandb: validation_loss 5.96949
wandb: validation_rmse 2.44325
wandb: 
wandb: 🚀 View run gallant-sweep-15 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yxs8v4ih
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_194240-yxs8v4ih/logs
wandb: Agent Starting Run: zna4enyi with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_195320-zna4enyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-16
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zna4enyi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▄▁▁▁▂▂▃▃▃
wandb: validation_rmse █▄▁▁▂▂▂▄▃▄
wandb: 
wandb: Run summary:
wandb:      train_loss 6.39588
wandb:      train_rmse 2.52901
wandb: validation_loss 172.2064
wandb: validation_rmse 13.12274
wandb: 
wandb: 🚀 View run sparkling-sweep-16 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zna4enyi
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_195320-zna4enyi/logs
wandb: Agent Starting Run: c7azblu0 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_195535-c7azblu0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-17
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/c7azblu0
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.07569
wandb:      train_rmse 0.27513
wandb: validation_loss 4.37913
wandb: validation_rmse 2.09264
wandb: 
wandb: 🚀 View run lyric-sweep-17 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/c7azblu0
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_195535-c7azblu0/logs
wandb: Agent Starting Run: fumv3ocx with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_200615-fumv3ocx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-18
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/fumv3ocx
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▄▃▂▂▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss ▂▁▂▄▅▆▇▇▇█
wandb: validation_rmse ▂▁▃▄▆▆▇▇██
wandb: 
wandb: Run summary:
wandb:      train_loss 717.00053
wandb:      train_rmse 26.77687
wandb: validation_loss 682.15521
wandb: validation_rmse 26.1181
wandb: 
wandb: 🚀 View run misunderstood-sweep-18 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/fumv3ocx
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_200615-fumv3ocx/logs
wandb: Agent Starting Run: jkzay9wa with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_200829-jkzay9wa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-19
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jkzay9wa
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.1894
wandb:      train_rmse 0.4352
wandb: validation_loss 4.72074
wandb: validation_rmse 2.17273
wandb: 
wandb: 🚀 View run devout-sweep-19 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jkzay9wa
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_200829-jkzay9wa/logs
wandb: Agent Starting Run: aowh7wp8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_201909-aowh7wp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-20
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/aowh7wp8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▁▁▁▁▁▁
wandb: validation_loss █▂▁▃▄▄▅▄▃▆
wandb: validation_rmse █▂▁▃▅▄▅▄▃▇
wandb: 
wandb: Run summary:
wandb:      train_loss 12.60272
wandb:      train_rmse 3.55003
wandb: validation_loss 243.54646
wandb: validation_rmse 15.60597
wandb: 
wandb: 🚀 View run legendary-sweep-20 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/aowh7wp8
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_201909-aowh7wp8/logs
wandb: Agent Starting Run: pybx5rfm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_202124-pybx5rfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-21
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/pybx5rfm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▅▂█▂▄▁▃▄▁▁▁▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁
wandb: validation_rmse ▅▃█▃▅▁▅▂▂▁▁▂▂▁▃▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▁▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 14.20942
wandb:      train_rmse 3.76954
wandb: validation_loss 6.12468
wandb: validation_rmse 2.47481
wandb: 
wandb: 🚀 View run sleek-sweep-21 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/pybx5rfm
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_202124-pybx5rfm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 42pxbzy9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_203219-42pxbzy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-22
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/42pxbzy9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▄▃▃▂▂▁
wandb:      train_rmse █▆▆▅▄▃▃▂▂▁
wandb: validation_loss █▄▇▅▄▄▃▂▁▁
wandb: validation_rmse █▄▇▅▄▄▃▂▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 684.67146
wandb:      train_rmse 26.16623
wandb: validation_loss 683.11996
wandb: validation_rmse 26.13656
wandb: 
wandb: 🚀 View run desert-sweep-22 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/42pxbzy9
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_203219-42pxbzy9/logs
wandb: Agent Starting Run: enn9y3pe with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_203445-enn9y3pe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-23
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/enn9y3pe
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▄▄▃▂▂▁
wandb:      train_rmse █▆▆▅▄▄▃▂▂▁
wandb: validation_loss █▆▇▅▅▇▃▃▃▁
wandb: validation_rmse █▆▇▅▅▇▃▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 701.22813
wandb:      train_rmse 26.48071
wandb: validation_loss 706.53247
wandb: validation_rmse 26.58068
wandb: 
wandb: 🚀 View run light-sweep-23 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/enn9y3pe
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_203445-enn9y3pe/logs
wandb: Agent Starting Run: gc4mwusu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_203659-gc4mwusu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-24
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/gc4mwusu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▁▁▁▁
wandb: validation_loss █▁▃▂▃▄▄▅▃▅
wandb: validation_rmse █▁▃▂▄▄▄▅▄▅
wandb: 
wandb: Run summary:
wandb:      train_loss 5.67163
wandb:      train_rmse 2.38152
wandb: validation_loss 150.61629
wandb: validation_rmse 12.27258
wandb: 
wandb: 🚀 View run vivid-sweep-24 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/gc4mwusu
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_203659-gc4mwusu/logs
wandb: Agent Starting Run: g51ioiur with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_203914-g51ioiur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-25
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/g51ioiur
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss ▆▁▃▅▄▇▇██▇
wandb: validation_rmse ▆▁▃▅▅▇▇██▇
wandb: 
wandb: Run summary:
wandb:      train_loss 5.4704
wandb:      train_rmse 2.33889
wandb: validation_loss 278.86935
wandb: validation_rmse 16.69938
wandb: 
wandb: 🚀 View run silver-sweep-25 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/g51ioiur
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_203914-g51ioiur/logs
wandb: Agent Starting Run: gnknfoba with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_204128-gnknfoba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-26
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/gnknfoba
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss ▅▃▂█▆▆▄▄▁▃
wandb: validation_rmse ▅▃▂█▆▆▄▄▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 7.09762
wandb:      train_rmse 2.66414
wandb: validation_loss 249.90167
wandb: validation_rmse 15.80828
wandb: 
wandb: 🚀 View run vocal-sweep-26 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/gnknfoba
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_204128-gnknfoba/logs
wandb: Agent Starting Run: df4rj98j with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_204342-df4rj98j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-27
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/df4rj98j
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▂▁▁▁▁▁▁▁
wandb: validation_loss █▅▃▂▁▁▂▁▁▁
wandb: validation_rmse █▆▃▂▁▁▂▁▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 8.57991
wandb:      train_rmse 2.92915
wandb: validation_loss 223.52524
wandb: validation_rmse 14.95076
wandb: 
wandb: 🚀 View run vibrant-sweep-27 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/df4rj98j
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_204342-df4rj98j/logs
wandb: Agent Starting Run: cojhmfwv with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_204556-cojhmfwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-28
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/cojhmfwv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▂▂▂▃▁▂▁▁▂▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▃▂▂▂▄▁▂▁▂▁▂▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.39038
wandb:      train_rmse 0.6248
wandb: validation_loss 4.84602
wandb: validation_rmse 2.20137
wandb: 
wandb: 🚀 View run zany-sweep-28 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/cojhmfwv
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_204556-cojhmfwv/logs
wandb: Agent Starting Run: 8kwrnvad with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_205647-8kwrnvad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-29
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/8kwrnvad
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▃▃▂▂▁
wandb:      train_rmse █▆▅▅▄▃▃▂▂▁
wandb: validation_loss ▁▂▃▄▅▇▆██▇
wandb: validation_rmse ▁▂▃▄▅▇▆██▇
wandb: 
wandb: Run summary:
wandb:      train_loss 901.7011
wandb:      train_rmse 30.02834
wandb: validation_loss 988.17438
wandb: validation_rmse 31.43524
wandb: 
wandb: 🚀 View run skilled-sweep-29 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/8kwrnvad
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_205647-8kwrnvad/logs
wandb: Agent Starting Run: eugqfg63 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_205902-eugqfg63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-30
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/eugqfg63
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▂▁▁▁▁▁▁▁
wandb: validation_loss █▆▂▂▁▁▁▂▂▂
wandb: validation_rmse █▆▂▂▁▁▁▂▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 6.73346
wandb:      train_rmse 2.59489
wandb: validation_loss 104.28606
wandb: validation_rmse 10.21205
wandb: 
wandb: 🚀 View run fanciful-sweep-30 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/eugqfg63
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_205902-eugqfg63/logs
wandb: Agent Starting Run: 144jc5ps with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_210116-144jc5ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-31
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/144jc5ps
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▁▁▁▁▁▁
wandb: validation_loss █▄▁▃▄▃▇▁▃▆
wandb: validation_rmse █▄▁▃▄▄▇▁▃▆
wandb: 
wandb: Run summary:
wandb:      train_loss 12.72014
wandb:      train_rmse 3.56653
wandb: validation_loss 269.78778
wandb: validation_rmse 16.42522
wandb: 
wandb: 🚀 View run rosy-sweep-31 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/144jc5ps
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_210116-144jc5ps/logs
wandb: Agent Starting Run: hmp73z2g with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_210331-hmp73z2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-32
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/hmp73z2g
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.03466
wandb:      train_rmse 0.18616
wandb: validation_loss 5.02766
wandb: validation_rmse 2.24225
wandb: 
wandb: 🚀 View run visionary-sweep-32 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/hmp73z2g
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_210331-hmp73z2g/logs
wandb: Agent Starting Run: e84ar1ok with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_211416-e84ar1ok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-33
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/e84ar1ok
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▁▁▁▁▁▁
wandb: validation_loss ▁▆▆▇▆▆▆█▇█
wandb: validation_rmse ▁▆▆▇▆▆▆█▇█
wandb: 
wandb: Run summary:
wandb:      train_loss 11.42388
wandb:      train_rmse 3.37992
wandb: validation_loss 354.33633
wandb: validation_rmse 18.82382
wandb: 
wandb: 🚀 View run zesty-sweep-33 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/e84ar1ok
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_211416-e84ar1ok/logs
wandb: Agent Starting Run: 4nywdhdp with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_211631-4nywdhdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-34
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4nywdhdp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▁▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▃▃▂▁▁▂▂▂▁▁▃▁▁▁▁▁▂▄▂▁▁▁▂▁▁▂▁▂▁▂▁▁▂▁▁▁▁▁
wandb: validation_rmse █▄▃▃▂▁▁▂▂▂▁▃▁▁▁▁▁▂▄▁▁▁▁▂▂▁▂▁▁▂▁▂▁▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.40033
wandb:      train_rmse 0.63272
wandb: validation_loss 4.47548
wandb: validation_rmse 2.11553
wandb: 
wandb: 🚀 View run comfy-sweep-34 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4nywdhdp
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_211631-4nywdhdp/logs
wandb: Agent Starting Run: iq49nx2z with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_212727-iq49nx2z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-35
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/iq49nx2z
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▁▁▁▁▁
wandb: validation_loss █▅▃▃▂▂▂▁▁▁
wandb: validation_rmse █▅▃▃▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 10.85497
wandb:      train_rmse 3.29469
wandb: validation_loss 368.41161
wandb: validation_rmse 19.19405
wandb: 
wandb: 🚀 View run zesty-sweep-35 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/iq49nx2z
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_212727-iq49nx2z/logs
wandb: Agent Starting Run: dfcneo3v with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_212941-dfcneo3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-36
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/dfcneo3v
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▂▁▁▂▂▂
wandb: validation_rmse █▂▂▁▂▁▁▂▂▃
wandb: 
wandb: Run summary:
wandb:      train_loss 7.87932
wandb:      train_rmse 2.80701
wandb: validation_loss 173.97219
wandb: validation_rmse 13.18985
wandb: 
wandb: 🚀 View run electric-sweep-36 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/dfcneo3v
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_212941-dfcneo3v/logs
wandb: Agent Starting Run: ny1he9jc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_213155-ny1he9jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-37
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ny1he9jc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▂▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▂▁▁▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁
wandb: validation_loss ▆▃▂▁▁▂▁▃▄▃▅▂▆▁▂▁█▃▃▁▂▁▂▃▁▂▂▃▂▃▁▁▂▁▃▂▁▁▁▁
wandb: validation_rmse █▄▃▂▂▂▄▅▄▅▃█▂▂▂▄▄▂▂▂▂▂▅▁▆▃▄▂▃▄▁▁▂▁▅▃▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 32.04855
wandb:      train_rmse 5.66114
wandb: validation_loss 5.3794
wandb: validation_rmse 2.31935
wandb: 
wandb: 🚀 View run copper-sweep-37 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ny1he9jc
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_213155-ny1he9jc/logs
wandb: Agent Starting Run: 5nlvvyj3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_214241-5nlvvyj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-38
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5nlvvyj3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▄▄▃▂▂▁
wandb:      train_rmse █▆▆▅▄▄▃▂▂▁
wandb: validation_loss ▁▃▄▅▇▆████
wandb: validation_rmse ▁▃▄▅▇▆████
wandb: 
wandb: Run summary:
wandb:      train_loss 767.82197
wandb:      train_rmse 27.7096
wandb: validation_loss 646.93192
wandb: validation_rmse 25.43486
wandb: 
wandb: 🚀 View run crisp-sweep-38 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5nlvvyj3
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_214241-5nlvvyj3/logs
wandb: Agent Starting Run: qh35cr82 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_214456-qh35cr82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-39
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qh35cr82
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▁▅▂▂▅▂▅▂▃
wandb: validation_rmse █▁▅▂▂▅▂▅▂▃
wandb: 
wandb: Run summary:
wandb:      train_loss 29.95239
wandb:      train_rmse 5.47288
wandb: validation_loss 298.3342
wandb: validation_rmse 17.27235
wandb: 
wandb: 🚀 View run genial-sweep-39 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qh35cr82
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_214456-qh35cr82/logs
wandb: Agent Starting Run: jx1f2g1f with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_214710-jx1f2g1f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-40
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jx1f2g1f
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▂▃▂▂▃▃▁▁
wandb: validation_rmse █▅▂▃▂▂▃▃▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 9.00108
wandb:      train_rmse 3.00018
wandb: validation_loss 352.57921
wandb: validation_rmse 18.77709
wandb: 
wandb: 🚀 View run earnest-sweep-40 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jx1f2g1f
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_214710-jx1f2g1f/logs
wandb: Agent Starting Run: nefuzphl with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_214924-nefuzphl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-41
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/nefuzphl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▄▃▃▂▁▁
wandb:      train_rmse █▆▆▅▄▃▃▂▁▁
wandb: validation_loss █▅▆▆▅▄▄▃▁▁
wandb: validation_rmse █▅▆▆▅▄▄▃▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 830.62134
wandb:      train_rmse 28.8205
wandb: validation_loss 843.8143
wandb: validation_rmse 29.04848
wandb: 
wandb: 🚀 View run twilight-sweep-41 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/nefuzphl
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_214924-nefuzphl/logs
wandb: Agent Starting Run: 3cavaupf with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_215144-3cavaupf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-42
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/3cavaupf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▂▁▁▁▁
wandb:      train_rmse █▁▁▁▁▂▁▂▁▁
wandb: validation_loss ▃▅▅▆▅██▇▅▁
wandb: validation_rmse ▃▅▅▆▅██▇▅▁
wandb: 
wandb: Run summary:
wandb:      train_loss 42.93309
wandb:      train_rmse 6.55233
wandb: validation_loss 243.11507
wandb: validation_rmse 15.59215
wandb: 
wandb: 🚀 View run twilight-sweep-42 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/3cavaupf
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_215144-3cavaupf/logs
wandb: Agent Starting Run: jd6w51sq with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_215358-jd6w51sq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-43
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jd6w51sq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▁▁▁▂▂▂▁▃
wandb: validation_rmse █▄▁▁▁▂▂▂▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 55.36227
wandb:      train_rmse 7.44058
wandb: validation_loss 195.08547
wandb: validation_rmse 13.9673
wandb: 
wandb: 🚀 View run restful-sweep-43 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jd6w51sq
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_215358-jd6w51sq/logs
wandb: Agent Starting Run: vg1iuetr with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_215613-vg1iuetr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-44
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vg1iuetr
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▁▂▃▂▃▂▃▁▂
wandb: validation_rmse █▁▂▃▂▃▃▃▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 5.92793
wandb:      train_rmse 2.43473
wandb: validation_loss 139.08955
wandb: validation_rmse 11.79362
wandb: 
wandb: 🚀 View run earthy-sweep-44 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vg1iuetr
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_215613-vg1iuetr/logs
wandb: Agent Starting Run: ei3we93z with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_215827-ei3we93z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-45
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ei3we93z
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▁▁▁▁▁
wandb: validation_loss ▃▃▆▃▁▇▄▅▃█
wandb: validation_rmse ▃▃▆▃▁▇▄▅▃█
wandb: 
wandb: Run summary:
wandb:      train_loss 12.93299
wandb:      train_rmse 3.59625
wandb: validation_loss 334.90364
wandb: validation_rmse 18.30037
wandb: 
wandb: 🚀 View run sage-sweep-45 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ei3we93z
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_215827-ei3we93z/logs
wandb: Agent Starting Run: t06nmnks with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_220051-t06nmnks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-46
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t06nmnks
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.00365
wandb:      train_rmse 0.06041
wandb: validation_loss 5.14405
wandb: validation_rmse 2.26805
wandb: 
wandb: 🚀 View run honest-sweep-46 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t06nmnks
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_220051-t06nmnks/logs
wandb: Agent Starting Run: eoliq1ru with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_221126-eoliq1ru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-47
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/eoliq1ru
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▅▄▄▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▃▃▂▂▂▂▂▁▁▂▁▁▁▂▁▁▁▁▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.12004
wandb:      train_rmse 0.34647
wandb: validation_loss 3.77584
wandb: validation_rmse 1.94315
wandb: 
wandb: 🚀 View run elated-sweep-47 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/eoliq1ru
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_221126-eoliq1ru/logs
wandb: Agent Starting Run: 5tsvreq3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_222216-5tsvreq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-48
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5tsvreq3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.0
wandb:      train_rmse 0.00052
wandb: validation_loss 5.26764
wandb: validation_rmse 2.29513
wandb: 
wandb: 🚀 View run spring-sweep-48 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5tsvreq3
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_222216-5tsvreq3/logs
wandb: Agent Starting Run: yrualnmu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_223301-yrualnmu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-49
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yrualnmu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.0
wandb:      train_rmse 0.00204
wandb: validation_loss 5.39323
wandb: validation_rmse 2.32233
wandb: 
wandb: 🚀 View run lunar-sweep-49 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yrualnmu
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_223301-yrualnmu/logs
wandb: Agent Starting Run: onln9tol with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_224341-onln9tol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-50
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/onln9tol
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▃▂▂▁
wandb:      train_rmse █▆▅▄▄▃▃▂▂▁
wandb: validation_loss ▄▅▆█▆█▂▁▄▁
wandb: validation_rmse ▄▅▆█▆█▂▁▄▁
wandb: 
wandb: Run summary:
wandb:      train_loss 837.02571
wandb:      train_rmse 28.9314
wandb: validation_loss 770.26205
wandb: validation_rmse 27.7536
wandb: 
wandb: 🚀 View run dry-sweep-50 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/onln9tol
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_224341-onln9tol/logs
wandb: Agent Starting Run: kfjytkat with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_224556-kfjytkat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-51
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/kfjytkat
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.26932
wandb:      train_rmse 0.51896
wandb: validation_loss 4.46289
wandb: validation_rmse 2.11256
wandb: 
wandb: 🚀 View run different-sweep-51 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/kfjytkat
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_224556-kfjytkat/logs
wandb: Agent Starting Run: 1dcyo7ht with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_225641-1dcyo7ht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-52
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/1dcyo7ht
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▁▁▁▁
wandb: validation_loss █▇▇▃▁▁▁▁▁▂
wandb: validation_rmse █▇▇▃▁▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 20.98039
wandb:      train_rmse 4.58044
wandb: validation_loss 307.83351
wandb: validation_rmse 17.54518
wandb: 
wandb: 🚀 View run glorious-sweep-52 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/1dcyo7ht
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_225641-1dcyo7ht/logs
wandb: Agent Starting Run: 4lz8jwg4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_225855-4lz8jwg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-53
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4lz8jwg4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▁▁▁▁▁▁
wandb: validation_loss ▁█▅▅▄▇▃▇▁▆
wandb: validation_rmse ▁█▅▅▄▇▃▇▁▆
wandb: 
wandb: Run summary:
wandb:      train_loss 12.08364
wandb:      train_rmse 3.47615
wandb: validation_loss 270.93011
wandb: validation_rmse 16.45995
wandb: 
wandb: 🚀 View run astral-sweep-53 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4lz8jwg4
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_225855-4lz8jwg4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: abuu2mvs with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_230114-abuu2mvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-54
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/abuu2mvs
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▂▁▂▁▃▃
wandb: validation_rmse █▃▂▂▂▁▂▁▃▃
wandb: 
wandb: Run summary:
wandb:      train_loss 10.6076
wandb:      train_rmse 3.25693
wandb: validation_loss 233.15618
wandb: validation_rmse 15.26945
wandb: 
wandb: 🚀 View run kind-sweep-54 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/abuu2mvs
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_230114-abuu2mvs/logs
wandb: Agent Starting Run: ig0jclrf with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_230329-ig0jclrf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-55
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ig0jclrf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▁▁▁
wandb: validation_loss ▅▃█▄▁▇▃▂▁▂
wandb: validation_rmse ▅▃█▄▁▇▃▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 138.58523
wandb:      train_rmse 11.77222
wandb: validation_loss 715.39072
wandb: validation_rmse 26.74679
wandb: 
wandb: 🚀 View run earnest-sweep-55 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ig0jclrf
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_230329-ig0jclrf/logs
wandb: Agent Starting Run: yu9rjwln with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_230543-yu9rjwln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-56
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yu9rjwln
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▄▃▂▂▁
wandb:      train_rmse █▆▅▅▄▄▃▂▂▁
wandb: validation_loss █▁▁▃▁▃▄▅▁▂
wandb: validation_rmse █▁▁▃▁▃▄▅▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 828.04707
wandb:      train_rmse 28.77581
wandb: validation_loss 631.27014
wandb: validation_rmse 25.12509
wandb: 
wandb: 🚀 View run good-sweep-56 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yu9rjwln
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_230543-yu9rjwln/logs
wandb: Agent Starting Run: tdb64jwf with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_230757-tdb64jwf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-57
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/tdb64jwf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▂▁▁▁▁▁▁▁
wandb: validation_loss █▄▃▁▁▂▂▁▁▁
wandb: validation_rmse █▅▃▁▁▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 6.81282
wandb:      train_rmse 2.61014
wandb: validation_loss 129.99699
wandb: validation_rmse 11.40162
wandb: 
wandb: 🚀 View run wild-sweep-57 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/tdb64jwf
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_230757-tdb64jwf/logs
wandb: Agent Starting Run: zvdkcm3p with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_231012-zvdkcm3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-58
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zvdkcm3p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▃▂▂▁
wandb:      train_rmse █▆▅▄▄▃▃▂▂▁
wandb: validation_loss ▁▃▄▅▅▇▇███
wandb: validation_rmse ▁▃▄▅▅▇▇███
wandb: 
wandb: Run summary:
wandb:      train_loss 815.51219
wandb:      train_rmse 28.55717
wandb: validation_loss 735.51263
wandb: validation_rmse 27.12034
wandb: 
wandb: 🚀 View run eternal-sweep-58 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zvdkcm3p
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_231012-zvdkcm3p/logs
wandb: Agent Starting Run: 0j9nl2ck with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_231226-0j9nl2ck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-59
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/0j9nl2ck
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▇▆▅▄▄▄▃▃▃▂▃▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▃▂▂▂▂▂▂▁▃▁▁▁▁▂▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.13108
wandb:      train_rmse 0.36205
wandb: validation_loss 3.47559
wandb: validation_rmse 1.86429
wandb: 
wandb: 🚀 View run fancy-sweep-59 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/0j9nl2ck
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_231226-0j9nl2ck/logs
wandb: Agent Starting Run: 2uarkwg2 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_232316-2uarkwg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-60
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/2uarkwg2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▁▁▁▁
wandb: validation_loss ▅▃▃▁▂▄▂▅█▄
wandb: validation_rmse ▅▃▃▁▂▄▂▅█▄
wandb: 
wandb: Run summary:
wandb:      train_loss 16.88519
wandb:      train_rmse 4.10916
wandb: validation_loss 307.51582
wandb: validation_rmse 17.53613
wandb: 
wandb: 🚀 View run comic-sweep-60 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/2uarkwg2
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_232316-2uarkwg2/logs
wandb: Agent Starting Run: i2z0uxyi with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_232531-i2z0uxyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-61
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/i2z0uxyi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▆▃▂▂▁▁▁▂▁▁▁▁▂▂▁▁▂▂▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁
wandb: validation_rmse █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.167
wandb:      train_rmse 0.40866
wandb: validation_loss 5.39253
wandb: validation_rmse 2.32218
wandb: 
wandb: 🚀 View run divine-sweep-61 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/i2z0uxyi
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_232531-i2z0uxyi/logs
wandb: Agent Starting Run: dmi7az46 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_233616-dmi7az46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-62
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/dmi7az46
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▂▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▁▁▁▁
wandb: validation_loss ▁▃▃▅▅▆▇█▇█
wandb: validation_rmse ▁▃▃▅▆▆▇█▇█
wandb: 
wandb: Run summary:
wandb:      train_loss 20.1611
wandb:      train_rmse 4.49011
wandb: validation_loss 558.59598
wandb: validation_rmse 23.63464
wandb: 
wandb: 🚀 View run stoic-sweep-62 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/dmi7az46
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_233616-dmi7az46/logs
wandb: Agent Starting Run: 8ibqn5bo with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_233829-8ibqn5bo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-63
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/8ibqn5bo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▂▁▁▁▁▁▁▁
wandb: validation_loss ██▂▁▄▂▂▄▆▅
wandb: validation_rmse ██▃▁▄▂▂▄▇▅
wandb: 
wandb: Run summary:
wandb:      train_loss 12.31292
wandb:      train_rmse 3.50898
wandb: validation_loss 211.53458
wandb: validation_rmse 14.54423
wandb: 
wandb: 🚀 View run sage-sweep-63 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/8ibqn5bo
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_233829-8ibqn5bo/logs
wandb: Agent Starting Run: rj506vch with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_234044-rj506vch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-64
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/rj506vch
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▁▁▁▁▁▁
wandb: validation_loss ▃▂▁▄▄▄▃█▃▃
wandb: validation_rmse ▄▂▁▄▄▄▄█▄▃
wandb: 
wandb: Run summary:
wandb:      train_loss 3.95211
wandb:      train_rmse 1.98799
wandb: validation_loss 126.90221
wandb: validation_rmse 11.26509
wandb: 
wandb: 🚀 View run confused-sweep-64 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/rj506vch
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_234044-rj506vch/logs
wandb: Agent Starting Run: 432w9xg2 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_234258-432w9xg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-65
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/432w9xg2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▄▃▃▂▂▂▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.2426
wandb:      train_rmse 0.49254
wandb: validation_loss 4.80713
wandb: validation_rmse 2.19252
wandb: 
wandb: 🚀 View run dulcet-sweep-65 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/432w9xg2
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_234258-432w9xg2/logs
wandb: Agent Starting Run: 7t8gxhmu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241127_235343-7t8gxhmu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-66
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/7t8gxhmu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ▆▂▃▂▂▂▁▅▂▄▁▁▁▂▁▁█▂▅▁▁▁▂▁▂▁▂▁▂▂▆▂▁▂▁▁▂▃▁▁
wandb: validation_rmse █▃▄▃▃▂▇▃▅▂▁▂▁▂▁▂▇▂▂▃▂▂▁▃▃▂▂▁▃▂█▃▂▂▁▁▂▅▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 21.3174
wandb:      train_rmse 4.61708
wandb: validation_loss 4.17541
wandb: validation_rmse 2.04338
wandb: 
wandb: 🚀 View run colorful-sweep-66 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/7t8gxhmu
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_235343-7t8gxhmu/logs
wandb: Agent Starting Run: 5edhx8fg with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_000443-5edhx8fg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-67
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5edhx8fg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▂▁▂▂▁▂
wandb: validation_rmse █▃▂▂▂▁▂▂▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 97.66541
wandb:      train_rmse 9.88258
wandb: validation_loss 171.53287
wandb: validation_rmse 13.09706
wandb: 
wandb: 🚀 View run zany-sweep-67 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5edhx8fg
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_000443-5edhx8fg/logs
wandb: Agent Starting Run: u8ks1ehe with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_000658-u8ks1ehe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-68
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/u8ks1ehe
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▂▃▂▂▁▃
wandb: validation_rmse █▂▂▁▂▃▂▂▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 9.81799
wandb:      train_rmse 3.13337
wandb: validation_loss 420.68452
wandb: validation_rmse 20.5106
wandb: 
wandb: 🚀 View run expert-sweep-68 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/u8ks1ehe
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_000658-u8ks1ehe/logs
wandb: Agent Starting Run: 3atk96wu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_000912-3atk96wu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-69
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/3atk96wu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.00011
wandb:      train_rmse 0.01027
wandb: validation_loss 5.17928
wandb: validation_rmse 2.2758
wandb: 
wandb: 🚀 View run trim-sweep-69 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/3atk96wu
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_000912-3atk96wu/logs
wandb: Agent Starting Run: 740ajfdd with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_002009-740ajfdd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-70
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/740ajfdd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▁▁▁▁
wandb: validation_loss █▂▃▄▂▄▂▁▂▃
wandb: validation_rmse █▂▃▄▂▄▂▁▃▃
wandb: 
wandb: Run summary:
wandb:      train_loss 3.56189
wandb:      train_rmse 1.8873
wandb: validation_loss 107.36878
wandb: validation_rmse 10.36189
wandb: 
wandb: 🚀 View run olive-sweep-70 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/740ajfdd
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_002009-740ajfdd/logs
wandb: Agent Starting Run: 5yis7xs3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_002228-5yis7xs3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-71
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5yis7xs3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▂▂▂▁▁▁▁▁
wandb: validation_loss █▇▁▆▁▄▃▅▄▇
wandb: validation_rmse █▇▁▆▁▄▃▅▄▇
wandb: 
wandb: Run summary:
wandb:      train_loss 11.11963
wandb:      train_rmse 3.33461
wandb: validation_loss 289.38065
wandb: validation_rmse 17.01119
wandb: 
wandb: 🚀 View run vague-sweep-71 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5yis7xs3
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_002228-5yis7xs3/logs
wandb: Agent Starting Run: mckts58t with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_002442-mckts58t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-72
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/mckts58t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.07486
wandb:      train_rmse 0.27361
wandb: validation_loss 5.67433
wandb: validation_rmse 2.38209
wandb: 
wandb: 🚀 View run eternal-sweep-72 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/mckts58t
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_002442-mckts58t/logs
wandb: Agent Starting Run: t6upfvh2 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_003522-t6upfvh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-73
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t6upfvh2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▃▂▂▂▁▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▃▂▂▂▂▂▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.39148
wandb:      train_rmse 0.62568
wandb: validation_loss 4.74706
wandb: validation_rmse 2.17877
wandb: 
wandb: 🚀 View run fearless-sweep-73 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t6upfvh2
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_003522-t6upfvh2/logs
wandb: Agent Starting Run: 51h3olb8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_004608-51h3olb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-74
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/51h3olb8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 9e-05
wandb:      train_rmse 0.00952
wandb: validation_loss 5.33322
wandb: validation_rmse 2.30938
wandb: 
wandb: 🚀 View run honest-sweep-74 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/51h3olb8
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_004608-51h3olb8/logs
wandb: Agent Starting Run: ir9uk7ew with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_005648-ir9uk7ew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-75
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ir9uk7ew
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.04943
wandb:      train_rmse 0.22233
wandb: validation_loss 4.61441
wandb: validation_rmse 2.14812
wandb: 
wandb: 🚀 View run major-sweep-75 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ir9uk7ew
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_005648-ir9uk7ew/logs
wandb: Agent Starting Run: alqebmcg with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_010728-alqebmcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-76
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/alqebmcg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▁▁▁▁▁
wandb: validation_loss ▁▅▃▄▃▇▇▆█▂
wandb: validation_rmse ▁▅▃▄▃▇▇▆█▂
wandb: 
wandb: Run summary:
wandb:      train_loss 29.11618
wandb:      train_rmse 5.39594
wandb: validation_loss 495.38974
wandb: validation_rmse 22.25735
wandb: 
wandb: 🚀 View run lyric-sweep-76 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/alqebmcg
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_010728-alqebmcg/logs
wandb: Agent Starting Run: t5ldgk0f with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_010942-t5ldgk0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-77
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t5ldgk0f
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▁▁▁▁▁▁
wandb: validation_loss █▅▁▁▁▃▄▂▁▂
wandb: validation_rmse █▅▁▂▁▃▄▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 10.25004
wandb:      train_rmse 3.20157
wandb: validation_loss 203.75639
wandb: validation_rmse 14.27433
wandb: 
wandb: 🚀 View run helpful-sweep-77 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t5ldgk0f
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_010942-t5ldgk0f/logs
wandb: Agent Starting Run: ahecwu6a with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_011156-ahecwu6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-78
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ahecwu6a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▁▁▁▁▁
wandb: validation_loss █▂▁▄▃▂▆▂▅▆
wandb: validation_rmse █▂▁▄▃▂▆▂▅▆
wandb: 
wandb: Run summary:
wandb:      train_loss 8.29022
wandb:      train_rmse 2.87927
wandb: validation_loss 363.66435
wandb: validation_rmse 19.06999
wandb: 
wandb: 🚀 View run peach-sweep-78 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ahecwu6a
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_011156-ahecwu6a/logs
wandb: Agent Starting Run: zt66pxr3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_011410-zt66pxr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-79
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zt66pxr3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▅▁▁▂▂▁▁▂▂
wandb: validation_rmse █▅▁▁▂▂▁▁▂▂
wandb: 
wandb: Run summary:
wandb:      train_loss 6.67303
wandb:      train_rmse 2.58322
wandb: validation_loss 218.5032
wandb: validation_rmse 14.78185
wandb: 
wandb: 🚀 View run dutiful-sweep-79 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zt66pxr3
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_011410-zt66pxr3/logs
wandb: Agent Starting Run: ima5hela with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_011625-ima5hela
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-80
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ima5hela
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss █▃▁▂▃▂▂▂▃▄
wandb: validation_rmse █▃▁▂▃▂▂▂▃▄
wandb: 
wandb: Run summary:
wandb:      train_loss 5.5205
wandb:      train_rmse 2.34957
wandb: validation_loss 158.357
wandb: validation_rmse 12.584
wandb: 
wandb: 🚀 View run autumn-sweep-80 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ima5hela
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_011625-ima5hela/logs
wandb: Agent Starting Run: v9xoqb9h with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_011839-v9xoqb9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-81
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/v9xoqb9h
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▄▃▂▂▂▁▁▁▁
wandb:      train_rmse █▅▄▃▂▂▂▂▁▁
wandb: validation_loss ▁▅▃▃▅▆▇▆▇█
wandb: validation_rmse ▁▅▄▃▅▆▇▇██
wandb: 
wandb: Run summary:
wandb:      train_loss 56.41584
wandb:      train_rmse 7.51105
wandb: validation_loss 791.7547
wandb: validation_rmse 28.13814
wandb: 
wandb: 🚀 View run eager-sweep-81 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/v9xoqb9h
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_011839-v9xoqb9h/logs
wandb: Agent Starting Run: 5uqc8etv with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_012054-5uqc8etv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-82
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5uqc8etv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▂▁
wandb:      train_rmse █▆▅▄▄▃▂▂▂▁
wandb: validation_loss █▆▅▄▄▃▄▃▂▁
wandb: validation_rmse █▆▅▄▄▃▄▃▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 834.77483
wandb:      train_rmse 28.89247
wandb: validation_loss 834.11533
wandb: validation_rmse 28.88105
wandb: 
wandb: 🚀 View run dazzling-sweep-82 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/5uqc8etv
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_012054-5uqc8etv/logs
wandb: Agent Starting Run: cjmb8irf with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_012315-cjmb8irf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-83
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/cjmb8irf
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.04306
wandb:      train_rmse 0.20751
wandb: validation_loss 5.01513
wandb: validation_rmse 2.23945
wandb: 
wandb: 🚀 View run logical-sweep-83 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/cjmb8irf
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_012315-cjmb8irf/logs
wandb: Agent Starting Run: qgjvwqh1 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_013405-qgjvwqh1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-84
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qgjvwqh1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▁▁▁▁▁▁▁
wandb: validation_loss ▃▂▄▂▁▃▂█▇▂
wandb: validation_rmse ▃▃▄▃▁▃▂█▇▂
wandb: 
wandb: Run summary:
wandb:      train_loss 6.18098
wandb:      train_rmse 2.48616
wandb: validation_loss 123.875
wandb: validation_rmse 11.12991
wandb: 
wandb: 🚀 View run sandy-sweep-84 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qgjvwqh1
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_013405-qgjvwqh1/logs
wandb: Agent Starting Run: j7afxj0d with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_013619-j7afxj0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-85
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/j7afxj0d
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▂▁▁▂▂▂▁
wandb:      train_rmse █▃▂▂▂▁▂▂▂▁
wandb: validation_loss ▅▆▅▄▂█▁▆██
wandb: validation_rmse ▅▆▅▄▂█▁▆██
wandb: 
wandb: Run summary:
wandb:      train_loss 156.71095
wandb:      train_rmse 12.51842
wandb: validation_loss 622.67624
wandb: validation_rmse 24.95348
wandb: 
wandb: 🚀 View run frosty-sweep-85 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/j7afxj0d
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_013619-j7afxj0d/logs
wandb: Agent Starting Run: wd2grdd4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_013833-wd2grdd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-86
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/wd2grdd4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▁▁▁▁▁▁
wandb: validation_loss █▅▃▂▂▁▁▁▁▁
wandb: validation_rmse █▅▃▂▂▁▂▂▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 8.35262
wandb:      train_rmse 2.89009
wandb: validation_loss 161.0635
wandb: validation_rmse 12.69108
wandb: 
wandb: 🚀 View run gentle-sweep-86 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/wd2grdd4
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_013833-wd2grdd4/logs
wandb: Agent Starting Run: eron0uyc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_014048-eron0uyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-87
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/eron0uyc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▁▁▁▁▁▁▁
wandb: validation_loss █▂▂▁▃▂▁▃▂▂
wandb: validation_rmse █▂▃▁▃▂▁▃▃▂
wandb: 
wandb: Run summary:
wandb:      train_loss 3.61653
wandb:      train_rmse 1.90172
wandb: validation_loss 110.06774
wandb: validation_rmse 10.49132
wandb: 
wandb: 🚀 View run cosmic-sweep-87 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/eron0uyc
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_014048-eron0uyc/logs
wandb: Agent Starting Run: pcohilyj with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_014302-pcohilyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-88
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/pcohilyj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁
wandb:      train_rmse █▂▂▂▂▁▁▁▁▁
wandb: validation_loss ▅▁▃▄▁▅▇▆▇█
wandb: validation_rmse ▅▁▃▄▁▅▇▆▇█
wandb: 
wandb: Run summary:
wandb:      train_loss 10.65457
wandb:      train_rmse 3.26413
wandb: validation_loss 430.6059
wandb: validation_rmse 20.75105
wandb: 
wandb: 🚀 View run effortless-sweep-88 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/pcohilyj
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_014302-pcohilyj/logs
wandb: Agent Starting Run: v5pxw52d with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_014516-v5pxw52d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-89
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/v5pxw52d
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▂▁
wandb:      train_rmse █▇▆▅▄▃▃▂▂▁
wandb: validation_loss █▃▄▄▃▂▂▂▂▁
wandb: validation_rmse █▃▄▄▃▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 705.19773
wandb:      train_rmse 26.55556
wandb: validation_loss 750.22238
wandb: validation_rmse 27.39019
wandb: 
wandb: 🚀 View run wobbly-sweep-89 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/v5pxw52d
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_014516-v5pxw52d/logs
wandb: Agent Starting Run: zoss7z00 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_014731-zoss7z00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-90
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zoss7z00
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss ██▂▂▁▂▂▁▂▁▂▁▂▂▃▂▂▂▂▂
wandb: validation_rmse ██▂▂▁▃▂▂▂▁▂▂▃▂▄▂▂▃▃▂
wandb: 
wandb: Run summary:
wandb:      train_loss 3.33231
wandb:      train_rmse 1.82546
wandb: validation_loss 72.19548
wandb: validation_rmse 8.49679
wandb: 
wandb: 🚀 View run ethereal-sweep-90 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/zoss7z00
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_014731-zoss7z00/logs
wandb: Agent Starting Run: tgq8pmfu with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.5
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_015159-tgq8pmfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-91
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/tgq8pmfu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▆▅▄▃▃▂▂▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss ▁▂▃▃▄▆▆▆▇█
wandb: validation_rmse ▁▂▃▄▄▆▇▇▇█
wandb: 
wandb: Run summary:
wandb:      train_loss 728.23642
wandb:      train_rmse 26.98586
wandb: validation_loss 1063.9115
wandb: validation_rmse 32.61766
wandb: 
wandb: 🚀 View run blooming-sweep-91 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/tgq8pmfu
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_015159-tgq8pmfu/logs
wandb: Agent Starting Run: vayi9yze with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_015413-vayi9yze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-92
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vayi9yze
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 2e-05
wandb:      train_rmse 0.00417
wandb: validation_loss 4.78581
wandb: validation_rmse 2.18765
wandb: 
wandb: 🚀 View run whole-sweep-92 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vayi9yze
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_015413-vayi9yze/logs
wandb: Agent Starting Run: bue9bj47 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_020459-bue9bj47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-93
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/bue9bj47
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.18472
wandb:      train_rmse 0.42979
wandb: validation_loss 5.19068
wandb: validation_rmse 2.27831
wandb: 
wandb: 🚀 View run polar-sweep-93 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/bue9bj47
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_020459-bue9bj47/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cvt3en7f with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_021548-cvt3en7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-94
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/cvt3en7f
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▄▄▄▃▂▂▂▁
wandb:      train_rmse █▆▄▄▄▃▂▂▂▁
wandb: validation_loss █▅▄▄▃▂▃▃▁▁
wandb: validation_rmse █▅▄▄▃▂▃▃▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 927.20115
wandb:      train_rmse 30.44998
wandb: validation_loss 923.88779
wandb: validation_rmse 30.39552
wandb: 
wandb: 🚀 View run peach-sweep-94 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/cvt3en7f
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_021548-cvt3en7f/logs
wandb: Agent Starting Run: 8g01437m with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_021803-8g01437m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-95
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/8g01437m
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▁▁
wandb:      train_rmse █▇▆▅▄▃▃▂▁▁
wandb: validation_loss █▅▄▃▃▃▃▃▁▂
wandb: validation_rmse █▅▄▃▃▃▃▃▁▂
wandb: 
wandb: Run summary:
wandb:      train_loss 726.4257
wandb:      train_rmse 26.95229
wandb: validation_loss 638.04962
wandb: validation_rmse 25.25964
wandb: 
wandb: 🚀 View run fresh-sweep-95 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/8g01437m
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_021803-8g01437m/logs
wandb: Agent Starting Run: 6ziiiw2a with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0.3
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_022022-6ziiiw2a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-96
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/6ziiiw2a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▃▂▂▁
wandb:      train_rmse █▆▅▄▄▃▃▂▂▁
wandb: validation_loss ▁▂▃▅▆▆▆▇██
wandb: validation_rmse ▁▂▃▅▆▆▆▇██
wandb: 
wandb: Run summary:
wandb:      train_loss 882.74556
wandb:      train_rmse 29.71103
wandb: validation_loss 866.22412
wandb: validation_rmse 29.43169
wandb: 
wandb: 🚀 View run skilled-sweep-96 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/6ziiiw2a
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_022022-6ziiiw2a/logs
wandb: Agent Starting Run: 3r6lsi9s with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_022237-3r6lsi9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-97
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/3r6lsi9s
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▂▂▂▂▂▂▃▂▃▂▂▂▂▁▂▂▂▂▂▃▁▂▂▁▁▁▂▃▃▃▂▂▂▂▃▃▃▂
wandb:      train_rmse █▂▃▂▂▂▂▂▃▃▃▃▂▂▂▂▂▂▂▂▃▁▂▂▂▁▁▂▃▃▃▃▂▃▃▃▃▃▃▂
wandb: validation_loss ▄▃█▁▂▆▁▂▄▁█▁▁▂▃▂▂▁▁▂▁▁▄▇▄▂▃▁▁▂▃▃▄▃▂▁▂▃▁▃
wandb: validation_rmse ▅▄█▁▂▆▁▃▅▁█▁▂▂▄▃▂▃▁▁▃▁▂▇▅▃▁▁▂▄▄▅▄▃▂▃▄▁▁▄
wandb: 
wandb: Run summary:
wandb:      train_loss 115.88647
wandb:      train_rmse 10.76506
wandb: validation_loss 26.66282
wandb: validation_rmse 5.16361
wandb: 
wandb: 🚀 View run rose-sweep-97 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/3r6lsi9s
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_022237-3r6lsi9s/logs
wandb: Agent Starting Run: qsuwlmqm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 64
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.3
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-06
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_023332-qsuwlmqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-98
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qsuwlmqm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▃▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▅▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▅▃▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.12129
wandb:      train_rmse 0.34827
wandb: validation_loss 4.55457
wandb: validation_rmse 2.13414
wandb: 
wandb: 🚀 View run crimson-sweep-98 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/qsuwlmqm
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_023332-qsuwlmqm/logs
wandb: Agent Starting Run: 4sxe6zu3 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0.5
wandb: 	num_conv_layers: 2
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 16
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_024427-4sxe6zu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-99
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4sxe6zu3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 0.06116
wandb:      train_rmse 0.24731
wandb: validation_loss 5.20851
wandb: validation_rmse 2.28222
wandb: 
wandb: 🚀 View run wise-sweep-99 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/4sxe6zu3
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_024427-4sxe6zu3/logs
wandb: Agent Starting Run: i8dvwtg9 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 32
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 1
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: False
wandb: 	use_fc_batchnorm: False
wandb: 	weight_decay: 1e-05
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241128_025512-i8dvwtg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-100
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/tl226t5t
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/i8dvwtg9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_rmse █▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: validation_rmse █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 1e-05
wandb:      train_rmse 0.00324
wandb: validation_loss 5.07701
wandb: validation_rmse 2.25322
wandb: 
wandb: 🚀 View run swift-sweep-100 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/i8dvwtg9
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_025512-i8dvwtg9/logs
