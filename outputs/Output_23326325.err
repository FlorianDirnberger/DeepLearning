Loaded module: cuda/11.8
Loaded dependency [python3/3.10.13]: sqlite3/3.45.1
Loaded dependency [python3/3.10.13]: gcc/12.3.0-binutils-2.40
Loaded module: python3/3.10.13

Loading python3/3.10.13
  Loading requirement: sqlite3/3.45.1 gcc/12.3.0-binutils-2.40
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: s232735 (s232735-danmarks-tekniske-universitet-dtu). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /zhome/cf/5/202847/.netrc
wandb: Agent Starting Run: mrn5i7tw with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_162025-mrn5i7tw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-1
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/mrn5i7tw
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▃▃▂▁▁
wandb:      train_rmse █▆▅▅▄▃▃▂▂▁
wandb: validation_loss █▆▆▇▄▄▅▂▂▁
wandb: validation_rmse █▆▆▇▄▄▅▂▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 691.68675
wandb:      train_rmse 26.29994
wandb: validation_loss 702.28229
wandb: validation_rmse 26.50061
wandb: 
wandb: 🚀 View run still-sweep-1 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/mrn5i7tw
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_162025-mrn5i7tw/logs
wandb: Agent Starting Run: jg3i5r7h with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_162306-jg3i5r7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-2
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jg3i5r7h
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▂▁
wandb:      train_rmse █▆▆▄▄▃▂▂▂▁
wandb: validation_loss ▇▇█▅▄▂▃▃▁▁
wandb: validation_rmse ▇▇█▅▄▂▃▃▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 789.81657
wandb:      train_rmse 28.10368
wandb: validation_loss 784.71329
wandb: validation_rmse 28.01273
wandb: 
wandb: 🚀 View run astral-sweep-2 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jg3i5r7h
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_162306-jg3i5r7h/logs
wandb: Agent Starting Run: nvgf3ta8 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_162510-nvgf3ta8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-3
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/nvgf3ta8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▃▂▂▁
wandb:      train_rmse █▆▅▄▄▃▃▂▂▁
wandb: validation_loss █▇▇█▄▅▄▃▄▁
wandb: validation_rmse █▇▇█▄▅▄▃▄▁
wandb: 
wandb: Run summary:
wandb:      train_loss 823.19031
wandb:      train_rmse 28.69129
wandb: validation_loss 816.44083
wandb: validation_rmse 28.57343
wandb: 
wandb: 🚀 View run effortless-sweep-3 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/nvgf3ta8
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_162510-nvgf3ta8/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xycysebc with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_162725-xycysebc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-4
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/xycysebc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▁▁
wandb:      train_rmse █▆▅▄▄▃▂▂▁▁
wandb: validation_loss █▇▄▆▅▅▂▃▃▁
wandb: validation_rmse █▇▄▆▅▅▂▃▃▁
wandb: 
wandb: Run summary:
wandb:      train_loss 877.17284
wandb:      train_rmse 29.6171
wandb: validation_loss 886.20926
wandb: validation_rmse 29.76927
wandb: 
wandb: 🚀 View run eager-sweep-4 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/xycysebc
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_162725-xycysebc/logs
wandb: Agent Starting Run: yafa4c67 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_162931-yafa4c67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-5
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yafa4c67
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▅▄▃▃▂▂▁
wandb:      train_rmse █▆▅▅▄▃▃▂▂▁
wandb: validation_loss ▆█▆▂▄▃▂▁▁▄
wandb: validation_rmse ▆█▆▂▄▃▂▁▁▄
wandb: 
wandb: Run summary:
wandb:      train_loss 674.1296
wandb:      train_rmse 25.96401
wandb: validation_loss 754.05057
wandb: validation_rmse 27.45998
wandb: 
wandb: 🚀 View run amber-sweep-5 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/yafa4c67
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_162931-yafa4c67/logs
wandb: Agent Starting Run: ybnkfczm with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_163135-ybnkfczm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-6
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ybnkfczm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▄▃▂▂▁
wandb:      train_rmse █▆▆▅▄▄▃▂▂▁
wandb: validation_loss █▇█▆▅▄▃▁▁▁
wandb: validation_rmse █▇█▆▅▄▃▁▁▁
wandb: 
wandb: Run summary:
wandb:      train_loss 780.63392
wandb:      train_rmse 27.93983
wandb: validation_loss 782.8811
wandb: validation_rmse 27.98001
wandb: 
wandb: 🚀 View run easy-sweep-6 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/ybnkfczm
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_163135-ybnkfczm/logs
wandb: Agent Starting Run: vyc30qf7 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_163339-vyc30qf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-7
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vyc30qf7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▄▃▂▂▂▁
wandb:      train_rmse █▆▅▄▄▃▂▂▂▁
wandb: validation_loss █▄▆▆▅▄▃▄▂▁
wandb: validation_rmse █▄▆▆▅▄▃▄▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 801.28031
wandb:      train_rmse 28.3069
wandb: validation_loss 798.77213
wandb: validation_rmse 28.26256
wandb: 
wandb: 🚀 View run helpful-sweep-7 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/vyc30qf7
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_163339-vyc30qf7/logs
wandb: Agent Starting Run: 18xtp6e4 with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 128
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 4
wandb: 	num_fc_layers: 3
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_163538-18xtp6e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-8
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/18xtp6e4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▆▅▄▃▃▂▂▁▁
wandb:      train_rmse █▆▅▄▃▃▂▂▁▁
wandb: validation_loss █▇▇▅▃▄▂▂▁▃
wandb: validation_rmse █▇▇▅▃▄▂▂▁▃
wandb: 
wandb: Run summary:
wandb:      train_loss 812.76355
wandb:      train_rmse 28.50901
wandb: validation_loss 834.31326
wandb: validation_rmse 28.88448
wandb: 
wandb: 🚀 View run wild-sweep-8 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/18xtp6e4
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_163538-18xtp6e4/logs
wandb: Agent Starting Run: t61bmejz with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 256
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_163747-t61bmejz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-9
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t61bmejz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      train_loss █▇▆▅▄▃▃▂▂▁
wandb:      train_rmse █▇▆▅▄▄▃▂▂▁
wandb: validation_loss ▇█▆▄▃▅▃▄▂▁
wandb: validation_rmse ▇█▆▄▃▅▃▅▂▁
wandb: 
wandb: Run summary:
wandb:      train_loss 612.98786
wandb:      train_rmse 24.75859
wandb: validation_loss 642.43243
wandb: validation_rmse 25.34625
wandb: 
wandb: 🚀 View run lunar-sweep-9 at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/t61bmejz
wandb: ⭐️ View project at: https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_163747-t61bmejz/logs
wandb: Agent Starting Run: jkizcgxo with config:
wandb: 	activation_fn: ReLU
wandb: 	batch_size: 32
wandb: 	conv_dropout: 0
wandb: 	epochs: 50
wandb: 	hidden_units: 256
wandb: 	kernel_size: 3x3
wandb: 	learning_rate: 0.0001
wandb: 	linear_dropout: 0
wandb: 	num_conv_layers: 3
wandb: 	num_fc_layers: 2
wandb: 	optimizer: AdamW
wandb: 	out_channels: 32
wandb: 	padding: 1
wandb: 	pooling_size: 2
wandb: 	stride: 1
wandb: 	use_cnn_batchnorm: True
wandb: 	use_fc_batchnorm: True
wandb: 	weight_decay: 0.0001
wandb: 	weights_init: Kaiming_normal
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /zhome/cf/5/202847/my_project_dir/DeepLearning97/wandb/run-20241202_164002-jkizcgxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-10
wandb: ⭐️ View project at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel
wandb: 🧹 View sweep at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/sweeps/jlhtc6k0
wandb: 🚀 View run at https://wandb.ai/s232735-danmarks-tekniske-universitet-dtu/Preprocess%20with%20sobel/runs/jkizcgxo
wandb: Ctrl + C detected. Stopping sweep.
